{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b74fd31",
   "metadata": {},
   "source": [
    "## Testa a utilização dos modelos LSTM ou Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a9acc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, Concatenate, Dropout, Reshape\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362f38ac",
   "metadata": {},
   "source": [
    "## Função filtra_usuario_separa_x_epoca_y()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45b8acc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtra_usuario_separa_x_epoca_y(df, username=\"*\", usuarios_exclusao=[]):\n",
    "    \"\"\"\n",
    "    Prepara os dados filtrando por usuário e criando features históricas\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame com os dados originais\n",
    "        username: Nome do usuário para filtrar (\"*\" para todos os usuários)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (features_sequenciais, features_contextuais, target)\n",
    "    \"\"\"\n",
    "    print(f\"Processando dados para usuário: {username}\")\n",
    "    \n",
    "    # Filtrar por usuário se especificado\n",
    "\n",
    "    if username != \"*\":\n",
    "        df_filtro = df[df[\"usuario\"] == username].copy()\n",
    "        print(f\"Registros após filtro de usuário: {len(df_filtro)}\")\n",
    "    else:\n",
    "        df_filtro = df[~df[\"usuario\"].isin(usuarios_exclusao)].copy()\n",
    "        print(f\"Processando todos os usuários (excluindo {len(usuarios_exclusao)} usuários): {len(df_filtro)} registros\")\n",
    "\n",
    "        # Ordenar por data/hora para manter sequência temporal\n",
    "        df_filtro = df_filtro.sort_values([\"usuario\", \"Dia\", \"Mes\", \"Ano\", \"DataHoraCriacao\"])\n",
    "\n",
    "    # Criar features históricas (últimos 3 casos de uso)\n",
    "    print(\"Criando features históricas...\")\n",
    "    for shift in range(1, 3):\n",
    "        df_filtro[f\"casoDeUso_{shift}\"] = df_filtro.groupby([\"usuario\", \"Dia\", \"Mes\", \"Ano\"])[\"casoDeUso\"].shift(shift).fillna(\"vazio\")\n",
    "\n",
    "    # Remover registros com NaN e resetar índice\n",
    "    df_filtro = df_filtro.dropna().reset_index(drop=True)\n",
    "    print(f\"Registros após limpeza: {len(df_filtro)}\")\n",
    "\n",
    "    # Separar target\n",
    "    df_target = df_filtro[\"casoDeUso\"]\n",
    "\n",
    "    # Preparar features sequenciais (remover colunas não necessárias)\n",
    "    cols_a_remover = [\"DataHoraCriacao\", \"Dia\", \"Mes\", \"Ano\", \"casoDeUso\", \"usuario\", \"PeriodoDoMes\"]\n",
    "    df_x = df_filtro.drop(columns=cols_a_remover)\n",
    "\n",
    "    # Preparar features contextuais (período do mês)\n",
    "    df_epoca = df_filtro[[\"PeriodoDoMes\"]].copy()\n",
    "\n",
    "    return df_x, df_epoca, df_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0a3b8f",
   "metadata": {},
   "source": [
    "## Função aplica_OneHotEncoder_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ccfd6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplica_OneHotEncoder_x(df, cols):\n",
    "    \"\"\"\n",
    "    Aplica One-Hot Encoding nas colunas especificadas\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame para processar\n",
    "        cols: Lista de colunas para aplicar encoding\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (DataFrame com encoding aplicado, OneHotEncoder fitted)\n",
    "    \"\"\"\n",
    "    print(f\"Aplicando One-Hot Encoding em: {cols}\")\n",
    "    ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    df_ohe = pd.DataFrame(\n",
    "        ohe.fit_transform(df[cols]), \n",
    "        columns=ohe.get_feature_names_out(cols), \n",
    "        index=df.index\n",
    "    )\n",
    "    return pd.concat([df.drop(columns=cols), df_ohe], axis=1), ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaf53f3",
   "metadata": {},
   "source": [
    "## Função preprocessar_dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "632f5595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessar_dados(data_path, username=\"*\", usuarios_exclusao=[], test_size=0.4, random_state=42):\n",
    "    \"\"\"\n",
    "    Pipeline completo de preprocessamento de dados\n",
    "    \n",
    "    Args:\n",
    "        data_path: Caminho para o arquivo CSV\n",
    "        username: Usuário para filtrar\n",
    "        test_size: Proporção para teste\n",
    "        random_state: Seed para reprodutibilidade\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Dados de treino e teste preprocessados\n",
    "    \"\"\"\n",
    "    print(\"=== INICIANDO PREPROCESSAMENTO ===\")\n",
    "    \n",
    "    # Carregar dados\n",
    "    print(f\"Carregando dados de: {data_path}\")\n",
    "    df = pd.read_csv(\n",
    "        data_path, \n",
    "        sep=';', \n",
    "        encoding='utf-8', \n",
    "        parse_dates=['DataHoraCriacao'], \n",
    "        dayfirst=True\n",
    "    )\n",
    "    print(f\"Dataset carregado: {df.shape}\")\n",
    "    \n",
    "    # Verificar distribuição das classes\n",
    "    print(\"\\nDistribuição das classes:\")\n",
    "    print(df['casoDeUso'].value_counts().head(10))\n",
    "    \n",
    "    # Processar dados\n",
    "    df_x, df_epoca, serie_y = filtra_usuario_separa_x_epoca_y(df, username, usuarios_exclusao)\n",
    "    \n",
    "    # Aplicar One-Hot Encoding nas features históricas\n",
    "    # df_x, ohe_x = aplica_OneHotEncoder_x(df_x, [\"casoDeUso_1\", \"casoDeUso_2\", \"casoDeUso_3\"])\n",
    "    df_x, ohe_x = aplica_OneHotEncoder_x(df_x, [\"casoDeUso_1\", \"casoDeUso_2\"])\n",
    "    \n",
    "    # Mapear período do mês para valores numéricos e normalizar\n",
    "    print(\"Processando features contextuais...\")\n",
    "    df_epoca[\"PeriodoDoMes\"] = df_epoca[\"PeriodoDoMes\"].map({\n",
    "        'antes_folha': 0, \n",
    "        'dia_folha': 1, \n",
    "        'apos_folha': 2\n",
    "    })\n",
    "    \n",
    "    # Normalizar features contextuais\n",
    "    scaler_epoca = StandardScaler()\n",
    "    df_epoca_scaled = pd.DataFrame(\n",
    "        scaler_epoca.fit_transform(df_epoca), \n",
    "        columns=df_epoca.columns,\n",
    "        index=df_epoca.index\n",
    "    )\n",
    "    \n",
    "    # Converter target para One-Hot\n",
    "    y_one_hot, ohe_y = aplica_OneHotEncoder_x(serie_y.to_frame(), [\"casoDeUso\"])\n",
    "    \n",
    "    # Normalizar features sequenciais\n",
    "    print(\"Normalizando features sequenciais...\")\n",
    "    scaler_seq = StandardScaler()\n",
    "    df_x_scaled = pd.DataFrame(\n",
    "        scaler_seq.fit_transform(df_x),\n",
    "        columns=df_x.columns,\n",
    "        index=df_x.index\n",
    "    )\n",
    "    \n",
    "    # Verificar se é possível fazer divisão estratificada\n",
    "    print(\"Dividindo dados em treino e teste...\")\n",
    "    \n",
    "    # Verificar classes com poucas amostras\n",
    "    class_counts = serie_y.value_counts()\n",
    "    classes_com_poucas_amostras = class_counts[class_counts < 2]\n",
    "    \n",
    "    if len(classes_com_poucas_amostras) > 0:\n",
    "        print(f\"⚠️ Aviso: {len(classes_com_poucas_amostras)} classes com apenas 1 amostra:\")\n",
    "        print(classes_com_poucas_amostras.head())\n",
    "        print(\"Removendo classes com poucas amostras para permitir estratificação...\")\n",
    "        \n",
    "        # Filtrar classes com pelo menos 2 amostras\n",
    "        classes_validas = class_counts[class_counts >= 2].index\n",
    "        mask = serie_y.isin(classes_validas)\n",
    "        \n",
    "        df_x_scaled = df_x_scaled[mask]\n",
    "        df_epoca_scaled = df_epoca_scaled[mask]\n",
    "        y_one_hot = y_one_hot[mask]\n",
    "        serie_y = serie_y[mask]\n",
    "        \n",
    "        print(f\"Dados após filtro: {len(df_x_scaled)} amostras, {len(serie_y.unique())} classes\")\n",
    "        \n",
    "        # Recriar one-hot encoding para classes restantes\n",
    "        y_one_hot, ohe_y = aplica_OneHotEncoder_x(serie_y.to_frame(), [\"casoDeUso\"])\n",
    "    \n",
    "    # Tentar divisão estratificada, se falhar usar divisão simples\n",
    "    try:\n",
    "        X_train_seq, X_test_seq, X_train_epoch, X_test_epoch, y_train, y_test = train_test_split(\n",
    "            df_x_scaled, df_epoca_scaled, y_one_hot, \n",
    "            test_size=test_size, \n",
    "            random_state=random_state,\n",
    "            stratify=serie_y  # Estratificação para manter proporção das classes\n",
    "        )\n",
    "        print(\"✅ Divisão estratificada realizada com sucesso\")\n",
    "    except ValueError as e:\n",
    "        print(f\"⚠️ Não foi possível fazer divisão estratificada: {str(e)}\")\n",
    "        print(\"Realizando divisão simples...\")\n",
    "        X_train_seq, X_test_seq, X_train_epoch, X_test_epoch, y_train, y_test = train_test_split(\n",
    "            df_x_scaled, df_epoca_scaled, y_one_hot, \n",
    "            test_size=test_size, \n",
    "            random_state=random_state\n",
    "        )\n",
    "    \n",
    "    print(f\"Treino: {X_train_seq.shape[0]} samples\")\n",
    "    print(f\"Teste: {X_test_seq.shape[0]} samples\")\n",
    "    \n",
    "    return (X_train_seq, X_test_seq, X_train_epoch, X_test_epoch, \n",
    "            y_train, y_test, scaler_seq, scaler_epoca, ohe_x, ohe_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb99b950",
   "metadata": {},
   "source": [
    "## função criar_modelo_hibrido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81a2a60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_modelo_hibrido(input_seq_shape, input_epoch_shape, output_shape, \n",
    "                        use_lstm=True, lstm_units=64, dense_units=[128, 64], \n",
    "                        dropout_rate=0.3):\n",
    "    \"\"\"\n",
    "    Cria modelo híbrido com opção de usar LSTM ou Dense\n",
    "    \n",
    "    Args:\n",
    "        input_seq_shape: Shape das features sequenciais\n",
    "        input_epoch_shape: Shape das features contextuais\n",
    "        output_shape: Número de classes de saída\n",
    "        use_lstm: Se True, usa LSTM; se False, usa Dense\n",
    "        lstm_units: Unidades LSTM\n",
    "        dense_units: Lista com unidades das camadas Dense\n",
    "        dropout_rate: Taxa de dropout\n",
    "    \n",
    "    Returns:\n",
    "        Model: Modelo compilado\n",
    "    \"\"\"\n",
    "    print(f\"=== CRIANDO MODELO {'LSTM' if use_lstm else 'DENSE'} HÍBRIDO ===\")\n",
    "    \n",
    "    # Input para features sequenciais\n",
    "    input_seq = Input(shape=(input_seq_shape,), name='input_sequence')\n",
    "    input_epoch = Input(shape=(input_epoch_shape,), name='input_epoch')\n",
    "    \n",
    "    if use_lstm:\n",
    "        # Para LSTM, precisamos reshapear para 3D (samples, timesteps, features)\n",
    "        # Assumindo que cada feature é um timestep\n",
    "        x = Reshape((input_seq_shape, 1))(input_seq)\n",
    "        x = LSTM(lstm_units, return_sequences=False, dropout=dropout_rate)(x)\n",
    "        print(f\"Usando LSTM com {lstm_units} unidades\")\n",
    "    else:\n",
    "        # Usar camadas Dense tradicionais\n",
    "        x = input_seq\n",
    "        for i, units in enumerate(dense_units):\n",
    "            x = Dense(units, activation='relu', name=f'dense_{i+1}')(x)\n",
    "            x = Dropout(dropout_rate, name=f'dropout_{i+1}')(x)\n",
    "        print(f\"Usando Dense layers: {dense_units}\")\n",
    "    \n",
    "    # Combinar features sequenciais com contextuais\n",
    "    combined = Concatenate(name='concatenate')([x, input_epoch])\n",
    "    \n",
    "    # Camada de saída\n",
    "    output = Dense(output_shape, activation='softmax', name='output')(combined)\n",
    "    \n",
    "    # Criar modelo\n",
    "    model = Model(inputs=[input_seq, input_epoch], outputs=output)\n",
    "    \n",
    "    # Compilar modelo\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(\"Modelo criado e compilado!\")\n",
    "    print(f\"Parâmetros totais: {model.count_params():,}\")\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a396405",
   "metadata": {},
   "source": [
    "## função treinar_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57b83292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar_modelo(model, X_train_seq, X_train_epoch, y_train, \n",
    "                  epochs=50, validation_split=0.2, verbose=1):\n",
    "    \"\"\"\n",
    "    Treina o modelo com callbacks para early stopping e redução de learning rate\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo a ser treinado\n",
    "        X_train_seq, X_train_epoch: Features de treino\n",
    "        y_train: Target de treino\n",
    "        epochs: Número máximo de épocas\n",
    "        validation_split: Proporção para validação\n",
    "        verbose: Verbosidade do treinamento\n",
    "    \n",
    "    Returns:\n",
    "        History: Histórico do treinamento\n",
    "    \"\"\"\n",
    "    print(\"=== INICIANDO TREINAMENTO ===\")\n",
    "    \n",
    "    # Callbacks para melhorar o treinamento\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Treinar modelo\n",
    "    history = model.fit(\n",
    "        [X_train_seq, X_train_epoch], \n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        validation_split=validation_split,\n",
    "        callbacks=callbacks,\n",
    "        verbose=verbose,\n",
    "        batch_size=32\n",
    "    )\n",
    "    \n",
    "    print(\"Treinamento concluído!\")\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa75ba6",
   "metadata": {},
   "source": [
    "## Função avaliar_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de1538f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliar_modelo(model, X_test_seq, X_test_epoch, y_test, ohe_y):\n",
    "    \"\"\"\n",
    "    Avalia o modelo com múltiplas métricas\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo treinado\n",
    "        X_test_seq, X_test_epoch: Features de teste\n",
    "        y_test: Target de teste\n",
    "        ohe_y: OneHotEncoder do target para obter nomes das classes\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dicionário com métricas de avaliação\n",
    "    \"\"\"\n",
    "    print(\"=== AVALIANDO MODELO ===\")\n",
    "    \n",
    "    # Predições\n",
    "    y_pred_proba = model.predict([X_test_seq, X_test_epoch])\n",
    "    y_pred = np.argmax(y_pred_proba, axis=-1)\n",
    "    y_test_labels = np.argmax(y_test.values, axis=-1)\n",
    "    \n",
    "    # Métricas básicas\n",
    "    accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "    print(f\"Acurácia: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    # Relatório de classificação\n",
    "    class_names = ohe_y.get_feature_names_out(['casoDeUso'])\n",
    "    class_names = [name.replace('casoDeUso_', '') for name in class_names]\n",
    "    \n",
    "    print(\"\\n=== RELATÓRIO DE CLASSIFICAÇÃO ===\")\n",
    "    print(classification_report(y_test_labels, y_pred, target_names=class_names))\n",
    "    \n",
    "    # Matriz de confusão\n",
    "    cm = confusion_matrix(y_test_labels, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'y_pred': y_pred,\n",
    "        'y_test': y_test_labels,\n",
    "        'confusion_matrix': cm,\n",
    "        'class_names': class_names,\n",
    "        'y_pred_proba': y_pred_proba\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c68b79c",
   "metadata": {},
   "source": [
    "## Função salvar_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7880be2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvar_modelo(model, scaler_seq, scaler_epoca, ohe_x, ohe_y, path_base='artefatos_modelo'):\n",
    "    \"\"\"\n",
    "    Salva o modelo Keras e os transformadores necessários para inferência futura.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo Keras treinado.\n",
    "        scaler_seq: Scaler das features sequenciais.\n",
    "        scaler_epoca: Scaler das features contextuais.\n",
    "        ohe_x: OneHotEncoder das features históricas.\n",
    "        ohe_y: OneHotEncoder do target.\n",
    "        path_base: Pasta/caminho base para salvar os arquivos.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    os.makedirs(path_base, exist_ok=True)\n",
    "\n",
    "    # Salva o modelo keras\n",
    "    model.save(os.path.join(path_base, 'modelo.keras'))\n",
    "\n",
    "    # Salva os transformadores com pickle\n",
    "    with open(os.path.join(path_base, 'scaler_seq.pkl'), 'wb') as f:\n",
    "        pickle.dump(scaler_seq, f)\n",
    "\n",
    "    with open(os.path.join(path_base, 'scaler_epoca.pkl'), 'wb') as f:\n",
    "        pickle.dump(scaler_epoca, f)\n",
    "\n",
    "    with open(os.path.join(path_base, 'ohe_x.pkl'), 'wb') as f:\n",
    "        pickle.dump(ohe_x, f)\n",
    "\n",
    "    with open(os.path.join(path_base, 'ohe_y.pkl'), 'wb') as f:\n",
    "        pickle.dump(ohe_y, f)\n",
    "\n",
    "    print(f\"\\n✅ Modelo e transformadores salvos na pasta '{path_base}'!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f3f9fb",
   "metadata": {},
   "source": [
    "## Função plotar_resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c1196ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotar_resultados(history, results):\n",
    "    \"\"\"\n",
    "    Plota gráficos de treinamento e matriz de confusão\n",
    "    \n",
    "    Args:\n",
    "        history: Histórico do treinamento\n",
    "        results: Resultados da avaliação\n",
    "    \"\"\"\n",
    "    print(\"Gerando visualizações...\")\n",
    "    \n",
    "    # Configurar estilo dos gráficos\n",
    "    plt.style.use('default')\n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    \n",
    "    # 1. Acurácia durante treinamento\n",
    "    ax1 = plt.subplot(2, 3, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Treino', linewidth=2)\n",
    "    plt.plot(history.history['val_accuracy'], label='Validação', linewidth=2)\n",
    "    plt.title('Acurácia Durante o Treinamento', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Acurácia')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Perda durante treinamento\n",
    "    ax2 = plt.subplot(2, 3, 2)\n",
    "    plt.plot(history.history['loss'], label='Treino', linewidth=2)\n",
    "    plt.plot(history.history['val_loss'], label='Validação', linewidth=2)\n",
    "    plt.title('Perda Durante o Treinamento', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Perda')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Learning Rate (se disponível)\n",
    "    ax3 = plt.subplot(2, 3, 3)\n",
    "    if 'lr' in history.history:\n",
    "        plt.plot(history.history['lr'], linewidth=2, color='red')\n",
    "        plt.title('Learning Rate', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Épocas')\n",
    "        plt.ylabel('Learning Rate')\n",
    "        plt.yscale('log')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'Learning Rate\\nnão disponível', \n",
    "                ha='center', va='center', fontsize=12)\n",
    "        plt.title('Learning Rate', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 4. Matriz de confusão\n",
    "    ax4 = plt.subplot(2, 3, (4, 6))\n",
    "    sns.heatmap(\n",
    "        results['confusion_matrix'], \n",
    "        annot=True, \n",
    "        fmt='d', \n",
    "        cmap='Blues',\n",
    "        xticklabels=results['class_names'],\n",
    "        yticklabels=results['class_names']\n",
    "    )\n",
    "    plt.title('Matriz de Confusão', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Predito')\n",
    "    plt.ylabel('Real')\n",
    "    \n",
    "    # 5. Distribuição de confiança das predições\n",
    "    ax5 = plt.subplot(2, 3, 5)\n",
    "    max_proba = np.max(results['y_pred_proba'], axis=1)\n",
    "    plt.hist(max_proba, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    plt.title('Distribuição de Confiança das Predições', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Confiança Máxima')\n",
    "    plt.ylabel('Frequência')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3af53c5",
   "metadata": {},
   "source": [
    "## Função Principal que executa todo o pipeline\n",
    "\n",
    "Esta função:\n",
    "\n",
    "1 - Préprocessa os dados:\n",
    "\n",
    "1.1 - filtrando os usuários que serão utilizados para treinamento\n",
    "\n",
    "1.2 - Gerando linhas com dois casos de uso históricos maio o caso de uso alvo/target\n",
    "\n",
    "1.3 - Separa a massa de dados de treino e avaliação do treino\n",
    "\n",
    "2 - Cria um modelo hibrido, podendo ser:\n",
    "\n",
    "2.1 - LSTM\n",
    "\n",
    "2.2 - Dense layers\n",
    "\n",
    "3 - Treina o modelo hibrido com os dados do passo 1\n",
    "\n",
    "4 - Avaliar o modelo treinado com a base de dados separada para avaliação no passo 1\n",
    "\n",
    "5 - Plota gráficos de avaliação dos resultados\n",
    "\n",
    "6 - Salva o modelo e seus parâmetros de configuração para posterior utilização nas previsões (aqui no notebook, será salvo abaixo da pasta notebooks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc2ffba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data_path='dados.csv', \n",
    "         usuario='*', # Nome do usuário ou '*' para todos\n",
    "         use_lstm=False,  # Usar Dense layers ou LSTM\n",
    "         epochs=50,\n",
    "         plotar_resultado=True, # Se deve ou não chamar o método plotar_resultados()\n",
    "         usuarios_exclusao=[], # No caso de usar '*' em usuario, lista de exclusão da base de dados.  Não carregar os dados desses.\n",
    "         salvar_modelo=False\n",
    "\n",
    "         ):  \n",
    "    \"\"\"\n",
    "    Função principal que executa todo o pipeline\n",
    "    \n",
    "    Args:\n",
    "        data_path: Caminho para os dados\n",
    "        usuario: Usuário para filtrar\n",
    "        use_lstm: Se usar LSTM ou Dense layers\n",
    "        epochs: Número de épocas para treinamento\n",
    "        plotar_resultado: Se deve ou não chamar o método plotar_resultados() ao final do treino e testes\n",
    "        usuarios_exclusao: Lista de usuários a não serem considerados se o usuario='*'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Preprocessamento\n",
    "        (X_train_seq, X_test_seq, X_train_epoch, X_test_epoch, \n",
    "         y_train, y_test, scaler_seq, scaler_epoca, ohe_x, ohe_y) = preprocessar_dados(data_path, usuario, usuarios_exclusao)\n",
    "        \n",
    "        # Criar modelo\n",
    "        modelo = criar_modelo_hibrido(\n",
    "            input_seq_shape=X_train_seq.shape[1],\n",
    "            input_epoch_shape=X_train_epoch.shape[1],\n",
    "            output_shape=y_train.shape[1],\n",
    "            use_lstm=use_lstm\n",
    "        )\n",
    "        \n",
    "        print(\"\\n\\n=== ARQUITETURA DO MODELO ===\")\n",
    "        modelo.summary()\n",
    "        \n",
    "        # Treinar modelo\n",
    "        historico = treinar_modelo(\n",
    "            modelo, X_train_seq, X_train_epoch, y_train, \n",
    "            epochs=epochs\n",
    "        )\n",
    "        \n",
    "        # Avaliar modelo\n",
    "        resultados = avaliar_modelo(\n",
    "            modelo, X_test_seq, X_test_epoch, y_test, ohe_y\n",
    "        )\n",
    "        \n",
    "        # Plotar resultados\n",
    "        if plotar_resultado:\n",
    "            plotar_resultados(historico, resultados)\n",
    "        \n",
    "        if salvar_modelo:\n",
    "            salvar_modelo(modelo, scaler_seq, scaler_epoca, ohe_x, ohe_y, path_base='../modelos')\n",
    "\n",
    "        return modelo, historico, resultados\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erro durante execução: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c7e821",
   "metadata": {},
   "source": [
    "## Execução do treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0734399d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando pipeline de Machine Learning ...\n",
      "============================================================\n",
      "=== INICIANDO PREPROCESSAMENTO ===\n",
      "Carregando dados de: ../dados/processados/Dados_TechChallenge_Fase3.csv\n",
      "Dataset carregado: (115591, 7)\n",
      "\n",
      "Distribuição das classes:\n",
      "casoDeUso\n",
      "uc0043    13099\n",
      "uc0232     7408\n",
      "uc0096     7042\n",
      "uc0146     5042\n",
      "uc0075     3394\n",
      "uc0222     3085\n",
      "uc0162     3018\n",
      "uc0111     2963\n",
      "uc0179     2896\n",
      "uc0069     2620\n",
      "Name: count, dtype: int64\n",
      "Processando dados para usuário: *\n",
      "Processando todos os usuários (excluindo 9 usuários): 106118 registros\n",
      "Criando features históricas...\n",
      "Registros após limpeza: 106118\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso_1', 'casoDeUso_2']\n",
      "Processando features contextuais...\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "Normalizando features sequenciais...\n",
      "Dividindo dados em treino e teste...\n",
      "⚠️ Aviso: 13 classes com apenas 1 amostra:\n",
      "casoDeUso\n",
      "uc0246    1\n",
      "uc2015    1\n",
      "uc0154    1\n",
      "uc2099    1\n",
      "uc2047    1\n",
      "Name: count, dtype: int64\n",
      "Removendo classes com poucas amostras para permitir estratificação...\n",
      "Dados após filtro: 106105 amostras, 280 classes\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "✅ Divisão estratificada realizada com sucesso\n",
      "Treino: 63663 samples\n",
      "Teste: 42442 samples\n",
      "=== CRIANDO MODELO DENSE HÍBRIDO ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748219167.455892  112020 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5520 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando Dense layers: [128, 64]\n",
      "Modelo criado e compilado!\n",
      "Parâmetros totais: 101,872\n",
      "\n",
      "\n",
      "=== ARQUITETURA DO MODELO ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">586</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">75,136</span> │ input_sequence[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ input_epoch[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">280</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,480</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m586\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m75,136\u001b[0m │ input_sequence[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ input_epoch[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m280\u001b[0m)       │     \u001b[38;5;34m18,480\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,872</span> (397.94 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,872\u001b[0m (397.94 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,872</span> (397.94 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,872\u001b[0m (397.94 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INICIANDO TREINAMENTO ===\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1748219168.669351  116339 service.cc:152] XLA service 0x7fd29c0049a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1748219168.669379  116339 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Laptop GPU, Compute Capability 8.9\n",
      "2025-05-25 21:26:08.685422: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1748219168.765206  116339 cuda_dnn.cc:529] Loaded cuDNN version 90501\n",
      "2025-05-25 21:26:09.858216: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1111', 720 bytes spill stores, 620 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  83/1592\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0556 - loss: 5.3964"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748219170.590886  116339 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1574/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1548 - loss: 4.2126"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 21:26:14.398640: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1111_0', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-05-25 21:26:14.401809: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1111', 696 bytes spill stores, 604 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1553 - loss: 4.2086"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 21:26:15.868993: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_63', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-05-25 21:26:15.877381: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_63', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-05-25 21:26:17.127537: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_63', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-05-25 21:26:17.147796: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_63', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.1553 - loss: 4.2083 - val_accuracy: 0.2547 - val_loss: 3.3650 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.2427 - loss: 3.4633 - val_accuracy: 0.2670 - val_loss: 3.2373 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.2545 - loss: 3.3313 - val_accuracy: 0.2725 - val_loss: 3.2116 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2629 - loss: 3.2857 - val_accuracy: 0.2710 - val_loss: 3.2104 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2611 - loss: 3.2491 - val_accuracy: 0.2745 - val_loss: 3.1964 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2645 - loss: 3.2319 - val_accuracy: 0.2747 - val_loss: 3.1870 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2645 - loss: 3.1948 - val_accuracy: 0.2757 - val_loss: 3.1859 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2688 - loss: 3.1947 - val_accuracy: 0.2715 - val_loss: 3.1918 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2646 - loss: 3.1788 - val_accuracy: 0.2757 - val_loss: 3.1839 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.2659 - loss: 3.1838 - val_accuracy: 0.2754 - val_loss: 3.1926 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2706 - loss: 3.1568 - val_accuracy: 0.2753 - val_loss: 3.1991 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2688 - loss: 3.1532 - val_accuracy: 0.2750 - val_loss: 3.1994 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2701 - loss: 3.1493 - val_accuracy: 0.2738 - val_loss: 3.2010 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m1572/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2692 - loss: 3.1359\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2692 - loss: 3.1362 - val_accuracy: 0.2746 - val_loss: 3.2061 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2667 - loss: 3.1333 - val_accuracy: 0.2757 - val_loss: 3.1958 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2732 - loss: 3.0876 - val_accuracy: 0.2774 - val_loss: 3.1913 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2781 - loss: 3.0737 - val_accuracy: 0.2775 - val_loss: 3.1982 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2802 - loss: 3.0676 - val_accuracy: 0.2786 - val_loss: 3.1966 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2771 - loss: 3.0636\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.2771 - loss: 3.0636 - val_accuracy: 0.2784 - val_loss: 3.1961 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2770 - loss: 3.0542 - val_accuracy: 0.2802 - val_loss: 3.1955 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2819 - loss: 3.0424 - val_accuracy: 0.2797 - val_loss: 3.1971 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.2805 - loss: 3.0425 - val_accuracy: 0.2798 - val_loss: 3.2006 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.2821 - loss: 3.0364 - val_accuracy: 0.2796 - val_loss: 3.1978 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m1578/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2827 - loss: 3.0324\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2827 - loss: 3.0325 - val_accuracy: 0.2797 - val_loss: 3.1988 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.2805 - loss: 3.0300 - val_accuracy: 0.2801 - val_loss: 3.1987 - learning_rate: 1.2500e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2836 - loss: 3.0240 - val_accuracy: 0.2795 - val_loss: 3.2012 - learning_rate: 1.2500e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2861 - loss: 3.0127 - val_accuracy: 0.2803 - val_loss: 3.2010 - learning_rate: 1.2500e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2833 - loss: 3.0203 - val_accuracy: 0.2802 - val_loss: 3.2025 - learning_rate: 1.2500e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m1579/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2875 - loss: 3.0072\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2875 - loss: 3.0073 - val_accuracy: 0.2799 - val_loss: 3.2026 - learning_rate: 1.2500e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2791 - loss: 3.0141 - val_accuracy: 0.2797 - val_loss: 3.2014 - learning_rate: 6.2500e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2822 - loss: 3.0176 - val_accuracy: 0.2797 - val_loss: 3.2027 - learning_rate: 6.2500e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2813 - loss: 3.0176 - val_accuracy: 0.2801 - val_loss: 3.2038 - learning_rate: 6.2500e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2867 - loss: 3.0030 - val_accuracy: 0.2804 - val_loss: 3.2029 - learning_rate: 6.2500e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m1570/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2883 - loss: 2.9934\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2882 - loss: 2.9936 - val_accuracy: 0.2809 - val_loss: 3.2024 - learning_rate: 6.2500e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2844 - loss: 3.0098 - val_accuracy: 0.2806 - val_loss: 3.2032 - learning_rate: 3.1250e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2860 - loss: 3.0064 - val_accuracy: 0.2811 - val_loss: 3.2038 - learning_rate: 3.1250e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2894 - loss: 2.9850 - val_accuracy: 0.2808 - val_loss: 3.2035 - learning_rate: 3.1250e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2857 - loss: 2.9983 - val_accuracy: 0.2801 - val_loss: 3.2026 - learning_rate: 3.1250e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m1580/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2888 - loss: 2.9879\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2888 - loss: 2.9879 - val_accuracy: 0.2808 - val_loss: 3.2031 - learning_rate: 3.1250e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2880 - loss: 2.9896 - val_accuracy: 0.2808 - val_loss: 3.2037 - learning_rate: 1.5625e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2827 - loss: 3.0033 - val_accuracy: 0.2802 - val_loss: 3.2036 - learning_rate: 1.5625e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2890 - loss: 2.9876 - val_accuracy: 0.2801 - val_loss: 3.2040 - learning_rate: 1.5625e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2887 - loss: 3.0008 - val_accuracy: 0.2801 - val_loss: 3.2042 - learning_rate: 1.5625e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m1588/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2834 - loss: 3.0087\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2835 - loss: 3.0087 - val_accuracy: 0.2801 - val_loss: 3.2040 - learning_rate: 1.5625e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2856 - loss: 2.9954 - val_accuracy: 0.2800 - val_loss: 3.2040 - learning_rate: 7.8125e-06\n",
      "Epoch 46/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2893 - loss: 2.9953 - val_accuracy: 0.2806 - val_loss: 3.2040 - learning_rate: 7.8125e-06\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "Treinamento concluído!\n",
      "=== AVALIANDO MODELO ===\n",
      "\u001b[1m1327/1327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Acurácia: 28.01%\n",
      "\n",
      "=== RELATÓRIO DE CLASSIFICAÇÃO ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      uc0001       0.00      0.00      0.00         1\n",
      "      uc0003       0.00      0.00      0.00        12\n",
      "      uc0004       0.00      0.00      0.00        44\n",
      "      uc0006       0.00      0.00      0.00         2\n",
      "      uc0012       0.21      0.22      0.21        51\n",
      "      uc0013       0.00      0.00      0.00        42\n",
      "      uc0014       0.00      0.00      0.00         5\n",
      "      uc0015       0.27      0.17      0.21        24\n",
      "      uc0016       0.15      0.09      0.11      1016\n",
      "      uc0017       0.19      0.02      0.04       247\n",
      "     uc0018b       0.00      0.00      0.00       105\n",
      "      uc0019       0.19      0.01      0.01       811\n",
      "      uc0020       0.14      0.12      0.13         8\n",
      "      uc0021       0.00      0.00      0.00         3\n",
      "      uc0022       0.00      0.00      0.00         1\n",
      "      uc0023       0.85      0.96      0.91        55\n",
      "      uc0024       0.31      0.35      0.33       673\n",
      "      uc0025       0.50      0.33      0.40         9\n",
      "   uc0025_01       0.38      0.04      0.08        68\n",
      "      uc0026       0.00      0.00      0.00        27\n",
      "      uc0027       0.17      0.08      0.11        26\n",
      "      uc0028       0.25      0.03      0.05       109\n",
      "      uc0029       0.36      0.75      0.49       205\n",
      "      uc0030       0.50      0.59      0.54       252\n",
      "      uc0031       0.34      0.21      0.26       574\n",
      "      uc0032       0.08      0.04      0.06        46\n",
      "      uc0033       0.00      0.00      0.00        63\n",
      "      uc0034       0.78      0.06      0.11       115\n",
      "      uc0035       0.00      0.00      0.00        13\n",
      "      uc0036       0.00      0.00      0.00        26\n",
      "      uc0037       0.00      0.00      0.00         5\n",
      "      uc0039       0.28      0.41      0.33        99\n",
      "      uc0040       0.41      0.38      0.39       136\n",
      "      uc0041       0.00      0.00      0.00        23\n",
      "      uc0042       0.39      0.46      0.42       156\n",
      "      uc0043       0.22      0.71      0.34      5188\n",
      "      uc0044       0.35      0.28      0.31       741\n",
      "      uc0045       0.27      0.10      0.15       319\n",
      "      uc0046       0.00      0.00      0.00         1\n",
      "      uc0047       0.24      0.02      0.04       164\n",
      "      uc0049       0.33      0.16      0.22        31\n",
      "      uc0050       0.25      0.12      0.17         8\n",
      "      uc0052       0.20      0.02      0.04        46\n",
      "      uc0053       0.32      0.16      0.21       426\n",
      "      uc0054       0.00      0.00      0.00         6\n",
      "      uc0056       0.00      0.00      0.00        73\n",
      "      uc0057       0.00      0.00      0.00         1\n",
      "      uc0058       0.13      0.04      0.06       175\n",
      "      uc0059       0.19      0.20      0.19       116\n",
      "      uc0060       0.43      0.27      0.33       177\n",
      "      uc0061       0.00      0.00      0.00        26\n",
      "      uc0062       0.00      0.00      0.00        17\n",
      "      uc0064       0.00      0.00      0.00         2\n",
      "      uc0065       0.00      0.00      0.00         8\n",
      "      uc0067       1.00      0.07      0.12        15\n",
      "      uc0068       0.09      0.01      0.02       102\n",
      "      uc0069       0.29      0.47      0.36      1048\n",
      "      uc0070       0.00      0.00      0.00         7\n",
      "      uc0072       0.00      0.00      0.00         2\n",
      "      uc0075       0.37      0.60      0.46      1357\n",
      "      uc0076       0.50      0.01      0.03       200\n",
      "      uc0077       0.41      0.25      0.31       681\n",
      "      uc0078       0.19      0.05      0.08        57\n",
      "      uc0079       0.44      0.03      0.06       130\n",
      "      uc0080       0.00      0.00      0.00        25\n",
      "      uc0081       0.00      0.00      0.00        98\n",
      "      uc0082       0.00      0.00      0.00         1\n",
      "      uc0084       0.00      0.00      0.00         9\n",
      "      uc0085       0.00      0.00      0.00        32\n",
      "      uc0086       0.38      0.36      0.37       196\n",
      "      uc0087       0.19      0.07      0.10       334\n",
      "      uc0089       0.14      0.02      0.04        43\n",
      "      uc0090       0.00      0.00      0.00        64\n",
      "      uc0091       0.19      0.20      0.19        70\n",
      "      uc0092       0.00      0.00      0.00         2\n",
      "      uc0093       0.26      0.18      0.21        49\n",
      "      uc0094       0.21      0.02      0.04       785\n",
      "      uc0096       0.27      0.45      0.34      2791\n",
      "      uc0097       0.30      0.10      0.15        92\n",
      "      uc0098       0.64      0.54      0.58       115\n",
      "      uc0099       0.00      0.00      0.00         8\n",
      "      uc0100       0.00      0.00      0.00        66\n",
      "      uc0101       0.00      0.00      0.00         7\n",
      "      uc0102       0.08      0.05      0.06        21\n",
      "      uc0103       0.00      0.00      0.00        11\n",
      "      uc0105       0.00      0.00      0.00        22\n",
      "      uc0107       0.43      0.65      0.52       330\n",
      "      uc0108       0.59      0.56      0.57        52\n",
      "      uc0109       0.20      0.02      0.03        58\n",
      "      uc0110       0.50      0.17      0.26        63\n",
      "      uc0111       0.11      0.01      0.01      1182\n",
      "      uc0112       0.08      0.02      0.03        57\n",
      "      uc0113       0.00      0.00      0.00        70\n",
      "      uc0114       0.00      0.00      0.00       260\n",
      "      uc0115       0.24      0.09      0.13        79\n",
      "      uc0116       0.24      0.19      0.21        31\n",
      "      uc0117       0.47      0.73      0.58        26\n",
      "      uc0118       0.00      0.00      0.00        71\n",
      "      uc0124       0.41      0.11      0.17       772\n",
      "      uc0125       0.29      0.24      0.26       115\n",
      "      uc0126       0.30      0.02      0.03       727\n",
      "      uc0127       0.00      0.00      0.00         3\n",
      "      uc0128       0.00      0.00      0.00        25\n",
      "      uc0130       0.00      0.00      0.00        88\n",
      "      uc0131       0.26      0.02      0.04       631\n",
      "      uc0132       0.00      0.00      0.00         4\n",
      "      uc0133       0.00      0.00      0.00        13\n",
      "      uc0134       0.33      0.09      0.14       237\n",
      "      uc0135       0.00      0.00      0.00        75\n",
      "      uc0136       0.06      0.04      0.05        26\n",
      "      uc0137       0.00      0.00      0.00        34\n",
      "      uc0138       0.00      0.00      0.00        50\n",
      "      uc0139       0.31      0.14      0.20       431\n",
      "      uc0140       0.08      0.03      0.04        36\n",
      "      uc0141       0.36      0.56      0.43        18\n",
      "      uc0142       0.00      0.00      0.00         2\n",
      "      uc0146       0.17      0.12      0.14      1858\n",
      "      uc0147       0.00      0.00      0.00         7\n",
      "      uc0148       0.00      0.00      0.00         1\n",
      "      uc0149       0.41      0.11      0.18        80\n",
      "      uc0150       0.18      0.01      0.02       541\n",
      "      uc0153       0.22      0.20      0.21       118\n",
      "      uc0155       0.00      0.00      0.00         2\n",
      "      uc0156       0.00      0.00      0.00         8\n",
      "      uc0157       0.54      0.42      0.47       149\n",
      "      uc0158       0.22      0.08      0.11        26\n",
      "      uc0159       0.50      0.20      0.29        15\n",
      "      uc0161       0.00      0.00      0.00         7\n",
      "      uc0162       0.21      0.15      0.18      1069\n",
      "      uc0163       0.00      0.00      0.00         5\n",
      "      uc0164       0.00      0.00      0.00         2\n",
      "      uc0165       0.26      0.06      0.10       136\n",
      "      uc0167       0.00      0.00      0.00        25\n",
      "      uc0169       0.30      0.03      0.05       114\n",
      "      uc0171       0.00      0.00      0.00        31\n",
      "      uc0172       0.36      0.29      0.32        34\n",
      "      uc0173       0.00      0.00      0.00        16\n",
      "      uc0175       0.00      0.00      0.00         6\n",
      "      uc0178       0.00      0.00      0.00        64\n",
      "      uc0179       0.21      0.09      0.12      1158\n",
      "      uc0180       0.00      0.00      0.00        11\n",
      "      uc0181       0.15      0.02      0.04       482\n",
      "      uc0184       0.00      0.00      0.00         1\n",
      "      uc0186       0.13      0.04      0.06        47\n",
      "      uc0187       0.00      0.00      0.00        23\n",
      "      uc0189       0.23      0.15      0.18        46\n",
      "      uc0190       0.13      0.10      0.11        60\n",
      "      uc0191       0.00      0.00      0.00        25\n",
      "      uc0192       0.00      0.00      0.00        17\n",
      "      uc0193       0.17      0.08      0.11        53\n",
      "      uc0195       0.45      0.58      0.51        66\n",
      "      uc0197       0.21      0.18      0.19        38\n",
      "      uc0198       0.00      0.00      0.00       139\n",
      "      uc0199       0.00      0.00      0.00         1\n",
      "      uc0200       0.00      0.00      0.00         2\n",
      "      uc0201       0.00      0.00      0.00        24\n",
      "      uc0202       0.00      0.00      0.00         2\n",
      "      uc0206       0.00      0.00      0.00         1\n",
      "      uc0209       0.51      0.20      0.29       409\n",
      "      uc0211       0.12      0.03      0.05       298\n",
      "      uc0212       0.34      0.27      0.30       246\n",
      "      uc0215       0.27      0.07      0.11       647\n",
      "      uc0216       0.31      0.45      0.37       183\n",
      "      uc0217       0.00      0.00      0.00         6\n",
      "      uc0219       0.34      0.72      0.46       120\n",
      "      uc0220       0.52      0.51      0.51        89\n",
      "      uc0221       0.52      0.19      0.28        83\n",
      "      uc0222       0.34      0.28      0.31      1003\n",
      "      uc0223       0.38      0.15      0.21        20\n",
      "      uc0225       0.50      0.38      0.43        24\n",
      "      uc0226       0.45      0.73      0.55       235\n",
      "      uc0228       0.10      0.04      0.06        25\n",
      "      uc0229       0.30      0.29      0.30        94\n",
      "      uc0230       0.30      0.13      0.18        78\n",
      "      uc0232       0.37      0.40      0.39      2066\n",
      "      uc0233       0.00      0.00      0.00        27\n",
      "      uc0234       0.00      0.00      0.00        80\n",
      "      uc0235       0.00      0.00      0.00       300\n",
      "      uc0238       0.49      0.37      0.42        90\n",
      "      uc0240       0.00      0.00      0.00        42\n",
      "      uc0241       0.00      0.00      0.00        19\n",
      "      uc0242       0.00      0.00      0.00        28\n",
      "      uc0243       0.00      0.00      0.00        12\n",
      "      uc0244       0.00      0.00      0.00         3\n",
      "      uc0250       0.00      0.00      0.00         1\n",
      "      uc0253       0.00      0.00      0.00        28\n",
      "      uc0254       0.00      0.00      0.00         2\n",
      "      uc0255       0.00      0.00      0.00        11\n",
      "      uc0256       0.00      0.00      0.00        11\n",
      "      uc0264       0.00      0.00      0.00         4\n",
      "      uc0265       0.00      0.00      0.00        17\n",
      "      uc0266       0.00      0.00      0.00         5\n",
      "      uc1003       0.37      0.21      0.27       107\n",
      "      uc1004       0.00      0.00      0.00        64\n",
      "      uc1005       0.00      0.00      0.00         1\n",
      "      uc1006       0.25      0.03      0.05       120\n",
      "      uc1007       0.00      0.00      0.00        17\n",
      "      uc1008       0.00      0.00      0.00         8\n",
      "      uc1009       0.16      0.22      0.19        50\n",
      "      uc1010       0.43      0.57      0.49        70\n",
      "      uc1011       0.55      0.27      0.36        41\n",
      "      uc1012       0.22      0.16      0.19        31\n",
      "      uc1013       0.00      0.00      0.00        16\n",
      "      uc1014       0.06      0.03      0.04        39\n",
      "      uc1015       0.17      0.27      0.21        26\n",
      "      uc1016       0.00      0.00      0.00        48\n",
      "      uc1017       0.48      0.28      0.35       282\n",
      "      uc1018       0.00      0.00      0.00        10\n",
      "      uc1019       0.00      0.00      0.00         8\n",
      "      uc2001       0.00      0.00      0.00        13\n",
      "      uc2002       0.54      0.25      0.34        28\n",
      "      uc2005       0.89      0.80      0.84        10\n",
      "      uc2006       0.92      0.32      0.48        37\n",
      "      uc2007       0.00      0.00      0.00        10\n",
      "      uc2008       0.50      0.19      0.27        32\n",
      "      uc2009       0.00      0.00      0.00         1\n",
      "      uc2011       0.55      0.67      0.60         9\n",
      "      uc2012       0.55      0.50      0.52        12\n",
      "      uc2014       0.25      0.04      0.07        25\n",
      "      uc2017       0.00      0.00      0.00         9\n",
      "      uc2019       0.41      0.33      0.36        40\n",
      "      uc2020       0.76      0.25      0.38        63\n",
      "      uc2021       0.00      0.00      0.00         1\n",
      "      uc2023       0.25      0.11      0.16       184\n",
      "      uc2025       0.00      0.00      0.00        24\n",
      "      uc2026       0.00      0.00      0.00        11\n",
      "      uc2027       0.75      0.16      0.26        19\n",
      "      uc2028       0.82      1.00      0.90        18\n",
      "      uc2029       0.29      0.40      0.34       224\n",
      "      uc2030       0.71      0.52      0.60        29\n",
      "      uc2031       0.00      0.00      0.00         5\n",
      "      uc2032       0.00      0.00      0.00        10\n",
      "      uc2033       0.00      0.00      0.00        88\n",
      "      uc2034       0.00      0.00      0.00        36\n",
      "      uc2036       0.62      0.24      0.35        33\n",
      "      uc2037       0.40      0.10      0.16        20\n",
      "      uc2039       0.40      0.17      0.24        35\n",
      "      uc2040       0.00      0.00      0.00        18\n",
      "      uc2041       0.00      0.00      0.00        19\n",
      "      uc2043       1.00      0.41      0.58        17\n",
      "      uc2044       0.00      0.00      0.00         2\n",
      "      uc2045       0.25      0.39      0.30        33\n",
      "      uc2046       0.00      0.00      0.00        18\n",
      "      uc2048       0.37      0.50      0.42        14\n",
      "      uc2049       0.92      0.63      0.75        19\n",
      "      uc2051       0.00      0.00      0.00         1\n",
      "      uc2053       0.57      0.40      0.47        10\n",
      "      uc2054       0.00      0.00      0.00         2\n",
      "      uc2055       0.44      0.57      0.50        14\n",
      "      uc2056       0.77      0.45      0.57        22\n",
      "      uc2059       0.25      0.66      0.37       380\n",
      "      uc2060       0.00      0.00      0.00        15\n",
      "      uc2061       0.00      0.00      0.00        22\n",
      "      uc2062       0.67      0.33      0.44        24\n",
      "      uc2063       0.89      0.62      0.73        13\n",
      "      uc2064       0.67      0.11      0.20        35\n",
      "      uc2065       0.47      0.46      0.46        35\n",
      "      uc2066       0.43      0.15      0.22        66\n",
      "      uc2067       0.00      0.00      0.00        20\n",
      "      uc2068       0.00      0.00      0.00        12\n",
      "      uc2071       0.17      0.05      0.08        19\n",
      "      uc2072       0.00      0.00      0.00         9\n",
      "      uc2073       0.62      0.48      0.54        21\n",
      "      uc2074       0.00      0.00      0.00         3\n",
      "      uc2075       0.55      0.43      0.48        14\n",
      "      uc2076       0.00      0.00      0.00        12\n",
      "      uc2077       0.00      0.00      0.00        11\n",
      "      uc2078       0.74      0.45      0.56        31\n",
      "      uc2079       0.00      0.00      0.00         7\n",
      "      uc2081       0.00      0.00      0.00         1\n",
      "      uc2082       0.71      0.42      0.53        12\n",
      "      uc2083       0.00      0.00      0.00        16\n",
      "      uc2084       0.24      0.27      0.25        15\n",
      "      uc2085       0.00      0.00      0.00         1\n",
      "      uc2086       0.00      0.00      0.00         8\n",
      "      uc2092       0.00      0.00      0.00        31\n",
      "      uc2095       0.10      0.21      0.14        19\n",
      "      uc2096       0.33      0.10      0.15        20\n",
      "      uc2097       0.00      0.00      0.00         4\n",
      "      uc2101       0.60      0.86      0.71        14\n",
      "\n",
      "    accuracy                           0.28     42442\n",
      "   macro avg       0.20      0.14      0.15     42442\n",
      "weighted avg       0.26      0.28      0.23     42442\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Pipeline concluído com sucesso!\n",
      "Acurácia final: 28.01%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nIniciando pipeline de Machine Learning ...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Executar todo o pipeline principal\n",
    "modelo, historico, resultados = main(\n",
    "    data_path='../dados/processados/Dados_TechChallenge_Fase3.csv', \n",
    "    usuario='*',  \n",
    "    usuarios_exclusao=[\"usuario_00\", \"usuario_01\", \"usuario_02\", \"usuario_04\", \"usuario_06\", \"usuario_08\", \"usuario_11\", \"usuario_12\", \"usuario_13\"],\n",
    "    use_lstm=False,  \n",
    "    epochs=50,\n",
    "    plotar_resultado=False,\n",
    "    salvar_modelo=False\n",
    ")\n",
    "\n",
    "print(\"\\n\\n\\nPipeline concluído com sucesso!\")\n",
    "print(f\"Acurácia final: {resultados['accuracy']*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc11e1c",
   "metadata": {},
   "source": [
    "## Função listar_usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f1bd1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listar_usuarios(data_path):\n",
    "    \"\"\"\n",
    "    retornar todos os usuários do arquivo\n",
    "    \n",
    "    Args:\n",
    "        data_path: Caminho para o arquivo CSV\n",
    "    \n",
    "    Returns:\n",
    "        list: Nomes de todos os usuários do arquivo\n",
    "    \"\"\"\n",
    "    print(\"=== OBTENDO USUÁRIOS DO ARQUIVO ===\")\n",
    "    \n",
    "    # Carregar dados\n",
    "    df = pd.read_csv(\n",
    "        data_path, \n",
    "        sep=';', \n",
    "        encoding='utf-8', \n",
    "        parse_dates=['DataHoraCriacao'], \n",
    "        dayfirst=True\n",
    "    )\n",
    "    \n",
    "    return df['usuario'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c92012a",
   "metadata": {},
   "source": [
    "## Função analisar_distribuicao_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "557862bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisar_distribuicao_classes(serie_y, username):\n",
    "    \"\"\"\n",
    "    Analisa a distribuição das classes para o usuário\n",
    "    \n",
    "    Args:\n",
    "        serie_y: Série com os targets\n",
    "        username: Nome do usuário\n",
    "    \n",
    "    Returns:\n",
    "        dict: Estatísticas das classes\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== ANÁLISE DE CLASSES PARA {username} ===\")\n",
    "    \n",
    "    class_counts = serie_y.value_counts()\n",
    "    print(f\"Total de classes: {len(class_counts)}\")\n",
    "    print(f\"Total de amostras: {len(serie_y)}\")\n",
    "    print(f\"Média de amostras por classe: {class_counts.mean():.1f}\")\n",
    "    print(f\"Mediana de amostras por classe: {class_counts.median():.1f}\")\n",
    "    \n",
    "    # Classes com poucas amostras\n",
    "    classes_com_1_amostra = class_counts[class_counts == 1]\n",
    "    classes_com_2_5_amostras = class_counts[(class_counts >= 2) & (class_counts <= 5)]\n",
    "    \n",
    "    print(f\"\\nClasses com 1 amostra: {len(classes_com_1_amostra)}\")\n",
    "    print(f\"Classes com 2-5 amostras: {len(classes_com_2_5_amostras)}\")\n",
    "    print(f\"Classes com 6+ amostras: {len(class_counts[class_counts > 5])}\")\n",
    "    \n",
    "    if len(classes_com_1_amostra) > 0:\n",
    "        print(f\"\\n⚠️ Classes problemáticas (1 amostra):\")\n",
    "        print(classes_com_1_amostra.head(10))\n",
    "    \n",
    "    # Top classes\n",
    "    print(f\"\\n📊 Top 10 classes mais frequentes:\")\n",
    "    print(class_counts.head(10))\n",
    "    \n",
    "    return {\n",
    "        'total_classes': len(class_counts),\n",
    "        'total_samples': len(serie_y),\n",
    "        'classes_with_one_sample': len(classes_com_1_amostra),\n",
    "        'class_counts': class_counts\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af5b796",
   "metadata": {},
   "source": [
    "## Função recomendar_usuarios\n",
    "\n",
    "Analisa a quantidade de amostras e de classes(casos de uso) envolvidas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3131f2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendar_usuarios(data_path, min_amostras=50, min_classes=5):\n",
    "    \"\"\"\n",
    "    Analisa todos os usuários e recomenda os melhores para treinamento\n",
    "    \n",
    "    Args:\n",
    "        data_path: Caminho para o arquivo CSV\n",
    "        min_amostras: Número mínimo de amostras por usuário\n",
    "        min_classes: Número mínimo de classes diferentes por usuário\n",
    "    \n",
    "    Returns:\n",
    "        list: Lista de usuários recomendados ordenados por qualidade\n",
    "    \"\"\"\n",
    "    print(\"=== ANALISANDO USUÁRIOS PARA RECOMENDAÇÃO ===\")\n",
    "    \n",
    "    # Carregar dados\n",
    "    df = pd.read_csv(\n",
    "        data_path, \n",
    "        sep=';', \n",
    "        encoding='utf-8', \n",
    "        parse_dates=['DataHoraCriacao'], \n",
    "        dayfirst=True\n",
    "    )\n",
    "    \n",
    "    usuarios_stats = []\n",
    "    \n",
    "    for usuario in df['usuario'].unique():\n",
    "        df_user = df[df['usuario'] == usuario]\n",
    "        class_counts = df_user['casoDeUso'].value_counts()\n",
    "        \n",
    "        # Calcular métricas de qualidade\n",
    "        total_amostras = len(df_user)\n",
    "        total_classes = len(class_counts)\n",
    "        classes_com_uma_amostra = len(class_counts[class_counts == 1])\n",
    "        classes_com_multiplas_amostras = len(class_counts[class_counts > 1])\n",
    "        media_amostras_por_classe = class_counts.mean()\n",
    "        balanceamento = 1 - (class_counts.std() / class_counts.mean()) if class_counts.mean() > 0 else 0\n",
    "        \n",
    "        # Score de qualidade (0-1, onde 1 é melhor)\n",
    "        score_amostras = min(total_amostras / 200, 1.0)  # Normaliza até 200 amostras\n",
    "        score_classes = min(total_classes / 20, 1.0)  # Normaliza até 20 classes\n",
    "        score_balanceamento = max(0, balanceamento)  # Evita valores negativos\n",
    "        score_sem_singletons = classes_com_multiplas_amostras / total_classes if total_classes > 0 else 0\n",
    "        \n",
    "        # Score final ponderado\n",
    "        score_final = (\n",
    "            0.3 * score_amostras + \n",
    "            0.3 * score_classes + \n",
    "            0.2 * score_balanceamento + \n",
    "            0.2 * score_sem_singletons\n",
    "        )\n",
    "        \n",
    "        usuarios_stats.append({\n",
    "            'usuario': usuario,\n",
    "            'total_amostras': total_amostras,\n",
    "            'total_classes': total_classes,\n",
    "            'classes_com_uma_amostra': classes_com_uma_amostra,\n",
    "            'classes_com_multiplas_amostras': classes_com_multiplas_amostras,\n",
    "            'media_amostras_por_classe': media_amostras_por_classe,\n",
    "            'balanceamento': balanceamento,\n",
    "            'score_final': score_final\n",
    "        })\n",
    "    \n",
    "    # Ordenar por score final\n",
    "    usuarios_stats.sort(key=lambda x: x['score_final'], reverse=True)\n",
    "    \n",
    "    # Filtrar usuários que atendem critérios mínimos\n",
    "    usuarios_validos = [\n",
    "        u for u in usuarios_stats \n",
    "        if u['total_amostras'] >= min_amostras and u['total_classes'] >= min_classes\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n📊 Top 10 usuários recomendados:\")\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"{'Usuário':<12} {'Amostras':<9} {'Classes':<8} {'Singleton':<10} {'Score':<8} {'Qualidade'}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for i, user_stats in enumerate(usuarios_validos[:10]):\n",
    "        qualidade = \"Excelente\" if user_stats['score_final'] > 0.7 else \"Boa\" if user_stats['score_final'] > 0.5 else \"Regular\"\n",
    "        print(f\"{user_stats['usuario']:<12} {user_stats['total_amostras']:<9} {user_stats['total_classes']:<8} \"\n",
    "              f\"{user_stats['classes_com_uma_amostra']:<10} {user_stats['score_final']:.3f}     {qualidade}\")\n",
    "    \n",
    "    if not usuarios_validos:\n",
    "        print(\"⚠️ Nenhum usuário atende os critérios mínimos especificados.\")\n",
    "        return usuarios_stats[:5]  # Retorna os 5 melhores mesmo que não atendam critérios\n",
    "    \n",
    "    return usuarios_validos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7168b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "recomendar_usuarios(data_path='../dados/processados/Dados_TechChallenge_Fase3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa838283",
   "metadata": {},
   "source": [
    "## Comparando treino por usuário\n",
    "\n",
    "Realiza o treino para cada usuário e compara qual usuário tem melhores condições de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67663cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Iniciando pipeline de Machine Learning melhorado...\n",
      "============================================================\n",
      "=== OBTENDO USUÁRIOS DO ARQUIVO ===\n",
      "Usuários encontrados: ['usuario_00' 'usuario_01' 'usuario_02' 'usuario_03' 'usuario_04'\n",
      " 'usuario_05' 'usuario_06' 'usuario_07' 'usuario_08' 'usuario_09'\n",
      " 'usuario_10' 'usuario_11' 'usuario_12' 'usuario_13' 'usuario_14'\n",
      " 'usuario_15' 'usuario_16']\n",
      "============================================================\n",
      "\n",
      "🔄 Processando usuário 1/17: usuario_00\n",
      "----------------------------------------\n",
      "=== INICIANDO PREPROCESSAMENTO ===\n",
      "Carregando dados de: ../dados/processados/Dados_TechChallenge_Fase3.csv\n",
      "Dataset carregado: (115591, 7)\n",
      "\n",
      "Distribuição das classes:\n",
      "casoDeUso\n",
      "uc0043    13099\n",
      "uc0232     7408\n",
      "uc0096     7042\n",
      "uc0146     5042\n",
      "uc0075     3394\n",
      "uc0222     3085\n",
      "uc0162     3018\n",
      "uc0111     2963\n",
      "uc0179     2896\n",
      "uc0069     2620\n",
      "Name: count, dtype: int64\n",
      "Processando dados para usuário: usuario_00\n",
      "Registros após filtro de usuário: 717\n",
      "Criando features históricas...\n",
      "Registros após limpeza: 717\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso_1', 'casoDeUso_2']\n",
      "Processando features contextuais...\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "Normalizando features sequenciais...\n",
      "Dividindo dados em treino e teste...\n",
      "⚠️ Aviso: 8 classes com apenas 1 amostra:\n",
      "casoDeUso\n",
      "uc2054    1\n",
      "uc2044    1\n",
      "uc2021    1\n",
      "uc2041    1\n",
      "uc2051    1\n",
      "Name: count, dtype: int64\n",
      "Removendo classes com poucas amostras para permitir estratificação...\n",
      "Dados após filtro: 709 amostras, 61 classes\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "✅ Divisão estratificada realizada com sucesso\n",
      "Treino: 425 samples\n",
      "Teste: 284 samples\n",
      "=== CRIANDO MODELO DENSE HÍBRIDO ===\n",
      "Usando Dense layers: [128, 64]\n",
      "Modelo criado e compilado!\n",
      "Parâmetros totais: 30,074\n",
      "\n",
      "\n",
      "=== ARQUITETURA DO MODELO ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">138</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">17,792</span> │ input_sequence[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ input_epoch[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,026</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m138\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m17,792\u001b[0m │ input_sequence[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ input_epoch[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m)        │      \u001b[38;5;34m4,026\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,074</span> (117.48 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m30,074\u001b[0m (117.48 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,074</span> (117.48 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30,074\u001b[0m (117.48 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INICIANDO TREINAMENTO ===\n",
      "Epoch 1/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.0167 - loss: 4.4651  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 21:42:21.726435: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_63', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-05-25 21:42:21.779820: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_63', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 292ms/step - accuracy: 0.0170 - loss: 4.4586 - val_accuracy: 0.0118 - val_loss: 4.2914 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0409 - loss: 4.0891 - val_accuracy: 0.0471 - val_loss: 4.1633 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0957 - loss: 3.7989 - val_accuracy: 0.0706 - val_loss: 4.0973 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1700 - loss: 3.6825 - val_accuracy: 0.0824 - val_loss: 4.0495 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1645 - loss: 3.5497 - val_accuracy: 0.0824 - val_loss: 4.0125 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2422 - loss: 3.3640 - val_accuracy: 0.0941 - val_loss: 3.9865 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2547 - loss: 3.2162 - val_accuracy: 0.1059 - val_loss: 3.9651 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2394 - loss: 3.1463 - val_accuracy: 0.1059 - val_loss: 3.9548 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3071 - loss: 2.9859 - val_accuracy: 0.1176 - val_loss: 3.9499 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3130 - loss: 2.8195 - val_accuracy: 0.0941 - val_loss: 3.9308 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2789 - loss: 2.9099 - val_accuracy: 0.1176 - val_loss: 3.9060 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3375 - loss: 2.7012 - val_accuracy: 0.1294 - val_loss: 3.8946 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2982 - loss: 2.6856 - val_accuracy: 0.1294 - val_loss: 3.9132 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3768 - loss: 2.4759 - val_accuracy: 0.1412 - val_loss: 3.9026 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3892 - loss: 2.4605 - val_accuracy: 0.1412 - val_loss: 3.9050 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3685 - loss: 2.4142 - val_accuracy: 0.1529 - val_loss: 3.8955 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4389 - loss: 2.1826 - val_accuracy: 0.1647 - val_loss: 3.8936 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4024 - loss: 2.2299 - val_accuracy: 0.1647 - val_loss: 3.8994 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4366 - loss: 2.1968 - val_accuracy: 0.1647 - val_loss: 3.9084 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4247 - loss: 2.1016 - val_accuracy: 0.1647 - val_loss: 3.9222 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4485 - loss: 2.0391 - val_accuracy: 0.1529 - val_loss: 3.9206 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5000 - loss: 1.8169\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4643 - loss: 1.9599 - val_accuracy: 0.1647 - val_loss: 3.9292 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4816 - loss: 1.9011 - val_accuracy: 0.1647 - val_loss: 3.9380 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5053 - loss: 1.8276 - val_accuracy: 0.1647 - val_loss: 3.9407 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4885 - loss: 1.9440 - val_accuracy: 0.1647 - val_loss: 3.9529 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4805 - loss: 1.9415 - val_accuracy: 0.1765 - val_loss: 3.9603 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3750 - loss: 2.0093\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4578 - loss: 1.8539 - val_accuracy: 0.1647 - val_loss: 3.9687 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5334 - loss: 1.7382 - val_accuracy: 0.1647 - val_loss: 3.9742 - learning_rate: 2.5000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5264 - loss: 1.7907 - val_accuracy: 0.1647 - val_loss: 3.9761 - learning_rate: 2.5000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5154 - loss: 1.7714 - val_accuracy: 0.1647 - val_loss: 3.9886 - learning_rate: 2.5000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5556 - loss: 1.7670 - val_accuracy: 0.1647 - val_loss: 4.0023 - learning_rate: 2.5000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6250 - loss: 1.5519\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5015 - loss: 1.7921 - val_accuracy: 0.1765 - val_loss: 4.0057 - learning_rate: 2.5000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5127 - loss: 1.7645 - val_accuracy: 0.1765 - val_loss: 4.0086 - learning_rate: 1.2500e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4986 - loss: 1.8482 - val_accuracy: 0.1765 - val_loss: 4.0109 - learning_rate: 1.2500e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5269 - loss: 1.7037 - val_accuracy: 0.1765 - val_loss: 4.0129 - learning_rate: 1.2500e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5940 - loss: 1.6793 - val_accuracy: 0.1765 - val_loss: 4.0146 - learning_rate: 1.2500e-04\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Treinamento concluído!\n",
      "=== AVALIANDO MODELO ===\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 21:42:26.336109: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_18', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-05-25 21:42:26.352537: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_18', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step\n",
      "Acurácia: 21.83%\n",
      "\n",
      "=== RELATÓRIO DE CLASSIFICAÇÃO ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      uc0212       0.00      0.00      0.00         4\n",
      "      uc0232       0.00      0.00      0.00         4\n",
      "      uc2001       0.00      0.00      0.00         2\n",
      "      uc2002       0.17      0.17      0.17         6\n",
      "      uc2005       0.00      0.00      0.00         1\n",
      "      uc2006       0.00      0.00      0.00         4\n",
      "      uc2007       0.00      0.00      0.00         1\n",
      "      uc2008       0.00      0.00      0.00         4\n",
      "      uc2011       0.00      0.00      0.00         1\n",
      "      uc2012       0.00      0.00      0.00         2\n",
      "      uc2014       0.67      0.80      0.73         5\n",
      "      uc2019       0.11      0.20      0.14        10\n",
      "      uc2020       0.22      0.17      0.19        12\n",
      "      uc2023       0.15      0.18      0.17        11\n",
      "      uc2025       0.00      0.00      0.00         4\n",
      "      uc2026       0.00      0.00      0.00         1\n",
      "      uc2027       0.00      0.00      0.00         1\n",
      "      uc2028       1.00      0.67      0.80         3\n",
      "      uc2029       0.32      0.27      0.29        22\n",
      "      uc2030       0.00      0.00      0.00         3\n",
      "      uc2032       0.00      0.00      0.00         1\n",
      "      uc2033       0.67      0.33      0.44         6\n",
      "      uc2034       0.00      0.00      0.00         2\n",
      "      uc2036       0.10      0.17      0.12         6\n",
      "      uc2037       0.00      0.00      0.00         1\n",
      "      uc2039       0.00      0.00      0.00         9\n",
      "      uc2040       0.00      0.00      0.00         3\n",
      "      uc2043       0.00      0.00      0.00         4\n",
      "      uc2045       0.00      0.00      0.00         6\n",
      "      uc2046       0.00      0.00      0.00         2\n",
      "      uc2048       0.00      0.00      0.00         2\n",
      "      uc2049       0.33      0.50      0.40         2\n",
      "      uc2053       0.00      0.00      0.00         2\n",
      "      uc2055       0.25      0.50      0.33         2\n",
      "      uc2056       0.00      0.00      0.00         4\n",
      "      uc2059       0.24      0.62      0.35        45\n",
      "      uc2060       0.00      0.00      0.00         1\n",
      "      uc2062       0.25      0.33      0.29         6\n",
      "      uc2063       0.00      0.00      0.00         3\n",
      "      uc2064       0.00      0.00      0.00         5\n",
      "      uc2065       0.25      0.25      0.25         4\n",
      "      uc2066       0.00      0.00      0.00         9\n",
      "      uc2067       0.00      0.00      0.00         2\n",
      "      uc2068       0.00      0.00      0.00         2\n",
      "      uc2071       0.00      0.00      0.00         2\n",
      "      uc2072       0.50      0.25      0.33         4\n",
      "      uc2073       0.00      0.00      0.00         2\n",
      "      uc2074       0.00      0.00      0.00         1\n",
      "      uc2075       1.00      0.50      0.67         4\n",
      "      uc2076       0.00      0.00      0.00         2\n",
      "      uc2077       0.00      0.00      0.00         2\n",
      "      uc2078       1.00      0.17      0.29         6\n",
      "      uc2082       0.33      1.00      0.50         1\n",
      "      uc2083       0.00      0.00      0.00         3\n",
      "      uc2084       0.00      0.00      0.00         2\n",
      "      uc2086       0.00      0.00      0.00         2\n",
      "      uc2092       0.17      0.12      0.14        16\n",
      "      uc2095       0.00      0.00      0.00         4\n",
      "      uc2096       0.00      0.00      0.00         1\n",
      "      uc2098       0.00      0.00      0.00         1\n",
      "      uc2100       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.22       284\n",
      "   macro avg       0.13      0.12      0.11       284\n",
      "weighted avg       0.19      0.22      0.18       284\n",
      "\n",
      "🔍 Debug - Tipo de 'results': <class 'dict'>\n",
      "🔍 Debug - Chaves disponíveis: ['accuracy', 'y_pred', 'y_test', 'confusion_matrix', 'class_names', 'y_pred_proba']\n",
      "✅ Usuário usuario_00 processado com sucesso!\n",
      "\n",
      "🔄 Processando usuário 2/17: usuario_01\n",
      "----------------------------------------\n",
      "=== INICIANDO PREPROCESSAMENTO ===\n",
      "Carregando dados de: ../dados/processados/Dados_TechChallenge_Fase3.csv\n",
      "Dataset carregado: (115591, 7)\n",
      "\n",
      "Distribuição das classes:\n",
      "casoDeUso\n",
      "uc0043    13099\n",
      "uc0232     7408\n",
      "uc0096     7042\n",
      "uc0146     5042\n",
      "uc0075     3394\n",
      "uc0222     3085\n",
      "uc0162     3018\n",
      "uc0111     2963\n",
      "uc0179     2896\n",
      "uc0069     2620\n",
      "Name: count, dtype: int64\n",
      "Processando dados para usuário: usuario_01\n",
      "Registros após filtro de usuário: 1601\n",
      "Criando features históricas...\n",
      "Registros após limpeza: 1601\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso_1', 'casoDeUso_2']\n",
      "Processando features contextuais...\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "Normalizando features sequenciais...\n",
      "Dividindo dados em treino e teste...\n",
      "⚠️ Aviso: 2 classes com apenas 1 amostra:\n",
      "casoDeUso\n",
      "uc0187    1\n",
      "uc0193    1\n",
      "Name: count, dtype: int64\n",
      "Removendo classes com poucas amostras para permitir estratificação...\n",
      "Dados após filtro: 1599 amostras, 15 classes\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "✅ Divisão estratificada realizada com sucesso\n",
      "Treino: 959 samples\n",
      "Teste: 640 samples\n",
      "=== CRIANDO MODELO DENSE HÍBRIDO ===\n",
      "Usando Dense layers: [128, 64]\n",
      "Modelo criado e compilado!\n",
      "Parâmetros totais: 13,982\n",
      "\n",
      "\n",
      "=== ARQUITETURA DO MODELO ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,736</span> │ input_sequence[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ input_epoch[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">990</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m4,736\u001b[0m │ input_sequence[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ input_epoch[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        │        \u001b[38;5;34m990\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,982</span> (54.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,982\u001b[0m (54.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,982</span> (54.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,982\u001b[0m (54.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INICIANDO TREINAMENTO ===\n",
      "Epoch 1/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 0.1003 - loss: 2.8082 - val_accuracy: 0.4479 - val_loss: 2.1051 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4078 - loss: 2.0889 - val_accuracy: 0.4531 - val_loss: 1.7305 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4759 - loss: 1.7227 - val_accuracy: 0.5208 - val_loss: 1.5569 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5478 - loss: 1.5151 - val_accuracy: 0.5573 - val_loss: 1.4780 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6044 - loss: 1.4730 - val_accuracy: 0.5469 - val_loss: 1.4439 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5504 - loss: 1.4722 - val_accuracy: 0.5521 - val_loss: 1.4187 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5713 - loss: 1.4023 - val_accuracy: 0.5521 - val_loss: 1.4074 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6257 - loss: 1.2412 - val_accuracy: 0.5417 - val_loss: 1.4131 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5749 - loss: 1.3400 - val_accuracy: 0.5469 - val_loss: 1.3967 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5660 - loss: 1.3203 - val_accuracy: 0.5573 - val_loss: 1.3972 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5723 - loss: 1.3027 - val_accuracy: 0.5677 - val_loss: 1.3982 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6052 - loss: 1.2819 - val_accuracy: 0.5677 - val_loss: 1.3939 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5763 - loss: 1.2725 - val_accuracy: 0.5521 - val_loss: 1.3976 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6104 - loss: 1.2130 - val_accuracy: 0.5521 - val_loss: 1.4038 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5863 - loss: 1.2511 - val_accuracy: 0.5469 - val_loss: 1.4009 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5546 - loss: 1.3127 - val_accuracy: 0.5521 - val_loss: 1.3966 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m 1/24\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6562 - loss: 1.3332\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6183 - loss: 1.2050 - val_accuracy: 0.5469 - val_loss: 1.4024 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5934 - loss: 1.2315 - val_accuracy: 0.5469 - val_loss: 1.4039 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6047 - loss: 1.2200 - val_accuracy: 0.5469 - val_loss: 1.4026 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5771 - loss: 1.2170 - val_accuracy: 0.5521 - val_loss: 1.4012 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5657 - loss: 1.2566 - val_accuracy: 0.5521 - val_loss: 1.4026 - learning_rate: 5.0000e-04\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Treinamento concluído!\n",
      "=== AVALIANDO MODELO ===\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "Acurácia: 57.03%\n",
      "\n",
      "=== RELATÓRIO DE CLASSIFICAÇÃO ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      uc0043       0.54      0.41      0.47        17\n",
      "      uc0111       0.00      0.00      0.00         2\n",
      "      uc0131       0.00      0.00      0.00         8\n",
      "      uc0142       1.00      1.00      1.00         1\n",
      "      uc0146       0.25      0.27      0.26        48\n",
      "      uc0162       0.23      0.43      0.30        61\n",
      "      uc0169       0.00      0.00      0.00        12\n",
      "      uc0181       0.67      0.07      0.12        29\n",
      "      uc0221       0.00      0.00      0.00         2\n",
      "      uc0222       0.63      0.35      0.45        63\n",
      "      uc0232       0.72      0.91      0.80       253\n",
      "      uc0235       0.26      0.10      0.15        77\n",
      "      uc0238       0.76      0.89      0.82        57\n",
      "      uc1003       0.00      0.00      0.00         3\n",
      "      uc1017       0.86      0.86      0.86         7\n",
      "\n",
      "    accuracy                           0.57       640\n",
      "   macro avg       0.39      0.35      0.35       640\n",
      "weighted avg       0.54      0.57      0.53       640\n",
      "\n",
      "🔍 Debug - Tipo de 'results': <class 'dict'>\n",
      "🔍 Debug - Chaves disponíveis: ['accuracy', 'y_pred', 'y_test', 'confusion_matrix', 'class_names', 'y_pred_proba']\n",
      "✅ Usuário usuario_01 processado com sucesso!\n",
      "\n",
      "🔄 Processando usuário 3/17: usuario_02\n",
      "----------------------------------------\n",
      "=== INICIANDO PREPROCESSAMENTO ===\n",
      "Carregando dados de: ../dados/processados/Dados_TechChallenge_Fase3.csv\n",
      "Dataset carregado: (115591, 7)\n",
      "\n",
      "Distribuição das classes:\n",
      "casoDeUso\n",
      "uc0043    13099\n",
      "uc0232     7408\n",
      "uc0096     7042\n",
      "uc0146     5042\n",
      "uc0075     3394\n",
      "uc0222     3085\n",
      "uc0162     3018\n",
      "uc0111     2963\n",
      "uc0179     2896\n",
      "uc0069     2620\n",
      "Name: count, dtype: int64\n",
      "Processando dados para usuário: usuario_02\n",
      "Registros após filtro de usuário: 126\n",
      "Criando features históricas...\n",
      "Registros após limpeza: 126\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso_1', 'casoDeUso_2']\n",
      "Processando features contextuais...\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "Normalizando features sequenciais...\n",
      "Dividindo dados em treino e teste...\n",
      "✅ Divisão estratificada realizada com sucesso\n",
      "Treino: 75 samples\n",
      "Teste: 51 samples\n",
      "=== CRIANDO MODELO DENSE HÍBRIDO ===\n",
      "Usando Dense layers: [128, 64]\n",
      "Modelo criado e compilado!\n",
      "Parâmetros totais: 9,028\n",
      "\n",
      "\n",
      "=== ARQUITETURA DO MODELO ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ input_sequence[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ input_epoch[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m640\u001b[0m │ input_sequence[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ input_epoch[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │        \u001b[38;5;34m132\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,028</span> (35.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,028\u001b[0m (35.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,028</span> (35.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,028\u001b[0m (35.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INICIANDO TREINAMENTO ===\n",
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.5549 - loss: 0.6767 - val_accuracy: 0.4667 - val_loss: 0.6875 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6083 - loss: 0.6790 - val_accuracy: 0.4667 - val_loss: 0.6857 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6208 - loss: 0.6847 - val_accuracy: 0.4667 - val_loss: 0.6857 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6417 - loss: 0.6745 - val_accuracy: 0.4667 - val_loss: 0.6865 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6313 - loss: 0.6604 - val_accuracy: 0.4667 - val_loss: 0.6901 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6625 - loss: 0.6717 - val_accuracy: 0.4667 - val_loss: 0.6936 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5938 - loss: 0.6598\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6424 - loss: 0.6536 - val_accuracy: 0.4667 - val_loss: 0.6977 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6417 - loss: 0.6857 - val_accuracy: 0.4667 - val_loss: 0.6997 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6417 - loss: 0.6660 - val_accuracy: 0.4667 - val_loss: 0.7011 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5993 - loss: 0.6725 - val_accuracy: 0.4667 - val_loss: 0.7023 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6736 - loss: 0.6273 - val_accuracy: 0.4667 - val_loss: 0.7038 - learning_rate: 5.0000e-04\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Treinamento concluído!\n",
      "=== AVALIANDO MODELO ===\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 21:42:38.005909: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_18', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-05-25 21:42:38.015104: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_18', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 62.75%\n",
      "\n",
      "=== RELATÓRIO DE CLASSIFICAÇÃO ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      uc0232       0.00      0.00      0.00        19\n",
      "      uc2057       0.63      1.00      0.77        32\n",
      "\n",
      "    accuracy                           0.63        51\n",
      "   macro avg       0.31      0.50      0.39        51\n",
      "weighted avg       0.39      0.63      0.48        51\n",
      "\n",
      "🔍 Debug - Tipo de 'results': <class 'dict'>\n",
      "🔍 Debug - Chaves disponíveis: ['accuracy', 'y_pred', 'y_test', 'confusion_matrix', 'class_names', 'y_pred_proba']\n",
      "✅ Usuário usuario_02 processado com sucesso!\n",
      "\n",
      "🔄 Processando usuário 4/17: usuario_03\n",
      "----------------------------------------\n",
      "=== INICIANDO PREPROCESSAMENTO ===\n",
      "Carregando dados de: ../dados/processados/Dados_TechChallenge_Fase3.csv\n",
      "Dataset carregado: (115591, 7)\n",
      "\n",
      "Distribuição das classes:\n",
      "casoDeUso\n",
      "uc0043    13099\n",
      "uc0232     7408\n",
      "uc0096     7042\n",
      "uc0146     5042\n",
      "uc0075     3394\n",
      "uc0222     3085\n",
      "uc0162     3018\n",
      "uc0111     2963\n",
      "uc0179     2896\n",
      "uc0069     2620\n",
      "Name: count, dtype: int64\n",
      "Processando dados para usuário: usuario_03\n",
      "Registros após filtro de usuário: 21832\n",
      "Criando features históricas...\n",
      "Registros após limpeza: 21832\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso_1', 'casoDeUso_2']\n",
      "Processando features contextuais...\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "Normalizando features sequenciais...\n",
      "Dividindo dados em treino e teste...\n",
      "⚠️ Aviso: 10 classes com apenas 1 amostra:\n",
      "casoDeUso\n",
      "uc0184    1\n",
      "uc0142    1\n",
      "uc0185    1\n",
      "uc0207    1\n",
      "uc0206    1\n",
      "Name: count, dtype: int64\n",
      "Removendo classes com poucas amostras para permitir estratificação...\n",
      "Dados após filtro: 21822 amostras, 179 classes\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "✅ Divisão estratificada realizada com sucesso\n",
      "Treino: 13093 samples\n",
      "Teste: 8729 samples\n",
      "=== CRIANDO MODELO DENSE HÍBRIDO ===\n",
      "Usando Dense layers: [128, 64]\n",
      "Modelo criado e compilado!\n",
      "Parâmetros totais: 68,710\n",
      "\n",
      "\n",
      "=== ARQUITETURA DO MODELO ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">379</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">48,640</span> │ input_sequence[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ input_epoch[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">179</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">11,814</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m379\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m48,640\u001b[0m │ input_sequence[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ input_epoch[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m179\u001b[0m)       │     \u001b[38;5;34m11,814\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,710</span> (268.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m68,710\u001b[0m (268.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,710</span> (268.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m68,710\u001b[0m (268.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INICIANDO TREINAMENTO ===\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 21:42:40.651348: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1111', 172 bytes spill stores, 172 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1084 - loss: 4.5565"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 21:42:45.169337: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_63', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-05-25 21:42:45.192478: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_63', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.1085 - loss: 4.5551 - val_accuracy: 0.2092 - val_loss: 3.6404 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2067 - loss: 3.5613 - val_accuracy: 0.2390 - val_loss: 3.4767 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2361 - loss: 3.3758 - val_accuracy: 0.2444 - val_loss: 3.3914 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2510 - loss: 3.2799 - val_accuracy: 0.2493 - val_loss: 3.3659 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2604 - loss: 3.1958 - val_accuracy: 0.2512 - val_loss: 3.3302 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2663 - loss: 3.1270 - val_accuracy: 0.2562 - val_loss: 3.3227 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2708 - loss: 3.1011 - val_accuracy: 0.2539 - val_loss: 3.3267 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2776 - loss: 3.0508 - val_accuracy: 0.2524 - val_loss: 3.3280 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2673 - loss: 3.0433 - val_accuracy: 0.2528 - val_loss: 3.3359 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2860 - loss: 2.9437 - val_accuracy: 0.2547 - val_loss: 3.3414 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m306/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2774 - loss: 2.9694\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2774 - loss: 2.9695 - val_accuracy: 0.2532 - val_loss: 3.3417 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2776 - loss: 2.9077 - val_accuracy: 0.2570 - val_loss: 3.3475 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2977 - loss: 2.8810 - val_accuracy: 0.2562 - val_loss: 3.3531 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2851 - loss: 2.8532 - val_accuracy: 0.2619 - val_loss: 3.3609 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2980 - loss: 2.8666 - val_accuracy: 0.2596 - val_loss: 3.3640 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m313/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3012 - loss: 2.8180\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3011 - loss: 2.8193 - val_accuracy: 0.2570 - val_loss: 3.3686 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2990 - loss: 2.8197 - val_accuracy: 0.2577 - val_loss: 3.3776 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2992 - loss: 2.7896 - val_accuracy: 0.2589 - val_loss: 3.3748 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2940 - loss: 2.8107 - val_accuracy: 0.2623 - val_loss: 3.3823 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3062 - loss: 2.7658 - val_accuracy: 0.2612 - val_loss: 3.3789 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m316/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2990 - loss: 2.7992\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2991 - loss: 2.7992 - val_accuracy: 0.2612 - val_loss: 3.3836 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2977 - loss: 2.7950 - val_accuracy: 0.2604 - val_loss: 3.3865 - learning_rate: 1.2500e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3100 - loss: 2.7620 - val_accuracy: 0.2616 - val_loss: 3.3898 - learning_rate: 1.2500e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2978 - loss: 2.7856 - val_accuracy: 0.2616 - val_loss: 3.3961 - learning_rate: 1.2500e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3002 - loss: 2.7862 - val_accuracy: 0.2562 - val_loss: 3.3996 - learning_rate: 1.2500e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m313/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3003 - loss: 2.7634\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3003 - loss: 2.7640 - val_accuracy: 0.2589 - val_loss: 3.4019 - learning_rate: 1.2500e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3100 - loss: 2.7438 - val_accuracy: 0.2593 - val_loss: 3.4051 - learning_rate: 6.2500e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3045 - loss: 2.7370 - val_accuracy: 0.2627 - val_loss: 3.4078 - learning_rate: 6.2500e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3087 - loss: 2.7486 - val_accuracy: 0.2627 - val_loss: 3.4081 - learning_rate: 6.2500e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3031 - loss: 2.7621 - val_accuracy: 0.2635 - val_loss: 3.4071 - learning_rate: 6.2500e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m305/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3140 - loss: 2.7630\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3139 - loss: 2.7631 - val_accuracy: 0.2623 - val_loss: 3.4086 - learning_rate: 6.2500e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3085 - loss: 2.7607 - val_accuracy: 0.2623 - val_loss: 3.4091 - learning_rate: 3.1250e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3057 - loss: 2.7561 - val_accuracy: 0.2627 - val_loss: 3.4091 - learning_rate: 3.1250e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3077 - loss: 2.7542 - val_accuracy: 0.2619 - val_loss: 3.4101 - learning_rate: 3.1250e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3085 - loss: 2.7761 - val_accuracy: 0.2612 - val_loss: 3.4104 - learning_rate: 3.1250e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m318/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3013 - loss: 2.7767\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3015 - loss: 2.7762 - val_accuracy: 0.2604 - val_loss: 3.4108 - learning_rate: 3.1250e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3041 - loss: 2.7534 - val_accuracy: 0.2604 - val_loss: 3.4115 - learning_rate: 1.5625e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3108 - loss: 2.7053 - val_accuracy: 0.2604 - val_loss: 3.4125 - learning_rate: 1.5625e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3061 - loss: 2.7673 - val_accuracy: 0.2616 - val_loss: 3.4126 - learning_rate: 1.5625e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3104 - loss: 2.7639 - val_accuracy: 0.2616 - val_loss: 3.4125 - learning_rate: 1.5625e-05\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Treinamento concluído!\n",
      "=== AVALIANDO MODELO ===\n",
      "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 21:43:24.188794: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_18', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-05-25 21:43:24.196232: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_18', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 25.87%\n",
      "\n",
      "=== RELATÓRIO DE CLASSIFICAÇÃO ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      uc0003       0.00      0.00      0.00         2\n",
      "      uc0004       0.00      0.00      0.00         2\n",
      "      uc0012       0.20      0.05      0.07        22\n",
      "      uc0013       0.00      0.00      0.00        14\n",
      "      uc0014       0.00      0.00      0.00         3\n",
      "      uc0015       0.67      0.20      0.31        10\n",
      "      uc0016       0.11      0.06      0.08       223\n",
      "      uc0017       0.09      0.06      0.07        80\n",
      "     uc0018b       0.67      0.20      0.31        20\n",
      "      uc0019       0.14      0.04      0.06       248\n",
      "      uc0020       0.00      0.00      0.00         4\n",
      "      uc0021       0.00      0.00      0.00         2\n",
      "      uc0023       0.40      1.00      0.57         2\n",
      "      uc0024       0.50      0.07      0.12        14\n",
      "      uc0025       0.00      0.00      0.00         1\n",
      "   uc0025_01       0.00      0.00      0.00         3\n",
      "      uc0026       0.00      0.00      0.00         6\n",
      "      uc0027       0.00      0.00      0.00         1\n",
      "      uc0028       0.00      0.00      0.00         1\n",
      "      uc0029       0.38      0.60      0.46         5\n",
      "      uc0030       0.43      0.50      0.46         6\n",
      "      uc0031       0.28      0.34      0.30        68\n",
      "      uc0032       0.00      0.00      0.00         3\n",
      "      uc0033       0.00      0.00      0.00         4\n",
      "      uc0034       0.00      0.00      0.00         3\n",
      "      uc0036       0.00      0.00      0.00         7\n",
      "      uc0039       0.48      0.46      0.47        24\n",
      "      uc0040       0.38      0.38      0.38        37\n",
      "      uc0041       0.00      0.00      0.00         4\n",
      "      uc0042       0.49      0.41      0.44        49\n",
      "      uc0043       0.24      0.64      0.35      1302\n",
      "      uc0044       0.42      0.31      0.36        68\n",
      "      uc0045       0.38      0.07      0.12        81\n",
      "      uc0046       0.00      0.00      0.00         1\n",
      "      uc0047       0.11      0.05      0.07        20\n",
      "      uc0049       0.00      0.00      0.00         3\n",
      "      uc0052       0.00      0.00      0.00        13\n",
      "      uc0053       0.43      0.31      0.36        65\n",
      "      uc0054       0.00      0.00      0.00         3\n",
      "      uc0056       0.00      0.00      0.00        12\n",
      "      uc0058       0.22      0.17      0.19        47\n",
      "      uc0059       0.32      0.36      0.34        22\n",
      "      uc0060       0.16      0.23      0.19        39\n",
      "      uc0061       0.00      0.00      0.00         8\n",
      "      uc0062       0.00      0.00      0.00         8\n",
      "      uc0065       0.00      0.00      0.00         3\n",
      "      uc0067       0.00      0.00      0.00         2\n",
      "      uc0068       0.18      0.06      0.09        32\n",
      "      uc0069       0.30      0.47      0.37       266\n",
      "      uc0070       0.00      0.00      0.00         1\n",
      "      uc0072       0.00      0.00      0.00         1\n",
      "      uc0075       0.37      0.49      0.42       427\n",
      "      uc0076       0.21      0.13      0.16        61\n",
      "      uc0077       0.39      0.30      0.34       210\n",
      "      uc0078       0.00      0.00      0.00        16\n",
      "      uc0079       0.20      0.09      0.13        32\n",
      "      uc0080       0.00      0.00      0.00         4\n",
      "      uc0081       0.13      0.18      0.15        34\n",
      "      uc0082       0.00      0.00      0.00         1\n",
      "      uc0084       0.00      0.00      0.00         3\n",
      "      uc0085       0.00      0.00      0.00         4\n",
      "      uc0086       0.35      0.44      0.39        48\n",
      "      uc0087       0.23      0.16      0.19       141\n",
      "      uc0089       0.00      0.00      0.00         3\n",
      "      uc0090       0.00      0.00      0.00         6\n",
      "      uc0091       0.00      0.00      0.00         4\n",
      "      uc0093       0.50      0.50      0.50         2\n",
      "      uc0094       0.18      0.05      0.08       265\n",
      "      uc0096       0.20      0.20      0.20       313\n",
      "      uc0097       0.27      0.16      0.20        43\n",
      "      uc0098       0.76      0.59      0.67        27\n",
      "      uc0099       0.00      0.00      0.00         6\n",
      "      uc0100       0.00      0.00      0.00         7\n",
      "      uc0101       0.00      0.00      0.00         2\n",
      "      uc0102       0.00      0.00      0.00         4\n",
      "      uc0103       0.00      0.00      0.00         2\n",
      "      uc0105       0.00      0.00      0.00        12\n",
      "      uc0107       0.37      0.37      0.37       113\n",
      "      uc0108       0.29      1.00      0.44         2\n",
      "      uc0109       0.00      0.00      0.00        10\n",
      "      uc0110       0.00      0.00      0.00        15\n",
      "      uc0111       0.10      0.02      0.04       466\n",
      "      uc0112       0.00      0.00      0.00        20\n",
      "      uc0113       0.00      0.00      0.00        20\n",
      "      uc0114       0.00      0.00      0.00        41\n",
      "      uc0115       0.00      0.00      0.00        10\n",
      "      uc0116       0.33      0.17      0.22         6\n",
      "      uc0117       0.00      0.00      0.00         4\n",
      "      uc0118       0.00      0.00      0.00        11\n",
      "      uc0124       0.34      0.19      0.25       218\n",
      "      uc0125       0.30      0.28      0.29        39\n",
      "      uc0126       0.28      0.11      0.16        46\n",
      "      uc0128       0.00      0.00      0.00         7\n",
      "      uc0130       0.00      0.00      0.00         4\n",
      "      uc0131       0.17      0.09      0.12       214\n",
      "      uc0132       0.00      0.00      0.00         1\n",
      "      uc0133       0.00      0.00      0.00         5\n",
      "      uc0134       0.61      0.47      0.53        58\n",
      "      uc0135       0.00      0.00      0.00         9\n",
      "      uc0136       0.50      0.20      0.29        10\n",
      "      uc0137       0.00      0.00      0.00         7\n",
      "      uc0138       0.00      0.00      0.00         8\n",
      "      uc0139       0.42      0.22      0.29        60\n",
      "      uc0141       0.22      0.33      0.27         6\n",
      "      uc0146       0.20      0.24      0.22       689\n",
      "      uc0149       0.00      0.00      0.00         4\n",
      "      uc0150       0.08      0.01      0.01       141\n",
      "      uc0153       0.26      0.42      0.32        45\n",
      "      uc0156       0.40      0.40      0.40         5\n",
      "      uc0157       0.46      0.38      0.42        63\n",
      "      uc0158       0.57      0.36      0.44        11\n",
      "      uc0159       0.00      0.00      0.00         6\n",
      "      uc0161       0.00      0.00      0.00         2\n",
      "      uc0162       0.24      0.22      0.23       301\n",
      "      uc0163       0.00      0.00      0.00         1\n",
      "      uc0165       0.23      0.18      0.20        17\n",
      "      uc0167       0.00      0.00      0.00         4\n",
      "      uc0169       0.00      0.00      0.00         9\n",
      "      uc0171       0.00      0.00      0.00         9\n",
      "      uc0172       0.52      0.47      0.49        32\n",
      "      uc0173       0.25      0.09      0.13        11\n",
      "      uc0178       0.00      0.00      0.00        40\n",
      "      uc0179       0.20      0.12      0.15       235\n",
      "      uc0180       0.00      0.00      0.00         1\n",
      "      uc0181       0.00      0.00      0.00        64\n",
      "      uc0186       0.00      0.00      0.00         3\n",
      "      uc0187       0.00      0.00      0.00         3\n",
      "      uc0189       0.00      0.00      0.00         6\n",
      "      uc0190       0.00      0.00      0.00         1\n",
      "      uc0191       0.00      0.00      0.00         1\n",
      "      uc0192       1.00      0.08      0.15        12\n",
      "      uc0193       0.00      0.00      0.00        10\n",
      "      uc0195       0.00      0.00      0.00         3\n",
      "      uc0197       0.17      0.15      0.16        33\n",
      "      uc0198       0.00      0.00      0.00         3\n",
      "      uc0199       0.00      0.00      0.00         1\n",
      "      uc0209       0.00      0.00      0.00        11\n",
      "      uc0211       0.14      0.06      0.09        48\n",
      "      uc0212       0.00      0.00      0.00        16\n",
      "      uc0215       0.17      0.02      0.03       117\n",
      "      uc0216       0.50      0.35      0.41        20\n",
      "      uc0217       0.00      0.00      0.00         1\n",
      "      uc0219       0.42      0.38      0.40        13\n",
      "      uc0220       0.25      0.44      0.32         9\n",
      "      uc0221       0.00      0.00      0.00         9\n",
      "      uc0222       0.29      0.14      0.19       128\n",
      "      uc0223       0.50      0.18      0.27        11\n",
      "      uc0225       0.44      0.39      0.41        18\n",
      "      uc0226       0.44      0.51      0.47        63\n",
      "      uc0228       0.00      0.00      0.00         8\n",
      "      uc0229       0.00      0.00      0.00         8\n",
      "      uc0230       0.00      0.00      0.00         3\n",
      "      uc0232       0.00      0.00      0.00        65\n",
      "      uc0233       0.00      0.00      0.00         6\n",
      "      uc0234       0.00      0.00      0.00        32\n",
      "      uc0235       0.00      0.00      0.00        28\n",
      "      uc0240       0.00      0.00      0.00        10\n",
      "      uc0241       0.25      0.25      0.25         4\n",
      "      uc0242       0.20      0.20      0.20         5\n",
      "      uc0243       0.00      0.00      0.00         1\n",
      "      uc0244       0.00      0.00      0.00         2\n",
      "      uc0256       0.00      0.00      0.00         1\n",
      "      uc1003       0.27      0.24      0.25        46\n",
      "      uc1004       0.00      0.00      0.00        22\n",
      "      uc1006       0.00      0.00      0.00        65\n",
      "      uc1007       0.40      0.33      0.36         6\n",
      "      uc1008       0.00      0.00      0.00         5\n",
      "      uc1009       0.38      0.43      0.40        28\n",
      "      uc1010       0.46      0.52      0.49        44\n",
      "      uc1011       0.33      0.04      0.07        24\n",
      "      uc1012       0.14      0.08      0.10        13\n",
      "      uc1013       0.00      0.00      0.00         3\n",
      "      uc1014       0.17      0.14      0.15         7\n",
      "      uc1015       0.00      0.00      0.00         5\n",
      "      uc1016       0.00      0.00      0.00        27\n",
      "      uc1017       0.39      0.32      0.35        68\n",
      "      uc1018       0.00      0.00      0.00         5\n",
      "      uc1019       0.00      0.00      0.00         5\n",
      "      uc2097       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.26      8729\n",
      "   macro avg       0.15      0.12      0.12      8729\n",
      "weighted avg       0.23      0.26      0.22      8729\n",
      "\n",
      "🔍 Debug - Tipo de 'results': <class 'dict'>\n",
      "🔍 Debug - Chaves disponíveis: ['accuracy', 'y_pred', 'y_test', 'confusion_matrix', 'class_names', 'y_pred_proba']\n",
      "✅ Usuário usuario_03 processado com sucesso!\n",
      "\n",
      "🔄 Processando usuário 5/17: usuario_04\n",
      "----------------------------------------\n",
      "=== INICIANDO PREPROCESSAMENTO ===\n",
      "Carregando dados de: ../dados/processados/Dados_TechChallenge_Fase3.csv\n",
      "Dataset carregado: (115591, 7)\n",
      "\n",
      "Distribuição das classes:\n",
      "casoDeUso\n",
      "uc0043    13099\n",
      "uc0232     7408\n",
      "uc0096     7042\n",
      "uc0146     5042\n",
      "uc0075     3394\n",
      "uc0222     3085\n",
      "uc0162     3018\n",
      "uc0111     2963\n",
      "uc0179     2896\n",
      "uc0069     2620\n",
      "Name: count, dtype: int64\n",
      "Processando dados para usuário: usuario_04\n",
      "Registros após filtro de usuário: 2666\n",
      "Criando features históricas...\n",
      "Registros após limpeza: 2666\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso_1', 'casoDeUso_2']\n",
      "Processando features contextuais...\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "Normalizando features sequenciais...\n",
      "Dividindo dados em treino e teste...\n",
      "⚠️ Aviso: 2 classes com apenas 1 amostra:\n",
      "casoDeUso\n",
      "uc2013    1\n",
      "uc2082    1\n",
      "Name: count, dtype: int64\n",
      "Removendo classes com poucas amostras para permitir estratificação...\n",
      "Dados após filtro: 2664 amostras, 74 classes\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "✅ Divisão estratificada realizada com sucesso\n",
      "Treino: 1598 samples\n",
      "Teste: 1066 samples\n",
      "=== CRIANDO MODELO DENSE HÍBRIDO ===\n",
      "Usando Dense layers: [128, 64]\n",
      "Modelo criado e compilado!\n",
      "Parâmetros totais: 32,980\n",
      "\n",
      "\n",
      "=== ARQUITETURA DO MODELO ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">154</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">19,840</span> │ input_sequence[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ input_epoch[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,884</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m154\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m19,840\u001b[0m │ input_sequence[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ input_epoch[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m)        │      \u001b[38;5;34m4,884\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,980</span> (128.83 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32,980\u001b[0m (128.83 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,980</span> (128.83 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m32,980\u001b[0m (128.83 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INICIANDO TREINAMENTO ===\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 21:43:26.195073: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1111', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2025-05-25 21:43:26.409909: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1113', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0458 - loss: 4.5103     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 21:43:28.270546: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1111', 44 bytes spill stores, 44 bytes spill loads\n",
      "\n",
      "2025-05-25 21:43:28.300487: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1113', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.0516 - loss: 4.4407 - val_accuracy: 0.1031 - val_loss: 3.9728 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1103 - loss: 3.9562 - val_accuracy: 0.1375 - val_loss: 3.7671 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1418 - loss: 3.7169 - val_accuracy: 0.1562 - val_loss: 3.6487 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1954 - loss: 3.4189 - val_accuracy: 0.1937 - val_loss: 3.5733 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1967 - loss: 3.2487 - val_accuracy: 0.2125 - val_loss: 3.4901 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2228 - loss: 3.2360 - val_accuracy: 0.2219 - val_loss: 3.4464 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2502 - loss: 3.0963 - val_accuracy: 0.2406 - val_loss: 3.3900 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2680 - loss: 2.9144 - val_accuracy: 0.2406 - val_loss: 3.3664 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2767 - loss: 2.8855 - val_accuracy: 0.2438 - val_loss: 3.3376 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3077 - loss: 2.7274 - val_accuracy: 0.2406 - val_loss: 3.3217 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3062 - loss: 2.6865 - val_accuracy: 0.2438 - val_loss: 3.3299 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3216 - loss: 2.6124 - val_accuracy: 0.2438 - val_loss: 3.3337 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3356 - loss: 2.6161 - val_accuracy: 0.2469 - val_loss: 3.3458 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3373 - loss: 2.5727 - val_accuracy: 0.2406 - val_loss: 3.3695 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3733 - loss: 2.4905 \n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3641 - loss: 2.5085 - val_accuracy: 0.2531 - val_loss: 3.3648 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3517 - loss: 2.4444 - val_accuracy: 0.2594 - val_loss: 3.3860 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3446 - loss: 2.5133 - val_accuracy: 0.2625 - val_loss: 3.3874 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3441 - loss: 2.4314 - val_accuracy: 0.2594 - val_loss: 3.3956 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3735 - loss: 2.3919 - val_accuracy: 0.2562 - val_loss: 3.4106 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3487 - loss: 2.4146 \n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3538 - loss: 2.4118 - val_accuracy: 0.2469 - val_loss: 3.4181 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3480 - loss: 2.4402 - val_accuracy: 0.2562 - val_loss: 3.4248 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3561 - loss: 2.3728 - val_accuracy: 0.2625 - val_loss: 3.4248 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3868 - loss: 2.3160 - val_accuracy: 0.2625 - val_loss: 3.4328 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3989 - loss: 2.2892 - val_accuracy: 0.2562 - val_loss: 3.4425 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3625 - loss: 2.3939 \n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3735 - loss: 2.3630 - val_accuracy: 0.2594 - val_loss: 3.4445 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3683 - loss: 2.3474 - val_accuracy: 0.2594 - val_loss: 3.4486 - learning_rate: 1.2500e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3698 - loss: 2.3198 - val_accuracy: 0.2562 - val_loss: 3.4502 - learning_rate: 1.2500e-04\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Treinamento concluído!\n",
      "=== AVALIANDO MODELO ===\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Acurácia: 24.86%\n",
      "\n",
      "=== RELATÓRIO DE CLASSIFICAÇÃO ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      uc0212       0.25      0.20      0.22        25\n",
      "      uc0232       0.50      0.07      0.12        15\n",
      "      uc0234       0.00      0.00      0.00         1\n",
      "      uc0237       0.00      0.00      0.00        15\n",
      "      uc2001       0.50      0.25      0.33         8\n",
      "      uc2002       0.37      0.54      0.44        13\n",
      "      uc2005       0.67      0.33      0.44         6\n",
      "      uc2006       0.67      0.50      0.57        12\n",
      "      uc2007       0.00      0.00      0.00         6\n",
      "      uc2008       0.40      0.53      0.46        15\n",
      "      uc2009       0.00      0.00      0.00         1\n",
      "      uc2010       0.00      0.00      0.00         1\n",
      "      uc2011       0.17      0.40      0.24         5\n",
      "      uc2012       0.30      0.30      0.30        10\n",
      "      uc2014       0.00      0.00      0.00         9\n",
      "      uc2015       0.00      0.00      0.00         5\n",
      "      uc2017       0.00      0.00      0.00         5\n",
      "      uc2019       0.12      0.13      0.13        30\n",
      "      uc2020       0.09      0.05      0.07        39\n",
      "      uc2023       0.21      0.55      0.30       121\n",
      "      uc2025       0.00      0.00      0.00        16\n",
      "      uc2026       0.00      0.00      0.00         5\n",
      "      uc2027       0.40      0.43      0.41        14\n",
      "      uc2028       0.48      0.59      0.53        17\n",
      "      uc2029       0.33      0.45      0.38        76\n",
      "      uc2030       0.00      0.00      0.00        12\n",
      "      uc2031       0.00      0.00      0.00         6\n",
      "      uc2032       0.00      0.00      0.00        15\n",
      "      uc2033       0.00      0.00      0.00        18\n",
      "      uc2034       0.14      0.03      0.05        30\n",
      "      uc2036       0.00      0.00      0.00         4\n",
      "      uc2037       0.00      0.00      0.00        13\n",
      "      uc2038       0.00      0.00      0.00         2\n",
      "      uc2039       0.00      0.00      0.00        17\n",
      "      uc2040       0.00      0.00      0.00         3\n",
      "      uc2041       0.00      0.00      0.00         8\n",
      "      uc2043       0.00      0.00      0.00         1\n",
      "      uc2045       0.00      0.00      0.00        10\n",
      "      uc2046       0.00      0.00      0.00         6\n",
      "      uc2048       0.00      0.00      0.00         4\n",
      "      uc2049       0.20      0.27      0.23        15\n",
      "      uc2053       0.00      0.00      0.00         4\n",
      "      uc2054       0.00      0.00      0.00         1\n",
      "      uc2055       0.00      0.00      0.00         4\n",
      "      uc2056       0.00      0.00      0.00        15\n",
      "      uc2059       0.24      0.35      0.28       133\n",
      "      uc2060       0.00      0.00      0.00         5\n",
      "      uc2061       0.00      0.00      0.00         5\n",
      "      uc2062       0.00      0.00      0.00         4\n",
      "      uc2063       0.00      0.00      0.00         4\n",
      "      uc2064       0.32      0.30      0.31        20\n",
      "      uc2065       0.40      0.44      0.42        27\n",
      "      uc2066       0.34      0.48      0.40        29\n",
      "      uc2067       0.33      0.10      0.15        10\n",
      "      uc2068       0.00      0.00      0.00         6\n",
      "      uc2071       0.00      0.00      0.00         1\n",
      "      uc2072       0.00      0.00      0.00         6\n",
      "      uc2073       0.00      0.00      0.00         2\n",
      "      uc2074       0.00      0.00      0.00         1\n",
      "      uc2075       0.00      0.00      0.00         2\n",
      "      uc2076       0.25      0.07      0.11        14\n",
      "      uc2077       0.00      0.00      0.00         7\n",
      "      uc2078       0.50      0.36      0.42        14\n",
      "      uc2079       0.00      0.00      0.00         1\n",
      "      uc2081       0.00      0.00      0.00         1\n",
      "      uc2083       0.00      0.00      0.00        12\n",
      "      uc2084       0.62      0.80      0.70        10\n",
      "      uc2085       0.00      0.00      0.00         2\n",
      "      uc2086       0.00      0.00      0.00         9\n",
      "      uc2092       0.15      0.14      0.14        63\n",
      "      uc2095       0.00      0.00      0.00         6\n",
      "      uc2096       0.00      0.00      0.00         9\n",
      "      uc2098       0.00      0.00      0.00         3\n",
      "      uc2100       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.25      1066\n",
      "   macro avg       0.12      0.12      0.11      1066\n",
      "weighted avg       0.20      0.25      0.21      1066\n",
      "\n",
      "🔍 Debug - Tipo de 'results': <class 'dict'>\n",
      "🔍 Debug - Chaves disponíveis: ['accuracy', 'y_pred', 'y_test', 'confusion_matrix', 'class_names', 'y_pred_proba']\n",
      "✅ Usuário usuario_04 processado com sucesso!\n",
      "\n",
      "🔄 Processando usuário 6/17: usuario_05\n",
      "----------------------------------------\n",
      "=== INICIANDO PREPROCESSAMENTO ===\n",
      "Carregando dados de: ../dados/processados/Dados_TechChallenge_Fase3.csv\n",
      "Dataset carregado: (115591, 7)\n",
      "\n",
      "Distribuição das classes:\n",
      "casoDeUso\n",
      "uc0043    13099\n",
      "uc0232     7408\n",
      "uc0096     7042\n",
      "uc0146     5042\n",
      "uc0075     3394\n",
      "uc0222     3085\n",
      "uc0162     3018\n",
      "uc0111     2963\n",
      "uc0179     2896\n",
      "uc0069     2620\n",
      "Name: count, dtype: int64\n",
      "Processando dados para usuário: usuario_05\n",
      "Registros após filtro de usuário: 15783\n",
      "Criando features históricas...\n",
      "Registros após limpeza: 15783\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso_1', 'casoDeUso_2']\n",
      "Processando features contextuais...\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "Normalizando features sequenciais...\n",
      "Dividindo dados em treino e teste...\n",
      "⚠️ Aviso: 13 classes com apenas 1 amostra:\n",
      "casoDeUso\n",
      "uc0046    1\n",
      "uc0173    1\n",
      "uc0064    1\n",
      "uc0195    1\n",
      "uc1008    1\n",
      "Name: count, dtype: int64\n",
      "Removendo classes com poucas amostras para permitir estratificação...\n",
      "Dados após filtro: 15770 amostras, 153 classes\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "✅ Divisão estratificada realizada com sucesso\n",
      "Treino: 9462 samples\n",
      "Teste: 6308 samples\n",
      "=== CRIANDO MODELO DENSE HÍBRIDO ===\n",
      "Usando Dense layers: [128, 64]\n",
      "Modelo criado e compilado!\n",
      "Parâmetros totais: 60,850\n",
      "\n",
      "\n",
      "=== ARQUITETURA DO MODELO ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">331</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">42,496</span> │ input_sequence[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ input_epoch[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">153</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,098</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m331\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m42,496\u001b[0m │ input_sequence[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ input_epoch[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m153\u001b[0m)       │     \u001b[38;5;34m10,098\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,850</span> (237.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m60,850\u001b[0m (237.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,850</span> (237.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m60,850\u001b[0m (237.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INICIANDO TREINAMENTO ===\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 21:43:36.642879: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1111', 172 bytes spill stores, 172 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m218/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1051 - loss: 4.5547"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 21:43:39.364881: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1111', 128 bytes spill stores, 128 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.1090 - loss: 4.5194 - val_accuracy: 0.2113 - val_loss: 3.5838 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1985 - loss: 3.5925 - val_accuracy: 0.2435 - val_loss: 3.4036 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2431 - loss: 3.3211 - val_accuracy: 0.2599 - val_loss: 3.3267 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2532 - loss: 3.2215 - val_accuracy: 0.2599 - val_loss: 3.2606 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2635 - loss: 3.1628 - val_accuracy: 0.2721 - val_loss: 3.2388 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2806 - loss: 3.0210 - val_accuracy: 0.2689 - val_loss: 3.2306 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2812 - loss: 2.9960 - val_accuracy: 0.2657 - val_loss: 3.2432 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2775 - loss: 2.9605 - val_accuracy: 0.2705 - val_loss: 3.2350 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2930 - loss: 2.9208 - val_accuracy: 0.2800 - val_loss: 3.2350 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2981 - loss: 2.8541 - val_accuracy: 0.2779 - val_loss: 3.2332 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m227/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2960 - loss: 2.8814\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2957 - loss: 2.8814 - val_accuracy: 0.2684 - val_loss: 3.2495 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3010 - loss: 2.8348 - val_accuracy: 0.2721 - val_loss: 3.2528 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3008 - loss: 2.8236 - val_accuracy: 0.2721 - val_loss: 3.2605 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3053 - loss: 2.7800 - val_accuracy: 0.2736 - val_loss: 3.2673 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3149 - loss: 2.7360 - val_accuracy: 0.2721 - val_loss: 3.2754 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m222/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3123 - loss: 2.7615\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3118 - loss: 2.7626 - val_accuracy: 0.2710 - val_loss: 3.2856 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3054 - loss: 2.7242 - val_accuracy: 0.2742 - val_loss: 3.2876 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3074 - loss: 2.7308 - val_accuracy: 0.2768 - val_loss: 3.2972 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3087 - loss: 2.7420 - val_accuracy: 0.2752 - val_loss: 3.3018 - learning_rate: 2.5000e-04\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Treinamento concluído!\n",
      "=== AVALIANDO MODELO ===\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Acurácia: 27.33%\n",
      "\n",
      "=== RELATÓRIO DE CLASSIFICAÇÃO ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      uc0001       0.00      0.00      0.00         1\n",
      "      uc0003       0.00      0.00      0.00         2\n",
      "      uc0004       0.00      0.00      0.00         4\n",
      "      uc0012       0.00      0.00      0.00         8\n",
      "      uc0013       0.00      0.00      0.00         4\n",
      "      uc0015       0.00      0.00      0.00         1\n",
      "      uc0016       0.20      0.04      0.07       154\n",
      "      uc0017       0.23      0.04      0.07        76\n",
      "     uc0018b       0.00      0.00      0.00         8\n",
      "      uc0019       0.25      0.22      0.23       156\n",
      "      uc0020       0.00      0.00      0.00         2\n",
      "      uc0023       1.00      1.00      1.00         2\n",
      "      uc0024       0.18      0.25      0.21        24\n",
      "   uc0025_01       0.00      0.00      0.00         2\n",
      "      uc0026       0.00      0.00      0.00         2\n",
      "      uc0027       0.00      0.00      0.00         3\n",
      "      uc0028       0.00      0.00      0.00         6\n",
      "      uc0029       0.46      0.75      0.57         8\n",
      "      uc0030       0.23      0.30      0.26        10\n",
      "      uc0031       0.43      0.38      0.40        71\n",
      "      uc0032       0.00      0.00      0.00         8\n",
      "      uc0033       0.00      0.00      0.00         2\n",
      "      uc0034       0.00      0.00      0.00        15\n",
      "      uc0035       0.00      0.00      0.00         1\n",
      "      uc0036       0.00      0.00      0.00         6\n",
      "      uc0039       0.58      0.44      0.50        16\n",
      "      uc0040       0.28      0.37      0.32        19\n",
      "      uc0041       0.00      0.00      0.00         4\n",
      "      uc0042       0.58      0.56      0.57        34\n",
      "      uc0043       0.27      0.69      0.38      1043\n",
      "      uc0044       0.58      0.33      0.42        55\n",
      "      uc0045       0.31      0.13      0.18       110\n",
      "      uc0047       0.00      0.00      0.00        10\n",
      "      uc0050       0.00      0.00      0.00         2\n",
      "      uc0052       0.00      0.00      0.00        11\n",
      "      uc0053       0.31      0.09      0.14        44\n",
      "      uc0056       0.00      0.00      0.00        10\n",
      "      uc0058       0.45      0.16      0.23        32\n",
      "      uc0059       0.50      0.04      0.07        28\n",
      "      uc0060       0.47      0.38      0.42        37\n",
      "      uc0061       0.00      0.00      0.00         2\n",
      "      uc0062       0.00      0.00      0.00         1\n",
      "      uc0065       0.00      0.00      0.00         1\n",
      "      uc0067       0.00      0.00      0.00         4\n",
      "      uc0068       0.00      0.00      0.00        22\n",
      "      uc0069       0.27      0.39      0.32       261\n",
      "      uc0070       0.00      0.00      0.00         3\n",
      "      uc0075       0.39      0.68      0.49       330\n",
      "      uc0076       0.50      0.06      0.11        49\n",
      "      uc0077       0.28      0.15      0.20       123\n",
      "      uc0078       0.20      0.10      0.13        20\n",
      "      uc0079       0.00      0.00      0.00        28\n",
      "      uc0080       0.00      0.00      0.00         6\n",
      "      uc0081       0.17      0.03      0.04        40\n",
      "      uc0084       0.00      0.00      0.00         3\n",
      "      uc0085       0.00      0.00      0.00        10\n",
      "      uc0086       0.20      0.38      0.26        50\n",
      "      uc0087       0.19      0.18      0.18        66\n",
      "      uc0089       0.00      0.00      0.00        16\n",
      "      uc0090       0.00      0.00      0.00        12\n",
      "      uc0091       0.25      0.21      0.23        28\n",
      "      uc0093       0.14      0.33      0.20         3\n",
      "      uc0094       0.07      0.01      0.02       100\n",
      "      uc0096       0.19      0.22      0.21       388\n",
      "      uc0097       0.00      0.00      0.00         9\n",
      "      uc0098       0.43      0.53      0.47        17\n",
      "      uc0100       0.00      0.00      0.00         9\n",
      "      uc0101       0.00      0.00      0.00         4\n",
      "      uc0102       0.00      0.00      0.00         5\n",
      "      uc0103       0.00      0.00      0.00         1\n",
      "      uc0105       0.00      0.00      0.00         4\n",
      "      uc0107       0.49      0.47      0.48        57\n",
      "      uc0108       0.50      0.40      0.44        10\n",
      "      uc0109       0.00      0.00      0.00         7\n",
      "      uc0110       0.57      0.18      0.28        22\n",
      "      uc0111       0.50      0.00      0.01       242\n",
      "      uc0112       0.00      0.00      0.00        22\n",
      "      uc0113       0.33      0.15      0.21        26\n",
      "      uc0114       0.17      0.02      0.04       166\n",
      "      uc0115       0.18      0.08      0.11        25\n",
      "      uc0116       0.00      0.00      0.00         2\n",
      "      uc0117       0.00      0.00      0.00         2\n",
      "      uc0118       0.00      0.00      0.00         4\n",
      "      uc0124       0.31      0.21      0.25       185\n",
      "      uc0125       0.33      0.12      0.17        26\n",
      "      uc0126       0.24      0.08      0.12        74\n",
      "      uc0127       0.00      0.00      0.00         1\n",
      "      uc0128       0.00      0.00      0.00        10\n",
      "      uc0130       0.00      0.00      0.00         1\n",
      "      uc0131       0.08      0.02      0.03       129\n",
      "      uc0133       0.00      0.00      0.00         3\n",
      "      uc0134       0.20      0.04      0.07        24\n",
      "      uc0135       0.00      0.00      0.00         6\n",
      "      uc0136       0.33      0.09      0.14        11\n",
      "      uc0137       0.00      0.00      0.00         8\n",
      "      uc0138       0.00      0.00      0.00         4\n",
      "      uc0139       0.10      0.07      0.08        43\n",
      "      uc0141       0.00      0.00      0.00         2\n",
      "      uc0146       0.04      0.01      0.01       158\n",
      "      uc0147       0.00      0.00      0.00         5\n",
      "      uc0149       0.33      0.22      0.27         9\n",
      "      uc0150       0.00      0.00      0.00        63\n",
      "      uc0153       0.43      0.30      0.35        20\n",
      "      uc0155       0.00      0.00      0.00         2\n",
      "      uc0156       0.00      0.00      0.00         2\n",
      "      uc0157       0.38      0.35      0.36        57\n",
      "      uc0158       0.00      0.00      0.00        10\n",
      "      uc0159       0.00      0.00      0.00         4\n",
      "      uc0161       0.00      0.00      0.00         2\n",
      "      uc0162       0.21      0.28      0.24       263\n",
      "      uc0163       0.00      0.00      0.00         4\n",
      "      uc0165       0.19      0.29      0.23        21\n",
      "      uc0167       0.00      0.00      0.00         2\n",
      "      uc0169       0.00      0.00      0.00        21\n",
      "      uc0171       0.00      0.00      0.00         8\n",
      "      uc0175       0.00      0.00      0.00         3\n",
      "      uc0179       0.24      0.16      0.19       294\n",
      "      uc0181       0.20      0.04      0.06        81\n",
      "      uc0186       0.00      0.00      0.00         4\n",
      "      uc0187       0.00      0.00      0.00         4\n",
      "      uc0189       0.00      0.00      0.00         6\n",
      "      uc0192       0.00      0.00      0.00         1\n",
      "      uc0193       0.00      0.00      0.00         2\n",
      "      uc0198       0.20      0.14      0.17         7\n",
      "      uc0209       0.00      0.00      0.00        11\n",
      "      uc0211       0.00      0.00      0.00        31\n",
      "      uc0212       0.65      0.61      0.63        36\n",
      "      uc0215       0.19      0.17      0.18       136\n",
      "      uc0216       0.17      0.10      0.12        21\n",
      "      uc0219       0.44      0.70      0.54        10\n",
      "      uc0220       0.44      0.50      0.47         8\n",
      "      uc0221       0.17      0.12      0.14         8\n",
      "      uc0222       0.14      0.11      0.12        70\n",
      "      uc0226       0.37      0.71      0.49        28\n",
      "      uc0230       0.00      0.00      0.00         2\n",
      "      uc0233       0.00      0.00      0.00         3\n",
      "      uc0234       0.00      0.00      0.00        17\n",
      "      uc0235       0.00      0.00      0.00        56\n",
      "      uc0238       0.00      0.00      0.00         3\n",
      "      uc0240       0.00      0.00      0.00         2\n",
      "      uc1003       0.00      0.00      0.00         5\n",
      "      uc1004       0.00      0.00      0.00         1\n",
      "      uc1005       0.00      0.00      0.00         1\n",
      "      uc1006       0.00      0.00      0.00         3\n",
      "      uc1007       0.00      0.00      0.00         3\n",
      "      uc1009       0.00      0.00      0.00        10\n",
      "      uc1010       0.50      0.14      0.22         7\n",
      "      uc1011       0.00      0.00      0.00         2\n",
      "      uc1012       0.00      0.00      0.00         4\n",
      "      uc1013       0.00      0.00      0.00         2\n",
      "      uc1014       0.25      0.14      0.18        14\n",
      "      uc1017       0.00      0.00      0.00         2\n",
      "      uc1019       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.27      6308\n",
      "   macro avg       0.13      0.11      0.11      6308\n",
      "weighted avg       0.25      0.27      0.22      6308\n",
      "\n",
      "🔍 Debug - Tipo de 'results': <class 'dict'>\n",
      "🔍 Debug - Chaves disponíveis: ['accuracy', 'y_pred', 'y_test', 'confusion_matrix', 'class_names', 'y_pred_proba']\n",
      "✅ Usuário usuario_05 processado com sucesso!\n",
      "\n",
      "🔄 Processando usuário 7/17: usuario_06\n",
      "----------------------------------------\n",
      "=== INICIANDO PREPROCESSAMENTO ===\n",
      "Carregando dados de: ../dados/processados/Dados_TechChallenge_Fase3.csv\n",
      "Dataset carregado: (115591, 7)\n",
      "\n",
      "Distribuição das classes:\n",
      "casoDeUso\n",
      "uc0043    13099\n",
      "uc0232     7408\n",
      "uc0096     7042\n",
      "uc0146     5042\n",
      "uc0075     3394\n",
      "uc0222     3085\n",
      "uc0162     3018\n",
      "uc0111     2963\n",
      "uc0179     2896\n",
      "uc0069     2620\n",
      "Name: count, dtype: int64\n",
      "Processando dados para usuário: usuario_06\n",
      "Registros após filtro de usuário: 90\n",
      "Criando features históricas...\n",
      "Registros após limpeza: 90\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso_1', 'casoDeUso_2']\n",
      "Processando features contextuais...\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "Normalizando features sequenciais...\n",
      "Dividindo dados em treino e teste...\n",
      "✅ Divisão estratificada realizada com sucesso\n",
      "Treino: 54 samples\n",
      "Teste: 36 samples\n",
      "=== CRIANDO MODELO DENSE HÍBRIDO ===\n",
      "Usando Dense layers: [128, 64]\n",
      "Modelo criado e compilado!\n",
      "Parâmetros totais: 9,284\n",
      "\n",
      "\n",
      "=== ARQUITETURA DO MODELO ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ input_sequence[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ input_epoch[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m896\u001b[0m │ input_sequence[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ input_epoch[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │        \u001b[38;5;34m132\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,284</span> (36.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,284\u001b[0m (36.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,284</span> (36.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,284\u001b[0m (36.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INICIANDO TREINAMENTO ===\n",
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2s/step - accuracy: 0.4818 - loss: 0.7272 - val_accuracy: 0.9091 - val_loss: 0.6184 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5647 - loss: 0.6792 - val_accuracy: 1.0000 - val_loss: 0.5521 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8186 - loss: 0.5776 - val_accuracy: 1.0000 - val_loss: 0.4977 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7357 - loss: 0.5653 - val_accuracy: 1.0000 - val_loss: 0.4501 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8653 - loss: 0.5028 - val_accuracy: 1.0000 - val_loss: 0.4052 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8394 - loss: 0.4822 - val_accuracy: 1.0000 - val_loss: 0.3631 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8653 - loss: 0.4607 - val_accuracy: 1.0000 - val_loss: 0.3269 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8963 - loss: 0.4200 - val_accuracy: 1.0000 - val_loss: 0.2935 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8704 - loss: 0.4031 - val_accuracy: 1.0000 - val_loss: 0.2628 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9172 - loss: 0.3338 - val_accuracy: 1.0000 - val_loss: 0.2364 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9172 - loss: 0.3510 - val_accuracy: 1.0000 - val_loss: 0.2140 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8963 - loss: 0.3783 - val_accuracy: 1.0000 - val_loss: 0.1944 - learning_rate: 0.0010\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Treinamento concluído!\n",
      "=== AVALIANDO MODELO ===\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step\n",
      "Acurácia: 86.11%\n",
      "\n",
      "=== RELATÓRIO DE CLASSIFICAÇÃO ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      uc2087       0.83      1.00      0.91        24\n",
      "      uc2090       1.00      0.58      0.74        12\n",
      "\n",
      "    accuracy                           0.86        36\n",
      "   macro avg       0.91      0.79      0.82        36\n",
      "weighted avg       0.89      0.86      0.85        36\n",
      "\n",
      "🔍 Debug - Tipo de 'results': <class 'dict'>\n",
      "🔍 Debug - Chaves disponíveis: ['accuracy', 'y_pred', 'y_test', 'confusion_matrix', 'class_names', 'y_pred_proba']\n",
      "✅ Usuário usuario_06 processado com sucesso!\n",
      "\n",
      "🔄 Processando usuário 8/17: usuario_07\n",
      "----------------------------------------\n",
      "=== INICIANDO PREPROCESSAMENTO ===\n",
      "Carregando dados de: ../dados/processados/Dados_TechChallenge_Fase3.csv\n",
      "Dataset carregado: (115591, 7)\n",
      "\n",
      "Distribuição das classes:\n",
      "casoDeUso\n",
      "uc0043    13099\n",
      "uc0232     7408\n",
      "uc0096     7042\n",
      "uc0146     5042\n",
      "uc0075     3394\n",
      "uc0222     3085\n",
      "uc0162     3018\n",
      "uc0111     2963\n",
      "uc0179     2896\n",
      "uc0069     2620\n",
      "Name: count, dtype: int64\n",
      "Processando dados para usuário: usuario_07\n",
      "Registros após filtro de usuário: 8189\n",
      "Criando features históricas...\n",
      "Registros após limpeza: 8189\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso_1', 'casoDeUso_2']\n",
      "Processando features contextuais...\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "Normalizando features sequenciais...\n",
      "Dividindo dados em treino e teste...\n",
      "⚠️ Aviso: 16 classes com apenas 1 amostra:\n",
      "casoDeUso\n",
      "uc0193    1\n",
      "uc0065    1\n",
      "uc2047    1\n",
      "uc2018    1\n",
      "uc2015    1\n",
      "Name: count, dtype: int64\n",
      "Removendo classes com poucas amostras para permitir estratificação...\n",
      "Dados após filtro: 8173 amostras, 164 classes\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "✅ Divisão estratificada realizada com sucesso\n",
      "Treino: 4903 samples\n",
      "Teste: 3270 samples\n",
      "=== CRIANDO MODELO DENSE HÍBRIDO ===\n",
      "Usando Dense layers: [128, 64]\n",
      "Modelo criado e compilado!\n",
      "Parâmetros totais: 65,160\n",
      "\n",
      "\n",
      "=== ARQUITETURA DO MODELO ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">359</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">46,080</span> │ input_sequence[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ input_epoch[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">164</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,824</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m359\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m46,080\u001b[0m │ input_sequence[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ input_epoch[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m164\u001b[0m)       │     \u001b[38;5;34m10,824\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,160</span> (254.53 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m65,160\u001b[0m (254.53 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,160</span> (254.53 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m65,160\u001b[0m (254.53 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INICIANDO TREINAMENTO ===\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 21:44:03.377819: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1111', 504 bytes spill stores, 504 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0817 - loss: 4.9059"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 21:44:05.456496: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1111_0', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-05-25 21:44:05.578035: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1111', 488 bytes spill stores, 488 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.0834 - loss: 4.8914 - val_accuracy: 0.2151 - val_loss: 3.9235 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1823 - loss: 3.8577 - val_accuracy: 0.2681 - val_loss: 3.5464 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2405 - loss: 3.5189 - val_accuracy: 0.3293 - val_loss: 3.3075 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2834 - loss: 3.2090 - val_accuracy: 0.3282 - val_loss: 3.1689 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3077 - loss: 3.0001 - val_accuracy: 0.3507 - val_loss: 3.0752 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3330 - loss: 2.8307 - val_accuracy: 0.3354 - val_loss: 3.0320 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3527 - loss: 2.7132 - val_accuracy: 0.3496 - val_loss: 3.0097 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3582 - loss: 2.6196 - val_accuracy: 0.3425 - val_loss: 3.0203 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3619 - loss: 2.5712 - val_accuracy: 0.3344 - val_loss: 3.0030 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3858 - loss: 2.5149 - val_accuracy: 0.3333 - val_loss: 3.0169 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3661 - loss: 2.4675 - val_accuracy: 0.3456 - val_loss: 3.0256 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3762 - loss: 2.4014 - val_accuracy: 0.3445 - val_loss: 3.0500 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3930 - loss: 2.3334 - val_accuracy: 0.3252 - val_loss: 3.0449 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m110/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3977 - loss: 2.3298\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3966 - loss: 2.3324 - val_accuracy: 0.3486 - val_loss: 3.0555 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4041 - loss: 2.2587 - val_accuracy: 0.3456 - val_loss: 3.0684 - learning_rate: 5.0000e-04\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Treinamento concluído!\n",
      "=== AVALIANDO MODELO ===\n",
      "WARNING:tensorflow:5 out of the last 201 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fd4530fdee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "Acurácia: 33.36%\n",
      "\n",
      "=== RELATÓRIO DE CLASSIFICAÇÃO ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      uc0013       0.00      0.00      0.00         1\n",
      "      uc0016       0.00      0.00      0.00        10\n",
      "      uc0017       0.00      0.00      0.00        12\n",
      "     uc0018b       0.00      0.00      0.00         6\n",
      "      uc0019       0.00      0.00      0.00         5\n",
      "      uc0031       0.00      0.00      0.00         1\n",
      "      uc0039       1.00      1.00      1.00         2\n",
      "      uc0040       0.00      0.00      0.00         3\n",
      "      uc0042       0.00      0.00      0.00         5\n",
      "      uc0043       0.12      0.08      0.10        38\n",
      "      uc0044       0.38      0.33      0.35         9\n",
      "      uc0045       0.00      0.00      0.00         7\n",
      "      uc0047       0.00      0.00      0.00         1\n",
      "      uc0052       0.00      0.00      0.00         3\n",
      "      uc0053       0.00      0.00      0.00         2\n",
      "      uc0054       0.00      0.00      0.00         1\n",
      "      uc0056       0.00      0.00      0.00         1\n",
      "      uc0058       0.00      0.00      0.00         6\n",
      "      uc0059       0.00      0.00      0.00         3\n",
      "      uc0060       0.00      0.00      0.00         4\n",
      "      uc0061       0.00      0.00      0.00         1\n",
      "      uc0068       0.00      0.00      0.00         4\n",
      "      uc0069       0.31      0.42      0.36        67\n",
      "      uc0075       0.60      0.59      0.59        73\n",
      "      uc0076       0.00      0.00      0.00         7\n",
      "      uc0077       0.25      0.22      0.24        45\n",
      "      uc0079       0.00      0.00      0.00         4\n",
      "      uc0080       0.00      0.00      0.00         1\n",
      "      uc0086       0.00      0.00      0.00         6\n",
      "      uc0087       0.00      0.00      0.00        10\n",
      "      uc0094       0.10      0.07      0.08        14\n",
      "      uc0096       0.00      0.00      0.00         1\n",
      "      uc0097       0.00      0.00      0.00         1\n",
      "      uc0098       1.00      1.00      1.00         3\n",
      "      uc0102       0.00      0.00      0.00         1\n",
      "      uc0103       0.00      0.00      0.00         1\n",
      "      uc0107       0.41      0.50      0.45        18\n",
      "      uc0110       0.00      0.00      0.00         1\n",
      "      uc0111       0.00      0.00      0.00         3\n",
      "      uc0114       0.00      0.00      0.00         8\n",
      "      uc0115       0.00      0.00      0.00         1\n",
      "      uc0124       1.00      0.02      0.05        42\n",
      "      uc0125       0.00      0.00      0.00         2\n",
      "      uc0126       0.00      0.00      0.00         8\n",
      "      uc0131       0.00      0.00      0.00        16\n",
      "      uc0132       0.00      0.00      0.00         2\n",
      "      uc0134       0.00      0.00      0.00         4\n",
      "      uc0139       0.00      0.00      0.00         4\n",
      "      uc0140       0.00      0.00      0.00         4\n",
      "      uc0146       0.05      0.04      0.04        27\n",
      "      uc0150       0.00      0.00      0.00         6\n",
      "      uc0153       0.00      0.00      0.00         4\n",
      "      uc0156       0.00      0.00      0.00         1\n",
      "      uc0157       0.00      0.00      0.00         5\n",
      "      uc0159       0.00      0.00      0.00         1\n",
      "      uc0162       0.00      0.00      0.00         8\n",
      "      uc0169       0.00      0.00      0.00         3\n",
      "      uc0173       0.00      0.00      0.00         1\n",
      "      uc0178       0.00      0.00      0.00         3\n",
      "      uc0179       0.00      0.00      0.00        12\n",
      "      uc0181       0.00      0.00      0.00         3\n",
      "      uc0191       0.00      0.00      0.00         8\n",
      "      uc0192       0.00      0.00      0.00         2\n",
      "      uc0200       0.00      0.00      0.00         1\n",
      "      uc0209       0.45      0.78      0.57        80\n",
      "      uc0211       0.10      0.14      0.12        28\n",
      "      uc0212       0.00      0.00      0.00        42\n",
      "      uc0215       0.00      0.00      0.00        30\n",
      "      uc0222       0.00      0.00      0.00         8\n",
      "      uc0223       0.00      0.00      0.00         1\n",
      "      uc0226       0.58      0.55      0.56        20\n",
      "      uc0229       0.00      0.00      0.00         1\n",
      "      uc0232       0.39      0.71      0.50       306\n",
      "      uc0233       0.00      0.00      0.00         1\n",
      "      uc0234       0.00      0.00      0.00         6\n",
      "      uc0235       0.00      0.00      0.00         6\n",
      "      uc0238       0.00      0.00      0.00         3\n",
      "      uc0240       0.00      0.00      0.00         4\n",
      "      uc0241       0.00      0.00      0.00         3\n",
      "      uc0242       0.00      0.00      0.00         5\n",
      "      uc0244       0.00      0.00      0.00         1\n",
      "      uc0253       0.00      0.00      0.00        10\n",
      "      uc0265       0.00      0.00      0.00         5\n",
      "      uc1003       0.00      0.00      0.00         5\n",
      "      uc1004       0.00      0.00      0.00         7\n",
      "      uc1006       0.50      0.06      0.11        17\n",
      "      uc1007       0.00      0.00      0.00         1\n",
      "      uc1009       0.00      0.00      0.00         2\n",
      "      uc1010       0.00      0.00      0.00         5\n",
      "      uc1011       0.00      0.00      0.00         2\n",
      "      uc1012       0.00      0.00      0.00         5\n",
      "      uc1013       0.00      0.00      0.00         1\n",
      "      uc1015       0.00      0.00      0.00         4\n",
      "      uc1017       0.40      0.29      0.33        14\n",
      "      uc2001       0.00      0.00      0.00        13\n",
      "      uc2002       0.75      0.32      0.45        28\n",
      "      uc2005       0.55      0.60      0.57        10\n",
      "      uc2006       0.78      0.19      0.30        37\n",
      "      uc2007       0.00      0.00      0.00        10\n",
      "      uc2008       0.40      0.25      0.31        32\n",
      "      uc2009       0.00      0.00      0.00         1\n",
      "      uc2011       0.83      0.56      0.67         9\n",
      "      uc2012       0.44      0.33      0.38        12\n",
      "      uc2014       0.00      0.00      0.00        25\n",
      "      uc2017       0.00      0.00      0.00         9\n",
      "      uc2019       0.71      0.12      0.21        40\n",
      "      uc2020       0.57      0.13      0.21        63\n",
      "      uc2021       0.00      0.00      0.00         1\n",
      "      uc2023       0.17      0.13      0.15       184\n",
      "      uc2025       0.00      0.00      0.00        24\n",
      "      uc2026       0.00      0.00      0.00        11\n",
      "      uc2027       0.38      0.26      0.31        19\n",
      "      uc2028       0.89      0.94      0.92        18\n",
      "      uc2029       0.29      0.47      0.36       224\n",
      "      uc2030       0.47      0.48      0.47        29\n",
      "      uc2031       0.00      0.00      0.00         5\n",
      "      uc2032       0.00      0.00      0.00        10\n",
      "      uc2033       0.00      0.00      0.00        88\n",
      "      uc2034       0.00      0.00      0.00        36\n",
      "      uc2036       0.35      0.21      0.26        33\n",
      "      uc2037       0.00      0.00      0.00        20\n",
      "      uc2039       0.00      0.00      0.00        35\n",
      "      uc2040       0.00      0.00      0.00        18\n",
      "      uc2041       0.00      0.00      0.00        19\n",
      "      uc2043       0.50      0.59      0.54        17\n",
      "      uc2044       0.00      0.00      0.00         2\n",
      "      uc2045       0.62      0.55      0.58        33\n",
      "      uc2046       0.00      0.00      0.00        18\n",
      "      uc2048       0.50      0.57      0.53        14\n",
      "      uc2049       0.77      0.53      0.62        19\n",
      "      uc2051       0.00      0.00      0.00         1\n",
      "      uc2053       0.40      0.20      0.27        10\n",
      "      uc2054       0.00      0.00      0.00         2\n",
      "      uc2055       0.33      0.14      0.20        14\n",
      "      uc2056       0.41      0.32      0.36        22\n",
      "      uc2059       0.26      0.82      0.39       380\n",
      "      uc2060       0.00      0.00      0.00        15\n",
      "      uc2061       0.00      0.00      0.00        22\n",
      "      uc2062       1.00      0.25      0.40        24\n",
      "      uc2063       0.80      0.92      0.86        13\n",
      "      uc2064       0.44      0.11      0.18        35\n",
      "      uc2065       0.46      0.49      0.47        35\n",
      "      uc2066       0.24      0.15      0.19        66\n",
      "      uc2067       0.00      0.00      0.00        20\n",
      "      uc2068       0.00      0.00      0.00        12\n",
      "      uc2071       0.00      0.00      0.00        19\n",
      "      uc2072       0.00      0.00      0.00         9\n",
      "      uc2073       0.38      0.38      0.38        21\n",
      "      uc2074       0.00      0.00      0.00         3\n",
      "      uc2075       0.73      0.57      0.64        14\n",
      "      uc2076       0.00      0.00      0.00        12\n",
      "      uc2077       0.00      0.00      0.00        11\n",
      "      uc2078       0.93      0.45      0.61        31\n",
      "      uc2079       0.00      0.00      0.00         7\n",
      "      uc2081       0.00      0.00      0.00         1\n",
      "      uc2082       0.62      0.67      0.64        12\n",
      "      uc2083       0.00      0.00      0.00        16\n",
      "      uc2084       0.31      0.27      0.29        15\n",
      "      uc2085       0.00      0.00      0.00         1\n",
      "      uc2086       0.00      0.00      0.00         8\n",
      "      uc2092       0.00      0.00      0.00        31\n",
      "      uc2095       0.33      0.21      0.26        19\n",
      "      uc2096       0.00      0.00      0.00        20\n",
      "      uc2101       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.33      3270\n",
      "   macro avg       0.16      0.13      0.13      3270\n",
      "weighted avg       0.28      0.33      0.26      3270\n",
      "\n",
      "🔍 Debug - Tipo de 'results': <class 'dict'>\n",
      "🔍 Debug - Chaves disponíveis: ['accuracy', 'y_pred', 'y_test', 'confusion_matrix', 'class_names', 'y_pred_proba']\n",
      "✅ Usuário usuario_07 processado com sucesso!\n",
      "\n",
      "🔄 Processando usuário 9/17: usuario_08\n",
      "----------------------------------------\n",
      "=== INICIANDO PREPROCESSAMENTO ===\n",
      "Carregando dados de: ../dados/processados/Dados_TechChallenge_Fase3.csv\n",
      "Dataset carregado: (115591, 7)\n",
      "\n",
      "Distribuição das classes:\n",
      "casoDeUso\n",
      "uc0043    13099\n",
      "uc0232     7408\n",
      "uc0096     7042\n",
      "uc0146     5042\n",
      "uc0075     3394\n",
      "uc0222     3085\n",
      "uc0162     3018\n",
      "uc0111     2963\n",
      "uc0179     2896\n",
      "uc0069     2620\n",
      "Name: count, dtype: int64\n",
      "Processando dados para usuário: usuario_08\n",
      "Registros após filtro de usuário: 3291\n",
      "Criando features históricas...\n",
      "Registros após limpeza: 3291\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso_1', 'casoDeUso_2']\n",
      "Processando features contextuais...\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "Normalizando features sequenciais...\n",
      "Dividindo dados em treino e teste...\n",
      "⚠️ Aviso: 3 classes com apenas 1 amostra:\n",
      "casoDeUso\n",
      "uc0193    1\n",
      "uc0190    1\n",
      "uc0142    1\n",
      "Name: count, dtype: int64\n",
      "Removendo classes com poucas amostras para permitir estratificação...\n",
      "Dados após filtro: 3288 amostras, 18 classes\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "✅ Divisão estratificada realizada com sucesso\n",
      "Treino: 1972 samples\n",
      "Teste: 1316 samples\n",
      "=== CRIANDO MODELO DENSE HÍBRIDO ===\n",
      "Usando Dense layers: [128, 64]\n",
      "Modelo criado e compilado!\n",
      "Parâmetros totais: 15,204\n",
      "\n",
      "\n",
      "=== ARQUITETURA DO MODELO ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,760</span> │ input_sequence[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ input_epoch[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,188</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m5,760\u001b[0m │ input_sequence[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ input_epoch[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        │      \u001b[38;5;34m1,188\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,204</span> (59.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,204\u001b[0m (59.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,204</span> (59.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,204\u001b[0m (59.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INICIANDO TREINAMENTO ===\n",
      "Epoch 1/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.2359 - loss: 2.6707 - val_accuracy: 0.5468 - val_loss: 1.6937 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4849 - loss: 1.8584 - val_accuracy: 0.5924 - val_loss: 1.5095 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5644 - loss: 1.6231 - val_accuracy: 0.5975 - val_loss: 1.4652 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5726 - loss: 1.5428 - val_accuracy: 0.5975 - val_loss: 1.4412 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5913 - loss: 1.5457 - val_accuracy: 0.6076 - val_loss: 1.4052 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5642 - loss: 1.5475 - val_accuracy: 0.6000 - val_loss: 1.4089 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5934 - loss: 1.4873 - val_accuracy: 0.6101 - val_loss: 1.3956 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6085 - loss: 1.3856 - val_accuracy: 0.6051 - val_loss: 1.3886 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5830 - loss: 1.4473 - val_accuracy: 0.6051 - val_loss: 1.3829 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5967 - loss: 1.4160 - val_accuracy: 0.6076 - val_loss: 1.3809 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5909 - loss: 1.3969 - val_accuracy: 0.6051 - val_loss: 1.3724 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5773 - loss: 1.4636 - val_accuracy: 0.6101 - val_loss: 1.3769 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5894 - loss: 1.4235 - val_accuracy: 0.6127 - val_loss: 1.3740 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6006 - loss: 1.3697 - val_accuracy: 0.6025 - val_loss: 1.3722 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6111 - loss: 1.3686 - val_accuracy: 0.6101 - val_loss: 1.3640 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5830 - loss: 1.4245 - val_accuracy: 0.6152 - val_loss: 1.3735 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5899 - loss: 1.3926 - val_accuracy: 0.6152 - val_loss: 1.3595 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6076 - loss: 1.3513 - val_accuracy: 0.6101 - val_loss: 1.3623 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5959 - loss: 1.3447 - val_accuracy: 0.6152 - val_loss: 1.3651 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5862 - loss: 1.3575 - val_accuracy: 0.6127 - val_loss: 1.3624 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5945 - loss: 1.3698 - val_accuracy: 0.6101 - val_loss: 1.3658 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m39/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5926 - loss: 1.3341\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5939 - loss: 1.3350 - val_accuracy: 0.6152 - val_loss: 1.3658 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6050 - loss: 1.3342 - val_accuracy: 0.6127 - val_loss: 1.3688 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6036 - loss: 1.3594 - val_accuracy: 0.6152 - val_loss: 1.3640 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6121 - loss: 1.3154 - val_accuracy: 0.6127 - val_loss: 1.3701 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6104 - loss: 1.3081 - val_accuracy: 0.6152 - val_loss: 1.3662 - learning_rate: 5.0000e-04\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Treinamento concluído!\n",
      "=== AVALIANDO MODELO ===\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Acurácia: 60.33%\n",
      "\n",
      "=== RELATÓRIO DE CLASSIFICAÇÃO ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      uc0043       0.00      0.00      0.00        35\n",
      "      uc0111       0.00      0.00      0.00         1\n",
      "      uc0131       0.26      0.20      0.23        44\n",
      "      uc0146       0.31      0.32      0.32       111\n",
      "      uc0162       0.31      0.27      0.29        77\n",
      "      uc0169       0.00      0.00      0.00        16\n",
      "      uc0171       0.00      0.00      0.00         4\n",
      "      uc0181       0.38      0.08      0.14        59\n",
      "      uc0187       0.00      0.00      0.00         2\n",
      "      uc0221       1.00      0.20      0.33         5\n",
      "      uc0222       0.41      0.63      0.50       169\n",
      "      uc0232       0.80      0.95      0.87       563\n",
      "      uc0233       0.00      0.00      0.00         1\n",
      "      uc0235       0.00      0.00      0.00        51\n",
      "      uc0238       0.72      0.77      0.74        47\n",
      "      uc0253       0.00      0.00      0.00        29\n",
      "      uc1003       0.00      0.00      0.00        16\n",
      "      uc1017       0.46      0.55      0.50        86\n",
      "\n",
      "    accuracy                           0.60      1316\n",
      "   macro avg       0.26      0.22      0.22      1316\n",
      "weighted avg       0.52      0.60      0.55      1316\n",
      "\n",
      "🔍 Debug - Tipo de 'results': <class 'dict'>\n",
      "🔍 Debug - Chaves disponíveis: ['accuracy', 'y_pred', 'y_test', 'confusion_matrix', 'class_names', 'y_pred_proba']\n",
      "✅ Usuário usuario_08 processado com sucesso!\n",
      "\n",
      "🔄 Processando usuário 10/17: usuario_09\n",
      "----------------------------------------\n",
      "=== INICIANDO PREPROCESSAMENTO ===\n",
      "Carregando dados de: ../dados/processados/Dados_TechChallenge_Fase3.csv\n",
      "Dataset carregado: (115591, 7)\n",
      "\n",
      "Distribuição das classes:\n",
      "casoDeUso\n",
      "uc0043    13099\n",
      "uc0232     7408\n",
      "uc0096     7042\n",
      "uc0146     5042\n",
      "uc0075     3394\n",
      "uc0222     3085\n",
      "uc0162     3018\n",
      "uc0111     2963\n",
      "uc0179     2896\n",
      "uc0069     2620\n",
      "Name: count, dtype: int64\n",
      "Processando dados para usuário: usuario_09\n",
      "Registros após filtro de usuário: 2497\n",
      "Criando features históricas...\n",
      "Registros após limpeza: 2497\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso_1', 'casoDeUso_2']\n",
      "Processando features contextuais...\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "Normalizando features sequenciais...\n",
      "Dividindo dados em treino e teste...\n",
      "⚠️ Aviso: 24 classes com apenas 1 amostra:\n",
      "casoDeUso\n",
      "uc0033    1\n",
      "uc0173    1\n",
      "uc0065    1\n",
      "uc0159    1\n",
      "uc0089    1\n",
      "Name: count, dtype: int64\n",
      "Removendo classes com poucas amostras para permitir estratificação...\n",
      "Dados após filtro: 2473 amostras, 102 classes\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "✅ Divisão estratificada realizada com sucesso\n",
      "Treino: 1483 samples\n",
      "Teste: 990 samples\n",
      "=== CRIANDO MODELO DENSE HÍBRIDO ===\n",
      "Usando Dense layers: [128, 64]\n",
      "Modelo criado e compilado!\n",
      "Parâmetros totais: 47,116\n",
      "\n",
      "\n",
      "=== ARQUITETURA DO MODELO ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,128</span> │ input_sequence[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ input_epoch[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">102</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,732</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,128\u001b[0m │ input_sequence[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ input_epoch[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m102\u001b[0m)       │      \u001b[38;5;34m6,732\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,116</span> (184.05 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m47,116\u001b[0m (184.05 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,116</span> (184.05 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m47,116\u001b[0m (184.05 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INICIANDO TREINAMENTO ===\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 21:44:25.884287: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1111', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2025-05-25 21:44:26.009468: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1113', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.0269 - loss: 4.8042 - val_accuracy: 0.1987 - val_loss: 4.2734 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2010 - loss: 4.0686 - val_accuracy: 0.2222 - val_loss: 3.8508 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2185 - loss: 3.6252 - val_accuracy: 0.2290 - val_loss: 3.6324 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2476 - loss: 3.4024 - val_accuracy: 0.2323 - val_loss: 3.5102 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2753 - loss: 3.1739 - val_accuracy: 0.2424 - val_loss: 3.4489 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2943 - loss: 3.0159 - val_accuracy: 0.2391 - val_loss: 3.4111 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3375 - loss: 2.8412 - val_accuracy: 0.2660 - val_loss: 3.3616 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3585 - loss: 2.7499 - val_accuracy: 0.2727 - val_loss: 3.3439 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3538 - loss: 2.6991 - val_accuracy: 0.2727 - val_loss: 3.3334 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3607 - loss: 2.5865 - val_accuracy: 0.2727 - val_loss: 3.3376 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4057 - loss: 2.5018 - val_accuracy: 0.2694 - val_loss: 3.3599 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4057 - loss: 2.4152 - val_accuracy: 0.2828 - val_loss: 3.3597 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3903 - loss: 2.3889 - val_accuracy: 0.2828 - val_loss: 3.3937 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m22/38\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4128 - loss: 2.3478 \n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4149 - loss: 2.3291 - val_accuracy: 0.2795 - val_loss: 3.4005 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4014 - loss: 2.3010 - val_accuracy: 0.2828 - val_loss: 3.4269 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4446 - loss: 2.1893 - val_accuracy: 0.2795 - val_loss: 3.4334 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4120 - loss: 2.3053 - val_accuracy: 0.2828 - val_loss: 3.4399 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4272 - loss: 2.2035 - val_accuracy: 0.2862 - val_loss: 3.4517 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m23/38\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4086 - loss: 2.1744 \n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4163 - loss: 2.1879 - val_accuracy: 0.2828 - val_loss: 3.4597 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4484 - loss: 2.1358 - val_accuracy: 0.2795 - val_loss: 3.4656 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4271 - loss: 2.1907 - val_accuracy: 0.2862 - val_loss: 3.4677 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4614 - loss: 2.0749 - val_accuracy: 0.2862 - val_loss: 3.4762 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4543 - loss: 2.0704 - val_accuracy: 0.2929 - val_loss: 3.4779 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m24/38\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4407 - loss: 2.1071 \n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4422 - loss: 2.1022 - val_accuracy: 0.2929 - val_loss: 3.4861 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4497 - loss: 2.0448 - val_accuracy: 0.2896 - val_loss: 3.4918 - learning_rate: 1.2500e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4522 - loss: 2.0793 - val_accuracy: 0.2862 - val_loss: 3.4940 - learning_rate: 1.2500e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4141 - loss: 2.1658 - val_accuracy: 0.2862 - val_loss: 3.4960 - learning_rate: 1.2500e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4265 - loss: 2.1056 - val_accuracy: 0.2862 - val_loss: 3.4972 - learning_rate: 1.2500e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m23/38\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4290 - loss: 2.1635 \n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4387 - loss: 2.1197 - val_accuracy: 0.2862 - val_loss: 3.5057 - learning_rate: 1.2500e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4452 - loss: 2.0419 - val_accuracy: 0.2862 - val_loss: 3.5115 - learning_rate: 6.2500e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4687 - loss: 1.9816 - val_accuracy: 0.2862 - val_loss: 3.5139 - learning_rate: 6.2500e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4206 - loss: 2.0987 - val_accuracy: 0.2862 - val_loss: 3.5165 - learning_rate: 6.2500e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4732 - loss: 1.9701 - val_accuracy: 0.2862 - val_loss: 3.5212 - learning_rate: 6.2500e-05\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Treinamento concluído!\n",
      "=== AVALIANDO MODELO ===\n",
      "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 212ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 21:44:36.340779: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_18', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-05-25 21:44:36.346458: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_18', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "Acurácia: 30.30%\n",
      "\n",
      "=== RELATÓRIO DE CLASSIFICAÇÃO ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      uc0003       0.00      0.00      0.00         1\n",
      "      uc0004       0.00      0.00      0.00         1\n",
      "      uc0006       0.00      0.00      0.00         1\n",
      "      uc0016       0.06      0.05      0.05        21\n",
      "      uc0017       0.00      0.00      0.00         2\n",
      "     uc0018b       0.25      0.10      0.14        10\n",
      "      uc0019       0.00      0.00      0.00        14\n",
      "      uc0023       0.67      1.00      0.80         8\n",
      "      uc0024       0.32      0.38      0.35        34\n",
      "      uc0025       1.00      0.50      0.67         4\n",
      "   uc0025_01       1.00      0.17      0.29        12\n",
      "      uc0026       0.00      0.00      0.00         4\n",
      "      uc0027       0.00      0.00      0.00         1\n",
      "      uc0028       0.00      0.00      0.00        11\n",
      "      uc0029       0.48      0.70      0.57        20\n",
      "      uc0030       0.35      0.69      0.47        16\n",
      "      uc0031       0.00      0.00      0.00         1\n",
      "      uc0032       0.00      0.00      0.00         3\n",
      "      uc0034       0.00      0.00      0.00         6\n",
      "      uc0036       0.33      0.25      0.29         4\n",
      "      uc0043       0.12      0.21      0.16        28\n",
      "      uc0044       0.48      0.46      0.47        24\n",
      "      uc0045       0.00      0.00      0.00        12\n",
      "      uc0047       1.00      0.29      0.44         7\n",
      "      uc0052       0.00      0.00      0.00         2\n",
      "      uc0053       0.00      0.00      0.00        13\n",
      "      uc0056       0.00      0.00      0.00         2\n",
      "      uc0058       1.00      0.08      0.15        12\n",
      "      uc0059       0.00      0.00      0.00         2\n",
      "      uc0060       0.50      0.43      0.46         7\n",
      "      uc0061       0.00      0.00      0.00         1\n",
      "      uc0068       0.00      0.00      0.00         2\n",
      "      uc0069       0.19      0.43      0.26         7\n",
      "      uc0075       0.67      1.00      0.80         4\n",
      "      uc0076       0.00      0.00      0.00         2\n",
      "      uc0077       0.00      0.00      0.00         3\n",
      "      uc0087       0.00      0.00      0.00         2\n",
      "      uc0094       0.17      0.16      0.17        25\n",
      "      uc0096       0.33      0.50      0.40       105\n",
      "      uc0097       0.00      0.00      0.00         3\n",
      "      uc0100       1.00      0.50      0.67         2\n",
      "      uc0111       0.00      0.00      0.00         1\n",
      "      uc0112       0.00      0.00      0.00         1\n",
      "      uc0114       0.00      0.00      0.00         1\n",
      "      uc0124       0.25      0.09      0.13        11\n",
      "      uc0125       0.50      1.00      0.67         1\n",
      "      uc0126       0.19      0.15      0.17        52\n",
      "      uc0127       0.00      0.00      0.00         1\n",
      "      uc0130       0.00      0.00      0.00         1\n",
      "      uc0131       0.00      0.00      0.00        21\n",
      "      uc0134       0.00      0.00      0.00         2\n",
      "      uc0137       0.00      0.00      0.00         1\n",
      "      uc0138       0.00      0.00      0.00        12\n",
      "      uc0139       0.27      0.11      0.15        28\n",
      "      uc0140       0.27      0.29      0.28        14\n",
      "      uc0146       0.00      0.00      0.00         9\n",
      "      uc0149       0.00      0.00      0.00         2\n",
      "      uc0150       0.00      0.00      0.00         8\n",
      "      uc0162       0.18      0.22      0.20        23\n",
      "      uc0165       0.00      0.00      0.00         5\n",
      "      uc0169       0.00      0.00      0.00         3\n",
      "      uc0172       0.00      0.00      0.00         1\n",
      "      uc0175       0.00      0.00      0.00         1\n",
      "      uc0178       0.00      0.00      0.00         1\n",
      "      uc0179       0.13      0.15      0.14        26\n",
      "      uc0181       0.00      0.00      0.00         1\n",
      "      uc0186       0.00      0.00      0.00         2\n",
      "      uc0190       0.00      0.00      0.00         2\n",
      "      uc0191       0.00      0.00      0.00         2\n",
      "      uc0195       0.00      0.00      0.00         2\n",
      "      uc0198       0.00      0.00      0.00         7\n",
      "      uc0201       0.14      0.06      0.08        17\n",
      "      uc0209       0.17      0.20      0.18        10\n",
      "      uc0211       0.11      0.25      0.15         4\n",
      "      uc0212       0.00      0.00      0.00         1\n",
      "      uc0215       0.00      0.00      0.00        13\n",
      "      uc0219       0.00      0.00      0.00         1\n",
      "      uc0221       0.00      0.00      0.00         1\n",
      "      uc0222       0.00      0.00      0.00         6\n",
      "      uc0226       0.00      0.00      0.00         2\n",
      "      uc0228       0.00      0.00      0.00         1\n",
      "      uc0229       0.00      0.00      0.00         1\n",
      "      uc0230       0.00      0.00      0.00         1\n",
      "      uc0232       0.36      0.62      0.46       201\n",
      "      uc0234       0.00      0.00      0.00         1\n",
      "      uc0235       0.00      0.00      0.00         5\n",
      "      uc0238       0.00      0.00      0.00         3\n",
      "      uc0243       0.00      0.00      0.00         1\n",
      "      uc0253       0.14      0.14      0.14        14\n",
      "      uc0255       0.00      0.00      0.00         1\n",
      "      uc0265       0.00      0.00      0.00         2\n",
      "      uc0266       0.00      0.00      0.00         4\n",
      "      uc1003       0.20      0.50      0.29         2\n",
      "      uc1004       0.33      0.17      0.22         6\n",
      "      uc1006       0.00      0.00      0.00         3\n",
      "      uc1007       0.00      0.00      0.00         1\n",
      "      uc1009       0.00      0.00      0.00         1\n",
      "      uc1010       0.00      0.00      0.00         1\n",
      "      uc1015       0.00      0.00      0.00         1\n",
      "      uc1017       0.00      0.00      0.00         2\n",
      "      uc2097       0.00      0.00      0.00         1\n",
      "      uc2101       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.30       990\n",
      "   macro avg       0.13      0.13      0.11       990\n",
      "weighted avg       0.25      0.30      0.25       990\n",
      "\n",
      "🔍 Debug - Tipo de 'results': <class 'dict'>\n",
      "🔍 Debug - Chaves disponíveis: ['accuracy', 'y_pred', 'y_test', 'confusion_matrix', 'class_names', 'y_pred_proba']\n",
      "✅ Usuário usuario_09 processado com sucesso!\n",
      "\n",
      "🔄 Processando usuário 11/17: usuario_10\n",
      "----------------------------------------\n",
      "=== INICIANDO PREPROCESSAMENTO ===\n",
      "Carregando dados de: ../dados/processados/Dados_TechChallenge_Fase3.csv\n",
      "Dataset carregado: (115591, 7)\n",
      "\n",
      "Distribuição das classes:\n",
      "casoDeUso\n",
      "uc0043    13099\n",
      "uc0232     7408\n",
      "uc0096     7042\n",
      "uc0146     5042\n",
      "uc0075     3394\n",
      "uc0222     3085\n",
      "uc0162     3018\n",
      "uc0111     2963\n",
      "uc0179     2896\n",
      "uc0069     2620\n",
      "Name: count, dtype: int64\n",
      "Processando dados para usuário: usuario_10\n",
      "Registros após filtro de usuário: 20070\n",
      "Criando features históricas...\n",
      "Registros após limpeza: 20070\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso_1', 'casoDeUso_2']\n",
      "Processando features contextuais...\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "Normalizando features sequenciais...\n",
      "Dividindo dados em treino e teste...\n",
      "⚠️ Aviso: 25 classes com apenas 1 amostra:\n",
      "casoDeUso\n",
      "uc0132    1\n",
      "uc1005    1\n",
      "uc0057    1\n",
      "uc0035    1\n",
      "uc0084    1\n",
      "Name: count, dtype: int64\n",
      "Removendo classes com poucas amostras para permitir estratificação...\n",
      "Dados após filtro: 20045 amostras, 161 classes\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "✅ Divisão estratificada realizada com sucesso\n",
      "Treino: 12027 samples\n",
      "Teste: 8018 samples\n",
      "=== CRIANDO MODELO DENSE HÍBRIDO ===\n",
      "Usando Dense layers: [128, 64]\n",
      "Modelo criado e compilado!\n",
      "Parâmetros totais: 66,370\n",
      "\n",
      "\n",
      "=== ARQUITETURA DO MODELO ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">370</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">47,488</span> │ input_sequence[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ input_epoch[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">161</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,626</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m370\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m47,488\u001b[0m │ input_sequence[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ input_epoch[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m161\u001b[0m)       │     \u001b[38;5;34m10,626\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">66,370</span> (259.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m66,370\u001b[0m (259.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">66,370</span> (259.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m66,370\u001b[0m (259.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INICIANDO TREINAMENTO ===\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 21:44:39.330210: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1111', 172 bytes spill stores, 172 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m284/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1351 - loss: 4.3678"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 21:44:42.326149: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1111', 112 bytes spill stores, 112 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.1378 - loss: 4.3411 - val_accuracy: 0.2452 - val_loss: 3.4101 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2455 - loss: 3.3646 - val_accuracy: 0.2860 - val_loss: 3.2037 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2709 - loss: 3.1731 - val_accuracy: 0.2984 - val_loss: 3.1127 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2979 - loss: 3.0150 - val_accuracy: 0.3109 - val_loss: 3.0438 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2892 - loss: 2.9781 - val_accuracy: 0.3117 - val_loss: 3.0119 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3072 - loss: 2.9011 - val_accuracy: 0.3130 - val_loss: 3.0093 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3101 - loss: 2.8494 - val_accuracy: 0.3180 - val_loss: 2.9905 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3078 - loss: 2.8806 - val_accuracy: 0.3175 - val_loss: 2.9896 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3206 - loss: 2.7947 - val_accuracy: 0.3101 - val_loss: 2.9908 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3248 - loss: 2.7497 - val_accuracy: 0.3184 - val_loss: 3.0044 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3169 - loss: 2.7497 - val_accuracy: 0.3159 - val_loss: 2.9971 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3202 - loss: 2.7261 - val_accuracy: 0.3167 - val_loss: 3.0000 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m284/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3304 - loss: 2.6917\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3298 - loss: 2.6930 - val_accuracy: 0.3175 - val_loss: 3.0110 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3302 - loss: 2.6869 - val_accuracy: 0.3171 - val_loss: 3.0118 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3357 - loss: 2.6498 - val_accuracy: 0.3242 - val_loss: 3.0238 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3439 - loss: 2.6140 - val_accuracy: 0.3209 - val_loss: 3.0272 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3331 - loss: 2.6058 - val_accuracy: 0.3192 - val_loss: 3.0346 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m293/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3316 - loss: 2.6097\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3316 - loss: 2.6102 - val_accuracy: 0.3217 - val_loss: 3.0302 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3344 - loss: 2.6125 - val_accuracy: 0.3192 - val_loss: 3.0375 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3304 - loss: 2.5934 - val_accuracy: 0.3200 - val_loss: 3.0400 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3418 - loss: 2.5967 - val_accuracy: 0.3192 - val_loss: 3.0438 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3414 - loss: 2.5811 - val_accuracy: 0.3184 - val_loss: 3.0489 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m294/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3437 - loss: 2.5621\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3436 - loss: 2.5622 - val_accuracy: 0.3209 - val_loss: 3.0517 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3501 - loss: 2.5536 - val_accuracy: 0.3204 - val_loss: 3.0572 - learning_rate: 1.2500e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3450 - loss: 2.5242 - val_accuracy: 0.3184 - val_loss: 3.0596 - learning_rate: 1.2500e-04\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "Treinamento concluído!\n",
      "=== AVALIANDO MODELO ===\n",
      "\u001b[1m243/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 21:45:07.989534: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_18', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-05-25 21:45:08.048467: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_18', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Acurácia: 31.17%\n",
      "\n",
      "=== RELATÓRIO DE CLASSIFICAÇÃO ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      uc0003       0.00      0.00      0.00         6\n",
      "      uc0004       0.40      0.12      0.19        32\n",
      "      uc0006       0.00      0.00      0.00         1\n",
      "      uc0012       0.00      0.00      0.00         9\n",
      "      uc0013       0.00      0.00      0.00        12\n",
      "      uc0014       0.00      0.00      0.00         2\n",
      "      uc0015       0.22      0.22      0.22         9\n",
      "      uc0016       0.17      0.09      0.12       256\n",
      "      uc0017       0.00      0.00      0.00         4\n",
      "     uc0018b       0.00      0.00      0.00        33\n",
      "      uc0019       0.00      0.00      0.00        98\n",
      "      uc0021       0.00      0.00      0.00         1\n",
      "      uc0023       0.82      1.00      0.90         9\n",
      "      uc0024       0.39      0.39      0.39       184\n",
      "      uc0025       1.00      0.50      0.67         2\n",
      "   uc0025_01       0.00      0.00      0.00        12\n",
      "      uc0026       0.00      0.00      0.00         2\n",
      "      uc0027       0.29      0.29      0.29         7\n",
      "      uc0028       0.67      0.20      0.31        10\n",
      "      uc0029       0.30      0.69      0.42        13\n",
      "      uc0030       0.70      0.47      0.56        15\n",
      "      uc0031       0.33      0.12      0.17       229\n",
      "      uc0032       0.20      0.08      0.12        12\n",
      "      uc0033       0.00      0.00      0.00        24\n",
      "      uc0034       0.00      0.00      0.00         8\n",
      "      uc0036       0.00      0.00      0.00         4\n",
      "      uc0037       0.00      0.00      0.00         1\n",
      "      uc0039       0.33      0.48      0.39        33\n",
      "      uc0040       0.46      0.50      0.48        52\n",
      "      uc0041       0.00      0.00      0.00        12\n",
      "      uc0042       0.37      0.42      0.39        26\n",
      "      uc0043       0.31      0.75      0.44      1425\n",
      "      uc0044       0.36      0.30      0.33       478\n",
      "      uc0045       0.20      0.11      0.14        19\n",
      "      uc0047       0.00      0.00      0.00        47\n",
      "      uc0049       0.25      0.15      0.19        20\n",
      "      uc0050       0.00      0.00      0.00         4\n",
      "      uc0052       0.00      0.00      0.00         2\n",
      "      uc0053       0.20      0.16      0.18       119\n",
      "      uc0056       0.00      0.00      0.00        15\n",
      "      uc0058       0.00      0.00      0.00        22\n",
      "      uc0059       0.20      0.12      0.15         8\n",
      "      uc0060       0.00      0.00      0.00         9\n",
      "      uc0061       0.00      0.00      0.00         2\n",
      "      uc0062       0.00      0.00      0.00         1\n",
      "      uc0064       0.00      0.00      0.00         1\n",
      "      uc0067       0.00      0.00      0.00         2\n",
      "      uc0068       0.00      0.00      0.00         1\n",
      "      uc0069       0.00      0.00      0.00        23\n",
      "      uc0075       0.00      0.00      0.00        10\n",
      "      uc0077       0.40      0.20      0.27        10\n",
      "      uc0078       0.00      0.00      0.00         1\n",
      "      uc0079       0.38      0.22      0.28        36\n",
      "      uc0080       0.00      0.00      0.00        10\n",
      "      uc0081       0.00      0.00      0.00         1\n",
      "      uc0085       0.00      0.00      0.00         1\n",
      "      uc0086       0.34      0.52      0.42        42\n",
      "      uc0087       0.00      0.00      0.00        73\n",
      "      uc0089       0.60      0.20      0.30        15\n",
      "      uc0090       0.00      0.00      0.00         4\n",
      "      uc0091       0.00      0.00      0.00         4\n",
      "      uc0092       0.00      0.00      0.00         2\n",
      "      uc0093       0.27      0.18      0.22        33\n",
      "      uc0094       0.12      0.04      0.06       135\n",
      "      uc0096       0.30      0.44      0.36      1128\n",
      "      uc0097       0.00      0.00      0.00         8\n",
      "      uc0098       0.37      0.33      0.35        42\n",
      "      uc0100       0.00      0.00      0.00         6\n",
      "      uc0102       0.00      0.00      0.00         2\n",
      "      uc0103       0.00      0.00      0.00         2\n",
      "      uc0105       0.00      0.00      0.00         3\n",
      "      uc0107       0.43      0.33      0.38        27\n",
      "      uc0108       0.62      0.73      0.67        11\n",
      "      uc0109       0.00      0.00      0.00        34\n",
      "      uc0110       0.00      0.00      0.00         5\n",
      "      uc0111       0.20      0.01      0.01       140\n",
      "      uc0112       0.00      0.00      0.00         5\n",
      "      uc0113       0.00      0.00      0.00         3\n",
      "      uc0114       0.00      0.00      0.00        11\n",
      "      uc0115       0.00      0.00      0.00        12\n",
      "      uc0116       0.33      0.10      0.15        20\n",
      "      uc0117       0.48      0.71      0.57        17\n",
      "      uc0118       0.00      0.00      0.00        51\n",
      "      uc0124       0.08      0.08      0.08        13\n",
      "      uc0125       0.00      0.00      0.00         1\n",
      "      uc0126       0.24      0.06      0.10       134\n",
      "      uc0127       0.00      0.00      0.00         1\n",
      "      uc0128       0.00      0.00      0.00         6\n",
      "      uc0130       0.00      0.00      0.00        13\n",
      "      uc0131       0.25      0.06      0.10        48\n",
      "      uc0133       0.00      0.00      0.00         4\n",
      "      uc0134       0.00      0.00      0.00        40\n",
      "      uc0135       0.00      0.00      0.00        56\n",
      "      uc0136       0.00      0.00      0.00         1\n",
      "      uc0137       0.25      0.30      0.27        10\n",
      "      uc0138       0.00      0.00      0.00        18\n",
      "      uc0139       0.43      0.17      0.24        71\n",
      "      uc0141       0.25      0.50      0.33         8\n",
      "      uc0146       0.00      0.00      0.00        37\n",
      "      uc0148       0.00      0.00      0.00         1\n",
      "      uc0149       0.50      0.08      0.14        37\n",
      "      uc0150       0.17      0.09      0.12       125\n",
      "      uc0153       0.00      0.00      0.00        11\n",
      "      uc0157       0.44      0.44      0.44         9\n",
      "      uc0158       0.00      0.00      0.00         1\n",
      "      uc0159       0.25      0.50      0.33         2\n",
      "      uc0161       0.00      0.00      0.00         2\n",
      "      uc0162       0.24      0.11      0.15        71\n",
      "      uc0164       0.00      0.00      0.00         1\n",
      "      uc0165       0.41      0.23      0.29        71\n",
      "      uc0167       0.12      0.10      0.11        10\n",
      "      uc0169       0.50      0.11      0.18        36\n",
      "      uc0171       0.00      0.00      0.00         3\n",
      "      uc0173       0.00      0.00      0.00         2\n",
      "      uc0175       0.00      0.00      0.00         2\n",
      "      uc0178       0.00      0.00      0.00         8\n",
      "      uc0179       0.21      0.08      0.12       352\n",
      "      uc0181       0.21      0.04      0.07        75\n",
      "      uc0186       0.00      0.00      0.00        12\n",
      "      uc0187       0.20      0.07      0.11        14\n",
      "      uc0189       0.38      0.25      0.30        24\n",
      "      uc0190       0.21      0.29      0.24        34\n",
      "      uc0191       0.00      0.00      0.00         3\n",
      "      uc0193       0.14      0.07      0.09        29\n",
      "      uc0195       0.40      0.52      0.45        33\n",
      "      uc0198       0.00      0.00      0.00        54\n",
      "      uc0209       0.24      0.10      0.14       268\n",
      "      uc0211       0.00      0.00      0.00         7\n",
      "      uc0212       0.30      0.38      0.33         8\n",
      "      uc0215       0.50      0.02      0.04        43\n",
      "      uc0216       0.31      0.48      0.38       114\n",
      "      uc0219       0.39      0.69      0.50        83\n",
      "      uc0220       0.47      0.57      0.51        65\n",
      "      uc0221       0.33      0.11      0.17        44\n",
      "      uc0222       0.49      0.31      0.38       277\n",
      "      uc0223       0.00      0.00      0.00         1\n",
      "      uc0226       0.29      0.17      0.21        12\n",
      "      uc0229       0.18      0.16      0.17        51\n",
      "      uc0230       0.42      0.16      0.24        61\n",
      "      uc0232       0.15      0.02      0.04        99\n",
      "      uc0233       0.00      0.00      0.00         4\n",
      "      uc0234       0.00      0.00      0.00         2\n",
      "      uc0235       0.19      0.12      0.14        52\n",
      "      uc0238       0.00      0.00      0.00        12\n",
      "      uc0242       0.00      0.00      0.00         1\n",
      "      uc0243       0.00      0.00      0.00         9\n",
      "      uc1003       0.20      0.25      0.22         4\n",
      "      uc1004       0.00      0.00      0.00         3\n",
      "      uc1006       0.00      0.00      0.00         4\n",
      "      uc1007       0.00      0.00      0.00         1\n",
      "      uc1008       0.00      0.00      0.00         2\n",
      "      uc1009       0.00      0.00      0.00         2\n",
      "      uc1010       0.00      0.00      0.00         2\n",
      "      uc1011       0.00      0.00      0.00         3\n",
      "      uc1012       0.00      0.00      0.00         2\n",
      "      uc1013       0.00      0.00      0.00         2\n",
      "      uc1014       0.00      0.00      0.00         8\n",
      "      uc1016       0.00      0.00      0.00         5\n",
      "      uc1017       0.39      0.29      0.33        58\n",
      "      uc1018       0.00      0.00      0.00         5\n",
      "      uc1019       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.31      8018\n",
      "   macro avg       0.15      0.12      0.12      8018\n",
      "weighted avg       0.27      0.31      0.26      8018\n",
      "\n",
      "🔍 Debug - Tipo de 'results': <class 'dict'>\n",
      "🔍 Debug - Chaves disponíveis: ['accuracy', 'y_pred', 'y_test', 'confusion_matrix', 'class_names', 'y_pred_proba']\n",
      "✅ Usuário usuario_10 processado com sucesso!\n",
      "\n",
      "🔄 Processando usuário 12/17: usuario_11\n",
      "----------------------------------------\n",
      "=== INICIANDO PREPROCESSAMENTO ===\n",
      "Carregando dados de: ../dados/processados/Dados_TechChallenge_Fase3.csv\n",
      "Dataset carregado: (115591, 7)\n",
      "\n",
      "Distribuição das classes:\n",
      "casoDeUso\n",
      "uc0043    13099\n",
      "uc0232     7408\n",
      "uc0096     7042\n",
      "uc0146     5042\n",
      "uc0075     3394\n",
      "uc0222     3085\n",
      "uc0162     3018\n",
      "uc0111     2963\n",
      "uc0179     2896\n",
      "uc0069     2620\n",
      "Name: count, dtype: int64\n",
      "Processando dados para usuário: usuario_11\n",
      "Registros após filtro de usuário: 298\n",
      "Criando features históricas...\n",
      "Registros após limpeza: 298\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso_1', 'casoDeUso_2']\n",
      "Processando features contextuais...\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "Normalizando features sequenciais...\n",
      "Dividindo dados em treino e teste...\n",
      "⚠️ Aviso: 6 classes com apenas 1 amostra:\n",
      "casoDeUso\n",
      "uc2045    1\n",
      "uc2002    1\n",
      "uc2044    1\n",
      "uc2008    1\n",
      "uc2082    1\n",
      "Name: count, dtype: int64\n",
      "Removendo classes com poucas amostras para permitir estratificação...\n",
      "Dados após filtro: 292 amostras, 21 classes\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "✅ Divisão estratificada realizada com sucesso\n",
      "Treino: 175 samples\n",
      "Teste: 117 samples\n",
      "=== CRIANDO MODELO DENSE HÍBRIDO ===\n",
      "Usando Dense layers: [128, 64]\n",
      "Modelo criado e compilado!\n",
      "Parâmetros totais: 14,634\n",
      "\n",
      "\n",
      "=== ARQUITETURA DO MODELO ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_12\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_12\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,992</span> │ input_sequence[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ input_epoch[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,386</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m4,992\u001b[0m │ input_sequence[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ input_epoch[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)        │      \u001b[38;5;34m1,386\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,634</span> (57.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,634\u001b[0m (57.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,634</span> (57.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,634\u001b[0m (57.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INICIANDO TREINAMENTO ===\n",
      "Epoch 1/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 530ms/step - accuracy: 0.0865 - loss: 3.2064 - val_accuracy: 0.1714 - val_loss: 3.0030 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1574 - loss: 2.9941 - val_accuracy: 0.2000 - val_loss: 2.9405 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2635 - loss: 2.9251 - val_accuracy: 0.2571 - val_loss: 2.8917 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3250 - loss: 2.7527 - val_accuracy: 0.2571 - val_loss: 2.8466 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3640 - loss: 2.6570 - val_accuracy: 0.2571 - val_loss: 2.8080 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4074 - loss: 2.5950 - val_accuracy: 0.2286 - val_loss: 2.7733 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4503 - loss: 2.3952 - val_accuracy: 0.2286 - val_loss: 2.7472 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4666 - loss: 2.3375 - val_accuracy: 0.2286 - val_loss: 2.7236 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4876 - loss: 2.2407 - val_accuracy: 0.2286 - val_loss: 2.7099 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4581 - loss: 2.1474 - val_accuracy: 0.2286 - val_loss: 2.7115 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5091 - loss: 2.0912 - val_accuracy: 0.2286 - val_loss: 2.7294 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4941 - loss: 2.0203 - val_accuracy: 0.2286 - val_loss: 2.7600 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4859 - loss: 2.0124 - val_accuracy: 0.2286 - val_loss: 2.7827 - learning_rate: 0.0010\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Treinamento concluído!\n",
      "=== AVALIANDO MODELO ===\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "Acurácia: 30.77%\n",
      "\n",
      "=== RELATÓRIO DE CLASSIFICAÇÃO ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      uc0114       0.00      0.00      0.00         1\n",
      "      uc0232       0.00      0.00      0.00         3\n",
      "      uc2023       0.43      0.80      0.56        40\n",
      "      uc2025       0.00      0.00      0.00         1\n",
      "      uc2029       0.12      0.11      0.12        18\n",
      "      uc2030       0.00      0.00      0.00         1\n",
      "      uc2031       0.00      0.00      0.00         7\n",
      "      uc2032       0.00      0.00      0.00         1\n",
      "      uc2033       0.09      0.09      0.09        11\n",
      "      uc2034       0.00      0.00      0.00         7\n",
      "      uc2036       0.00      0.00      0.00         2\n",
      "      uc2040       0.00      0.00      0.00         1\n",
      "      uc2041       0.00      0.00      0.00         1\n",
      "      uc2056       0.00      0.00      0.00         1\n",
      "      uc2061       0.00      0.00      0.00         6\n",
      "      uc2062       0.00      0.00      0.00         2\n",
      "      uc2074       0.00      0.00      0.00         2\n",
      "      uc2075       0.00      0.00      0.00         3\n",
      "      uc2083       0.20      0.33      0.25         3\n",
      "      uc2086       0.00      0.00      0.00         4\n",
      "      uc2092       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.31       117\n",
      "   macro avg       0.04      0.06      0.05       117\n",
      "weighted avg       0.18      0.31      0.22       117\n",
      "\n",
      "🔍 Debug - Tipo de 'results': <class 'dict'>\n",
      "🔍 Debug - Chaves disponíveis: ['accuracy', 'y_pred', 'y_test', 'confusion_matrix', 'class_names', 'y_pred_proba']\n",
      "✅ Usuário usuario_11 processado com sucesso!\n",
      "\n",
      "🔄 Processando usuário 13/17: usuario_12\n",
      "----------------------------------------\n",
      "=== INICIANDO PREPROCESSAMENTO ===\n",
      "Carregando dados de: ../dados/processados/Dados_TechChallenge_Fase3.csv\n",
      "Dataset carregado: (115591, 7)\n",
      "\n",
      "Distribuição das classes:\n",
      "casoDeUso\n",
      "uc0043    13099\n",
      "uc0232     7408\n",
      "uc0096     7042\n",
      "uc0146     5042\n",
      "uc0075     3394\n",
      "uc0222     3085\n",
      "uc0162     3018\n",
      "uc0111     2963\n",
      "uc0179     2896\n",
      "uc0069     2620\n",
      "Name: count, dtype: int64\n",
      "Processando dados para usuário: usuario_12\n",
      "Registros após filtro de usuário: 295\n",
      "Criando features históricas...\n",
      "Registros após limpeza: 295\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso_1', 'casoDeUso_2']\n",
      "Processando features contextuais...\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "Normalizando features sequenciais...\n",
      "Dividindo dados em treino e teste...\n",
      "⚠️ Aviso: 14 classes com apenas 1 amostra:\n",
      "casoDeUso\n",
      "uc2037    1\n",
      "uc2020    1\n",
      "uc2012    1\n",
      "uc2014    1\n",
      "uc2011    1\n",
      "Name: count, dtype: int64\n",
      "Removendo classes com poucas amostras para permitir estratificação...\n",
      "Dados após filtro: 281 amostras, 17 classes\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "✅ Divisão estratificada realizada com sucesso\n",
      "Treino: 168 samples\n",
      "Teste: 113 samples\n",
      "=== CRIANDO MODELO DENSE HÍBRIDO ===\n",
      "Usando Dense layers: [128, 64]\n",
      "Modelo criado e compilado!\n",
      "Parâmetros totais: 16,290\n",
      "\n",
      "\n",
      "=== ARQUITETURA DO MODELO ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">53</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,912</span> │ input_sequence[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ input_epoch[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,122</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m53\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m6,912\u001b[0m │ input_sequence[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ input_epoch[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m)        │      \u001b[38;5;34m1,122\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,290</span> (63.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,290\u001b[0m (63.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,290</span> (63.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,290\u001b[0m (63.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INICIANDO TREINAMENTO ===\n",
      "Epoch 1/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 504ms/step - accuracy: 0.0268 - loss: 3.0385 - val_accuracy: 0.0588 - val_loss: 2.9228 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1162 - loss: 2.8203 - val_accuracy: 0.1176 - val_loss: 2.8403 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1538 - loss: 2.7585 - val_accuracy: 0.1765 - val_loss: 2.7673 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2180 - loss: 2.5653 - val_accuracy: 0.2941 - val_loss: 2.6950 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2809 - loss: 2.4581 - val_accuracy: 0.2941 - val_loss: 2.6221 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3712 - loss: 2.3156 - val_accuracy: 0.2941 - val_loss: 2.5478 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2843 - loss: 2.2615 - val_accuracy: 0.2941 - val_loss: 2.4788 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2656 - loss: 2.1580 - val_accuracy: 0.2941 - val_loss: 2.4148 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3536 - loss: 1.9729 - val_accuracy: 0.2941 - val_loss: 2.3513 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3881 - loss: 1.8608 - val_accuracy: 0.2941 - val_loss: 2.2892 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3327 - loss: 1.8383 - val_accuracy: 0.3529 - val_loss: 2.2361 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3498 - loss: 1.7878 - val_accuracy: 0.3529 - val_loss: 2.2045 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3993 - loss: 1.7468 - val_accuracy: 0.3529 - val_loss: 2.1802 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3631 - loss: 1.5289 - val_accuracy: 0.3529 - val_loss: 2.1668 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4104 - loss: 1.6219 - val_accuracy: 0.3529 - val_loss: 2.1529 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4160 - loss: 1.5627 - val_accuracy: 0.3529 - val_loss: 2.1459 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3683 - loss: 1.5829 - val_accuracy: 0.2647 - val_loss: 2.1283 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3945 - loss: 1.5511 - val_accuracy: 0.2647 - val_loss: 2.0974 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3570 - loss: 1.5559 - val_accuracy: 0.3529 - val_loss: 2.0699 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3936 - loss: 1.5799 - val_accuracy: 0.3529 - val_loss: 2.0604 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3686 - loss: 1.5409 - val_accuracy: 0.3529 - val_loss: 2.0677 - learning_rate: 0.0010\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Treinamento concluído!\n",
      "=== AVALIANDO MODELO ===\n",
      "WARNING:tensorflow:5 out of the last 256 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fd45170e0c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 180ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 21:45:20.904431: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_18', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-05-25 21:45:20.916400: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_18', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 190ms/step\n",
      "Acurácia: 38.05%\n",
      "\n",
      "=== RELATÓRIO DE CLASSIFICAÇÃO ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      uc0096       0.90      0.35      0.50        26\n",
      "      uc0114       0.67      0.08      0.15        24\n",
      "      uc0235       0.32      0.97      0.48        32\n",
      "      uc2001       0.00      0.00      0.00         1\n",
      "      uc2002       0.00      0.00      0.00         1\n",
      "      uc2023       0.00      0.00      0.00         2\n",
      "      uc2029       0.00      0.00      0.00         1\n",
      "      uc2031       0.00      0.00      0.00         1\n",
      "      uc2032       0.00      0.00      0.00         1\n",
      "      uc2033       0.00      0.00      0.00         3\n",
      "      uc2036       0.00      0.00      0.00         1\n",
      "      uc2045       0.00      0.00      0.00         1\n",
      "      uc2059       0.00      0.00      0.00         1\n",
      "      uc2061       0.50      1.00      0.67         1\n",
      "      uc2074       0.00      0.00      0.00         2\n",
      "      uc2075       0.00      0.00      0.00         1\n",
      "      uc2093       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.38       113\n",
      "   macro avg       0.14      0.14      0.11       113\n",
      "weighted avg       0.44      0.38      0.29       113\n",
      "\n",
      "🔍 Debug - Tipo de 'results': <class 'dict'>\n",
      "🔍 Debug - Chaves disponíveis: ['accuracy', 'y_pred', 'y_test', 'confusion_matrix', 'class_names', 'y_pred_proba']\n",
      "✅ Usuário usuario_12 processado com sucesso!\n",
      "\n",
      "🔄 Processando usuário 14/17: usuario_13\n",
      "----------------------------------------\n",
      "=== INICIANDO PREPROCESSAMENTO ===\n",
      "Carregando dados de: ../dados/processados/Dados_TechChallenge_Fase3.csv\n",
      "Dataset carregado: (115591, 7)\n",
      "\n",
      "Distribuição das classes:\n",
      "casoDeUso\n",
      "uc0043    13099\n",
      "uc0232     7408\n",
      "uc0096     7042\n",
      "uc0146     5042\n",
      "uc0075     3394\n",
      "uc0222     3085\n",
      "uc0162     3018\n",
      "uc0111     2963\n",
      "uc0179     2896\n",
      "uc0069     2620\n",
      "Name: count, dtype: int64\n",
      "Processando dados para usuário: usuario_13\n",
      "Registros após filtro de usuário: 389\n",
      "Criando features históricas...\n",
      "Registros após limpeza: 389\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso_1', 'casoDeUso_2']\n",
      "Processando features contextuais...\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "Normalizando features sequenciais...\n",
      "Dividindo dados em treino e teste...\n",
      "✅ Divisão estratificada realizada com sucesso\n",
      "Treino: 233 samples\n",
      "Teste: 156 samples\n",
      "=== CRIANDO MODELO DENSE HÍBRIDO ===\n",
      "Usando Dense layers: [128, 64]\n",
      "Modelo criado e compilado!\n",
      "Parâmetros totais: 10,250\n",
      "\n",
      "\n",
      "=== ARQUITETURA DO MODELO ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_14\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_14\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,664</span> │ input_sequence[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ input_epoch[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m1,664\u001b[0m │ input_sequence[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ input_epoch[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │        \u001b[38;5;34m330\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,250</span> (40.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,250\u001b[0m (40.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,250</span> (40.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,250\u001b[0m (40.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INICIANDO TREINAMENTO ===\n",
      "Epoch 1/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 378ms/step - accuracy: 0.2626 - loss: 1.6610 - val_accuracy: 0.2766 - val_loss: 1.4707 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4880 - loss: 1.4541 - val_accuracy: 0.7021 - val_loss: 1.3379 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5719 - loss: 1.3323 - val_accuracy: 0.7021 - val_loss: 1.2216 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5974 - loss: 1.3074 - val_accuracy: 0.7021 - val_loss: 1.1188 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6731 - loss: 1.1354 - val_accuracy: 0.7021 - val_loss: 1.0278 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6937 - loss: 1.0480 - val_accuracy: 0.7021 - val_loss: 0.9485 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7081 - loss: 0.9456 - val_accuracy: 0.7021 - val_loss: 0.8869 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7173 - loss: 0.8987 - val_accuracy: 0.7021 - val_loss: 0.8402 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7215 - loss: 0.8162 - val_accuracy: 0.7021 - val_loss: 0.7986 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6826 - loss: 0.8402 - val_accuracy: 0.7021 - val_loss: 0.7653 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7113 - loss: 0.8028 - val_accuracy: 0.7021 - val_loss: 0.7342 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7094 - loss: 0.7808 - val_accuracy: 0.7021 - val_loss: 0.7164 - learning_rate: 0.0010\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "Treinamento concluído!\n",
      "=== AVALIANDO MODELO ===\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Acurácia: 62.82%\n",
      "\n",
      "=== RELATÓRIO DE CLASSIFICAÇÃO ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      uc0232       0.54      0.17      0.26        41\n",
      "      uc2087       0.70      0.93      0.80        96\n",
      "      uc2088       0.00      0.00      0.00         3\n",
      "      uc2089       0.22      0.22      0.22         9\n",
      "      uc2090       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.63       156\n",
      "   macro avg       0.29      0.26      0.26       156\n",
      "weighted avg       0.59      0.63      0.57       156\n",
      "\n",
      "🔍 Debug - Tipo de 'results': <class 'dict'>\n",
      "🔍 Debug - Chaves disponíveis: ['accuracy', 'y_pred', 'y_test', 'confusion_matrix', 'class_names', 'y_pred_proba']\n",
      "✅ Usuário usuario_13 processado com sucesso!\n",
      "\n",
      "🔄 Processando usuário 15/17: usuario_14\n",
      "----------------------------------------\n",
      "=== INICIANDO PREPROCESSAMENTO ===\n",
      "Carregando dados de: ../dados/processados/Dados_TechChallenge_Fase3.csv\n",
      "Dataset carregado: (115591, 7)\n",
      "\n",
      "Distribuição das classes:\n",
      "casoDeUso\n",
      "uc0043    13099\n",
      "uc0232     7408\n",
      "uc0096     7042\n",
      "uc0146     5042\n",
      "uc0075     3394\n",
      "uc0222     3085\n",
      "uc0162     3018\n",
      "uc0111     2963\n",
      "uc0179     2896\n",
      "uc0069     2620\n",
      "Name: count, dtype: int64\n",
      "Processando dados para usuário: usuario_14\n",
      "Registros após filtro de usuário: 13695\n",
      "Criando features históricas...\n",
      "Registros após limpeza: 13695\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso_1', 'casoDeUso_2']\n",
      "Processando features contextuais...\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "Normalizando features sequenciais...\n",
      "Dividindo dados em treino e teste...\n",
      "⚠️ Aviso: 15 classes com apenas 1 amostra:\n",
      "casoDeUso\n",
      "uc0118    1\n",
      "uc0033    1\n",
      "uc0246    1\n",
      "uc0243    1\n",
      "uc0172    1\n",
      "Name: count, dtype: int64\n",
      "Removendo classes com poucas amostras para permitir estratificação...\n",
      "Dados após filtro: 13680 amostras, 120 classes\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "✅ Divisão estratificada realizada com sucesso\n",
      "Treino: 8208 samples\n",
      "Teste: 5472 samples\n",
      "=== CRIANDO MODELO DENSE HÍBRIDO ===\n",
      "Usando Dense layers: [128, 64]\n",
      "Modelo criado e compilado!\n",
      "Parâmetros totais: 50,992\n",
      "\n",
      "\n",
      "=== ARQUITETURA DO MODELO ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_15\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_15\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">271</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">34,816</span> │ input_sequence[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ input_epoch[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,920</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m271\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m34,816\u001b[0m │ input_sequence[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ input_epoch[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)       │      \u001b[38;5;34m7,920\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,992</span> (199.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,992\u001b[0m (199.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,992</span> (199.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,992\u001b[0m (199.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INICIANDO TREINAMENTO ===\n",
      "Epoch 1/50\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.1749 - loss: 4.2135 - val_accuracy: 0.2795 - val_loss: 3.2319 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2976 - loss: 3.1731 - val_accuracy: 0.3197 - val_loss: 3.0264 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3283 - loss: 3.0114 - val_accuracy: 0.3356 - val_loss: 2.9445 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3475 - loss: 2.8628 - val_accuracy: 0.3526 - val_loss: 2.8931 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3444 - loss: 2.7755 - val_accuracy: 0.3557 - val_loss: 2.8687 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3663 - loss: 2.6906 - val_accuracy: 0.3618 - val_loss: 2.8450 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3523 - loss: 2.6972 - val_accuracy: 0.3593 - val_loss: 2.8330 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3666 - loss: 2.6054 - val_accuracy: 0.3630 - val_loss: 2.8419 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3633 - loss: 2.5718 - val_accuracy: 0.3587 - val_loss: 2.8423 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3690 - loss: 2.5444 - val_accuracy: 0.3575 - val_loss: 2.8445 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3741 - loss: 2.5506 - val_accuracy: 0.3618 - val_loss: 2.8532 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m188/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3839 - loss: 2.5003\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3827 - loss: 2.5024 - val_accuracy: 0.3611 - val_loss: 2.8633 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3846 - loss: 2.4453 - val_accuracy: 0.3581 - val_loss: 2.8638 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3970 - loss: 2.4076 - val_accuracy: 0.3624 - val_loss: 2.8704 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3882 - loss: 2.4169 - val_accuracy: 0.3593 - val_loss: 2.8807 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3891 - loss: 2.4235 - val_accuracy: 0.3642 - val_loss: 2.8920 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m191/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3888 - loss: 2.4388\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3885 - loss: 2.4384 - val_accuracy: 0.3581 - val_loss: 2.8869 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3961 - loss: 2.3761 - val_accuracy: 0.3630 - val_loss: 2.8981 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3834 - loss: 2.4055 - val_accuracy: 0.3569 - val_loss: 2.8975 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3993 - loss: 2.3748 - val_accuracy: 0.3563 - val_loss: 2.9034 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3887 - loss: 2.3799 - val_accuracy: 0.3569 - val_loss: 2.9051 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m200/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3977 - loss: 2.3761\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3974 - loss: 2.3766 - val_accuracy: 0.3581 - val_loss: 2.9071 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3887 - loss: 2.3551 - val_accuracy: 0.3587 - val_loss: 2.9104 - learning_rate: 1.2500e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3875 - loss: 2.3816 - val_accuracy: 0.3581 - val_loss: 2.9137 - learning_rate: 1.2500e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3954 - loss: 2.3717 - val_accuracy: 0.3575 - val_loss: 2.9191 - learning_rate: 1.2500e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3984 - loss: 2.3749 - val_accuracy: 0.3575 - val_loss: 2.9230 - learning_rate: 1.2500e-04\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Treinamento concluído!\n",
      "=== AVALIANDO MODELO ===\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Acurácia: 35.64%\n",
      "\n",
      "=== RELATÓRIO DE CLASSIFICAÇÃO ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      uc0012       0.00      0.00      0.00         2\n",
      "      uc0013       0.00      0.00      0.00         1\n",
      "      uc0015       0.00      0.00      0.00         2\n",
      "      uc0016       0.33      0.02      0.03        60\n",
      "      uc0017       0.22      0.07      0.10        30\n",
      "     uc0018b       0.14      0.08      0.10        26\n",
      "      uc0019       0.00      0.00      0.00        67\n",
      "      uc0031       0.89      0.53      0.67        15\n",
      "      uc0036       0.00      0.00      0.00         2\n",
      "      uc0039       0.18      0.33      0.23         9\n",
      "      uc0040       0.00      0.00      0.00        13\n",
      "      uc0041       0.00      0.00      0.00         2\n",
      "      uc0042       0.67      0.53      0.59        15\n",
      "      uc0043       0.25      0.21      0.23       241\n",
      "      uc0044       0.43      0.38      0.40        47\n",
      "      uc0045       0.18      0.06      0.09        33\n",
      "      uc0047       0.25      0.11      0.15         9\n",
      "      uc0052       0.00      0.00      0.00         8\n",
      "      uc0053       0.24      0.08      0.12        61\n",
      "      uc0054       0.00      0.00      0.00         2\n",
      "      uc0056       0.00      0.00      0.00        16\n",
      "      uc0058       0.00      0.00      0.00        36\n",
      "      uc0059       0.00      0.00      0.00        27\n",
      "      uc0060       0.12      0.10      0.11        30\n",
      "      uc0061       0.00      0.00      0.00         4\n",
      "      uc0062       0.00      0.00      0.00         4\n",
      "      uc0065       0.00      0.00      0.00         2\n",
      "      uc0067       0.00      0.00      0.00         2\n",
      "      uc0068       0.22      0.11      0.14        19\n",
      "      uc0069       0.36      0.55      0.44       151\n",
      "      uc0075       0.44      0.47      0.46       199\n",
      "      uc0076       0.00      0.00      0.00        30\n",
      "      uc0077       0.32      0.27      0.30       135\n",
      "      uc0079       0.00      0.00      0.00        13\n",
      "      uc0080       0.00      0.00      0.00         2\n",
      "      uc0085       0.00      0.00      0.00         2\n",
      "      uc0086       0.64      0.44      0.52        16\n",
      "      uc0087       0.00      0.00      0.00        13\n",
      "      uc0090       0.25      0.15      0.19        13\n",
      "      uc0091       0.33      0.17      0.22         6\n",
      "      uc0094       0.33      0.13      0.18       117\n",
      "      uc0096       0.00      0.00      0.00        17\n",
      "      uc0097       0.00      0.00      0.00        15\n",
      "      uc0098       0.70      0.78      0.74         9\n",
      "      uc0099       0.00      0.00      0.00         2\n",
      "      uc0100       0.42      0.50      0.45        10\n",
      "      uc0102       0.00      0.00      0.00         3\n",
      "      uc0103       0.00      0.00      0.00         4\n",
      "      uc0107       0.45      0.63      0.52        43\n",
      "      uc0108       0.00      0.00      0.00         2\n",
      "      uc0110       0.00      0.00      0.00         4\n",
      "      uc0111       0.00      0.00      0.00        31\n",
      "      uc0112       0.00      0.00      0.00         2\n",
      "      uc0113       0.00      0.00      0.00         7\n",
      "      uc0114       0.00      0.00      0.00        16\n",
      "      uc0115       0.00      0.00      0.00         3\n",
      "      uc0124       0.55      0.14      0.22       160\n",
      "      uc0125       0.33      0.65      0.44        20\n",
      "      uc0126       0.00      0.00      0.00         2\n",
      "      uc0128       0.00      0.00      0.00         2\n",
      "      uc0130       0.00      0.00      0.00         1\n",
      "      uc0131       0.20      0.02      0.04        45\n",
      "      uc0134       0.00      0.00      0.00        67\n",
      "      uc0136       0.00      0.00      0.00         1\n",
      "      uc0137       0.00      0.00      0.00         1\n",
      "      uc0140       0.00      0.00      0.00        17\n",
      "      uc0146       0.20      0.22      0.21       288\n",
      "      uc0150       0.00      0.00      0.00        46\n",
      "      uc0153       0.05      0.08      0.06        12\n",
      "      uc0162       0.21      0.20      0.21        93\n",
      "      uc0167       0.00      0.00      0.00         4\n",
      "      uc0169       0.25      0.05      0.08        21\n",
      "      uc0171       0.00      0.00      0.00         3\n",
      "      uc0173       0.00      0.00      0.00         1\n",
      "      uc0178       0.00      0.00      0.00         4\n",
      "      uc0179       0.10      0.07      0.08       105\n",
      "      uc0180       0.00      0.00      0.00         9\n",
      "      uc0181       0.00      0.00      0.00       174\n",
      "      uc0187       0.00      0.00      0.00         1\n",
      "      uc0189       0.00      0.00      0.00         2\n",
      "      uc0190       0.00      0.00      0.00        23\n",
      "      uc0191       0.00      0.00      0.00         9\n",
      "      uc0193       0.00      0.00      0.00        10\n",
      "      uc0195       0.84      0.75      0.79        28\n",
      "      uc0209       1.00      0.22      0.36         9\n",
      "      uc0211       0.25      0.05      0.08        84\n",
      "      uc0212       0.00      0.00      0.00        54\n",
      "      uc0215       0.19      0.08      0.11       171\n",
      "      uc0217       0.00      0.00      0.00         2\n",
      "      uc0221       0.50      0.39      0.44        18\n",
      "      uc0222       0.30      0.43      0.35       425\n",
      "      uc0223       0.00      0.00      0.00         6\n",
      "      uc0226       0.54      0.79      0.64        62\n",
      "      uc0229       0.49      0.57      0.52        30\n",
      "      uc0232       0.40      0.77      0.52      1328\n",
      "      uc0233       0.00      0.00      0.00         9\n",
      "      uc0234       0.00      0.00      0.00        16\n",
      "      uc0235       0.00      0.00      0.00        74\n",
      "      uc0238       0.53      0.79      0.64        43\n",
      "      uc0240       0.00      0.00      0.00        14\n",
      "      uc0241       0.00      0.00      0.00         8\n",
      "      uc0242       0.00      0.00      0.00        13\n",
      "      uc0253       0.00      0.00      0.00         3\n",
      "      uc0255       0.00      0.00      0.00         9\n",
      "      uc0256       0.00      0.00      0.00         1\n",
      "      uc0265       0.00      0.00      0.00         9\n",
      "      uc1003       0.20      0.11      0.14        36\n",
      "      uc1004       0.00      0.00      0.00        20\n",
      "      uc1006       0.00      0.00      0.00        30\n",
      "      uc1007       0.00      0.00      0.00         4\n",
      "      uc1009       0.00      0.00      0.00         5\n",
      "      uc1010       0.40      0.29      0.33         7\n",
      "      uc1011       0.36      0.50      0.42        10\n",
      "      uc1012       0.00      0.00      0.00         6\n",
      "      uc1013       0.00      0.00      0.00         4\n",
      "      uc1014       0.00      0.00      0.00         1\n",
      "      uc1015       0.21      0.20      0.21        15\n",
      "      uc1016       0.00      0.00      0.00         8\n",
      "      uc1017       0.41      0.47      0.44       131\n",
      "      uc2101       0.73      1.00      0.84         8\n",
      "\n",
      "    accuracy                           0.36      5472\n",
      "   macro avg       0.15      0.13      0.13      5472\n",
      "weighted avg       0.28      0.36      0.29      5472\n",
      "\n",
      "🔍 Debug - Tipo de 'results': <class 'dict'>\n",
      "🔍 Debug - Chaves disponíveis: ['accuracy', 'y_pred', 'y_test', 'confusion_matrix', 'class_names', 'y_pred_proba']\n",
      "✅ Usuário usuario_14 processado com sucesso!\n",
      "\n",
      "🔄 Processando usuário 16/17: usuario_15\n",
      "----------------------------------------\n",
      "=== INICIANDO PREPROCESSAMENTO ===\n",
      "Carregando dados de: ../dados/processados/Dados_TechChallenge_Fase3.csv\n",
      "Dataset carregado: (115591, 7)\n",
      "\n",
      "Distribuição das classes:\n",
      "casoDeUso\n",
      "uc0043    13099\n",
      "uc0232     7408\n",
      "uc0096     7042\n",
      "uc0146     5042\n",
      "uc0075     3394\n",
      "uc0222     3085\n",
      "uc0162     3018\n",
      "uc0111     2963\n",
      "uc0179     2896\n",
      "uc0069     2620\n",
      "Name: count, dtype: int64\n",
      "Processando dados para usuário: usuario_15\n",
      "Registros após filtro de usuário: 24020\n",
      "Criando features históricas...\n",
      "Registros após limpeza: 24020\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso_1', 'casoDeUso_2']\n",
      "Processando features contextuais...\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "Normalizando features sequenciais...\n",
      "Dividindo dados em treino e teste...\n",
      "⚠️ Aviso: 22 classes com apenas 1 amostra:\n",
      "casoDeUso\n",
      "uc0006    1\n",
      "uc0142    1\n",
      "uc0159    1\n",
      "uc1006    1\n",
      "uc1015    1\n",
      "Name: count, dtype: int64\n",
      "Removendo classes com poucas amostras para permitir estratificação...\n",
      "Dados após filtro: 23998 amostras, 168 classes\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "✅ Divisão estratificada realizada com sucesso\n",
      "Treino: 14398 samples\n",
      "Teste: 9600 samples\n",
      "=== CRIANDO MODELO DENSE HÍBRIDO ===\n",
      "Usando Dense layers: [128, 64]\n",
      "Modelo criado e compilado!\n",
      "Parâmetros totais: 67,856\n",
      "\n",
      "\n",
      "=== ARQUITETURA DO MODELO ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">378</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">48,512</span> │ input_sequence[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ input_epoch[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">11,088</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m378\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m48,512\u001b[0m │ input_sequence[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ input_epoch[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m168\u001b[0m)       │     \u001b[38;5;34m11,088\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,856</span> (265.06 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m67,856\u001b[0m (265.06 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,856</span> (265.06 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m67,856\u001b[0m (265.06 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INICIANDO TREINAMENTO ===\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 21:45:51.582858: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1111', 504 bytes spill stores, 504 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m340/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1166 - loss: 4.3650"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 21:45:54.218740: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1111_0', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-05-25 21:45:54.347904: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1111', 488 bytes spill stores, 488 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.1195 - loss: 4.3397 - val_accuracy: 0.2503 - val_loss: 3.3817 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2272 - loss: 3.4178 - val_accuracy: 0.2601 - val_loss: 3.2232 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2629 - loss: 3.2098 - val_accuracy: 0.2736 - val_loss: 3.1525 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2775 - loss: 3.0811 - val_accuracy: 0.2795 - val_loss: 3.1201 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2862 - loss: 3.0132 - val_accuracy: 0.2847 - val_loss: 3.0768 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2923 - loss: 2.9812 - val_accuracy: 0.2875 - val_loss: 3.0747 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2902 - loss: 2.9584 - val_accuracy: 0.2944 - val_loss: 3.0586 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3070 - loss: 2.8795 - val_accuracy: 0.2868 - val_loss: 3.0545 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3044 - loss: 2.8257 - val_accuracy: 0.2889 - val_loss: 3.0539 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2926 - loss: 2.8491 - val_accuracy: 0.2927 - val_loss: 3.0498 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3037 - loss: 2.8368 - val_accuracy: 0.2990 - val_loss: 3.0546 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3037 - loss: 2.8137 - val_accuracy: 0.2979 - val_loss: 3.0682 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2993 - loss: 2.7760 - val_accuracy: 0.2937 - val_loss: 3.0751 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3146 - loss: 2.7617 - val_accuracy: 0.2913 - val_loss: 3.0684 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m353/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3005 - loss: 2.7469\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3005 - loss: 2.7475 - val_accuracy: 0.2958 - val_loss: 3.0778 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3200 - loss: 2.7190 - val_accuracy: 0.2906 - val_loss: 3.0848 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3137 - loss: 2.7016 - val_accuracy: 0.2941 - val_loss: 3.0876 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3174 - loss: 2.7206 - val_accuracy: 0.2910 - val_loss: 3.0982 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3181 - loss: 2.6823 - val_accuracy: 0.2941 - val_loss: 3.0953 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m359/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3161 - loss: 2.6594\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3161 - loss: 2.6595 - val_accuracy: 0.2979 - val_loss: 3.0942 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3255 - loss: 2.6600 - val_accuracy: 0.2948 - val_loss: 3.1023 - learning_rate: 2.5000e-04\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Treinamento concluído!\n",
      "=== AVALIANDO MODELO ===\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Acurácia: 29.14%\n",
      "\n",
      "=== RELATÓRIO DE CLASSIFICAÇÃO ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      uc0003       0.00      0.00      0.00         1\n",
      "      uc0004       0.00      0.00      0.00         6\n",
      "      uc0012       0.56      0.50      0.53        10\n",
      "      uc0013       0.00      0.00      0.00        10\n",
      "      uc0014       0.00      0.00      0.00         1\n",
      "      uc0015       0.00      0.00      0.00         2\n",
      "      uc0016       0.15      0.07      0.10       294\n",
      "      uc0017       0.00      0.00      0.00        43\n",
      "     uc0018b       0.00      0.00      0.00         2\n",
      "      uc0019       0.25      0.37      0.30       224\n",
      "      uc0020       0.00      0.00      0.00         1\n",
      "      uc0023       0.82      1.00      0.90        33\n",
      "      uc0024       0.31      0.37      0.34       418\n",
      "      uc0025       0.00      0.00      0.00         3\n",
      "   uc0025_01       0.00      0.00      0.00        39\n",
      "      uc0026       0.00      0.00      0.00        12\n",
      "      uc0027       0.27      0.21      0.24        14\n",
      "      uc0028       0.20      0.02      0.04        81\n",
      "      uc0029       0.49      0.66      0.56       158\n",
      "      uc0030       0.53      0.60      0.56       204\n",
      "      uc0031       0.30      0.13      0.18       189\n",
      "      uc0032       0.46      0.30      0.36        20\n",
      "      uc0033       0.27      0.19      0.22        32\n",
      "      uc0034       0.50      0.14      0.22        83\n",
      "      uc0035       0.20      0.36      0.26        11\n",
      "      uc0036       0.00      0.00      0.00         3\n",
      "      uc0037       0.00      0.00      0.00         3\n",
      "      uc0039       0.50      0.21      0.30        14\n",
      "      uc0040       0.56      0.75      0.64        12\n",
      "      uc0041       0.00      0.00      0.00         1\n",
      "      uc0042       0.36      0.70      0.47        27\n",
      "      uc0043       0.23      0.48      0.31      1110\n",
      "      uc0044       0.22      0.32      0.26        60\n",
      "      uc0045       0.00      0.00      0.00        57\n",
      "      uc0047       0.00      0.00      0.00        69\n",
      "      uc0049       0.67      0.29      0.40         7\n",
      "      uc0050       0.00      0.00      0.00         2\n",
      "      uc0052       0.00      0.00      0.00         6\n",
      "      uc0053       0.34      0.24      0.28       122\n",
      "      uc0056       0.00      0.00      0.00        17\n",
      "      uc0058       0.00      0.00      0.00        19\n",
      "      uc0059       0.24      0.46      0.32        26\n",
      "      uc0060       0.47      0.33      0.39        52\n",
      "      uc0061       0.00      0.00      0.00         8\n",
      "      uc0062       0.00      0.00      0.00         3\n",
      "      uc0067       0.00      0.00      0.00         6\n",
      "      uc0068       0.00      0.00      0.00        22\n",
      "      uc0069       0.32      0.41      0.36       274\n",
      "      uc0070       0.00      0.00      0.00         2\n",
      "      uc0072       0.00      0.00      0.00         1\n",
      "      uc0075       0.44      0.58      0.50       314\n",
      "      uc0076       0.00      0.00      0.00        50\n",
      "      uc0077       0.29      0.42      0.35       156\n",
      "      uc0078       0.21      0.15      0.18        20\n",
      "      uc0079       0.00      0.00      0.00        16\n",
      "      uc0080       0.00      0.00      0.00         2\n",
      "      uc0081       0.00      0.00      0.00        23\n",
      "      uc0084       0.00      0.00      0.00         2\n",
      "      uc0085       0.00      0.00      0.00        15\n",
      "      uc0086       0.35      0.22      0.27        32\n",
      "      uc0087       0.14      0.07      0.09        30\n",
      "      uc0089       0.00      0.00      0.00         9\n",
      "      uc0090       0.00      0.00      0.00        30\n",
      "      uc0091       0.32      0.61      0.42        28\n",
      "      uc0093       0.20      0.10      0.13        10\n",
      "      uc0094       0.19      0.02      0.04       130\n",
      "      uc0096       0.40      0.61      0.48       838\n",
      "      uc0097       0.25      0.08      0.12        13\n",
      "      uc0098       0.77      0.62      0.69        16\n",
      "      uc0100       0.00      0.00      0.00        31\n",
      "      uc0102       0.17      0.17      0.17         6\n",
      "      uc0103       0.00      0.00      0.00         1\n",
      "      uc0105       0.00      0.00      0.00         4\n",
      "      uc0107       0.47      0.69      0.56        71\n",
      "      uc0108       0.61      0.42      0.50        26\n",
      "      uc0109       0.00      0.00      0.00         7\n",
      "      uc0110       0.67      0.24      0.35        17\n",
      "      uc0111       0.00      0.00      0.00       299\n",
      "      uc0112       0.00      0.00      0.00         7\n",
      "      uc0113       0.00      0.00      0.00        13\n",
      "      uc0114       0.00      0.00      0.00        17\n",
      "      uc0115       0.24      0.30      0.26        27\n",
      "      uc0116       0.00      0.00      0.00         4\n",
      "      uc0117       0.50      0.50      0.50         2\n",
      "      uc0118       0.00      0.00      0.00         4\n",
      "      uc0124       0.32      0.08      0.13       144\n",
      "      uc0125       0.23      0.35      0.28        26\n",
      "      uc0126       0.15      0.05      0.08       411\n",
      "      uc0130       0.33      0.13      0.19        69\n",
      "      uc0131       0.00      0.00      0.00       158\n",
      "      uc0133       0.00      0.00      0.00         1\n",
      "      uc0134       0.00      0.00      0.00        43\n",
      "      uc0135       0.00      0.00      0.00         4\n",
      "      uc0136       0.00      0.00      0.00         4\n",
      "      uc0137       0.00      0.00      0.00         8\n",
      "      uc0138       0.00      0.00      0.00         9\n",
      "      uc0139       0.19      0.30      0.23       225\n",
      "      uc0141       0.00      0.00      0.00         2\n",
      "      uc0146       0.16      0.27      0.20       650\n",
      "      uc0147       0.00      0.00      0.00         2\n",
      "      uc0149       0.25      0.14      0.18        29\n",
      "      uc0150       0.19      0.05      0.07       152\n",
      "      uc0153       0.36      0.20      0.26        25\n",
      "      uc0157       0.56      0.62      0.59        16\n",
      "      uc0158       0.00      0.00      0.00         3\n",
      "      uc0162       0.30      0.22      0.25       308\n",
      "      uc0165       0.00      0.00      0.00        22\n",
      "      uc0167       0.00      0.00      0.00         5\n",
      "      uc0169       0.00      0.00      0.00        20\n",
      "      uc0171       0.00      0.00      0.00         7\n",
      "      uc0173       0.00      0.00      0.00         1\n",
      "      uc0175       0.00      0.00      0.00         1\n",
      "      uc0178       0.00      0.00      0.00         9\n",
      "      uc0179       0.00      0.00      0.00       134\n",
      "      uc0181       0.11      0.04      0.05        85\n",
      "      uc0186       0.22      0.15      0.18        26\n",
      "      uc0187       0.00      0.00      0.00         1\n",
      "      uc0189       0.25      0.12      0.17         8\n",
      "      uc0190       0.00      0.00      0.00         1\n",
      "      uc0191       0.00      0.00      0.00         1\n",
      "      uc0192       0.00      0.00      0.00         1\n",
      "      uc0193       0.00      0.00      0.00         1\n",
      "      uc0197       0.00      0.00      0.00         5\n",
      "      uc0198       0.17      0.07      0.10        68\n",
      "      uc0201       0.00      0.00      0.00         7\n",
      "      uc0202       0.00      0.00      0.00         1\n",
      "      uc0206       0.00      0.00      0.00         1\n",
      "      uc0209       0.45      0.25      0.32        20\n",
      "      uc0211       0.20      0.19      0.19        96\n",
      "      uc0212       0.65      0.48      0.55        88\n",
      "      uc0215       0.40      0.10      0.16       137\n",
      "      uc0216       0.37      0.48      0.42        27\n",
      "      uc0217       0.00      0.00      0.00         2\n",
      "      uc0219       0.57      0.31      0.40        13\n",
      "      uc0220       0.19      0.71      0.30         7\n",
      "      uc0221       1.00      0.33      0.50         3\n",
      "      uc0222       0.15      0.08      0.10        88\n",
      "      uc0223       0.00      0.00      0.00         1\n",
      "      uc0225       0.00      0.00      0.00         6\n",
      "      uc0226       0.40      0.79      0.54        48\n",
      "      uc0228       0.00      0.00      0.00        15\n",
      "      uc0229       0.00      0.00      0.00         1\n",
      "      uc0230       0.29      0.45      0.36        11\n",
      "      uc0232       0.24      0.13      0.17        61\n",
      "      uc0233       0.00      0.00      0.00         4\n",
      "      uc0234       0.00      0.00      0.00         6\n",
      "      uc0235       0.23      0.17      0.19        78\n",
      "      uc0238       0.50      0.16      0.24        25\n",
      "      uc0240       0.00      0.00      0.00        11\n",
      "      uc0241       0.00      0.00      0.00         4\n",
      "      uc0242       0.00      0.00      0.00         4\n",
      "      uc0250       0.00      0.00      0.00         1\n",
      "      uc0253       0.00      0.00      0.00         1\n",
      "      uc0254       0.00      0.00      0.00         1\n",
      "      uc0256       0.00      0.00      0.00        10\n",
      "      uc0264       0.00      0.00      0.00         4\n",
      "      uc0265       0.00      0.00      0.00         2\n",
      "      uc1003       0.00      0.00      0.00         8\n",
      "      uc1004       0.00      0.00      0.00         4\n",
      "      uc1009       0.25      0.50      0.33         2\n",
      "      uc1010       1.00      0.33      0.50         3\n",
      "      uc1013       0.00      0.00      0.00         3\n",
      "      uc1014       0.00      0.00      0.00         8\n",
      "      uc1016       0.00      0.00      0.00         7\n",
      "      uc1017       0.00      0.00      0.00         9\n",
      "      uc1019       0.00      0.00      0.00         1\n",
      "      uc2097       0.00      0.00      0.00         1\n",
      "      uc2101       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.29      9600\n",
      "   macro avg       0.16      0.14      0.14      9600\n",
      "weighted avg       0.25      0.29      0.25      9600\n",
      "\n",
      "🔍 Debug - Tipo de 'results': <class 'dict'>\n",
      "🔍 Debug - Chaves disponíveis: ['accuracy', 'y_pred', 'y_test', 'confusion_matrix', 'class_names', 'y_pred_proba']\n",
      "✅ Usuário usuario_15 processado com sucesso!\n",
      "\n",
      "🔄 Processando usuário 17/17: usuario_16\n",
      "----------------------------------------\n",
      "=== INICIANDO PREPROCESSAMENTO ===\n",
      "Carregando dados de: ../dados/processados/Dados_TechChallenge_Fase3.csv\n",
      "Dataset carregado: (115591, 7)\n",
      "\n",
      "Distribuição das classes:\n",
      "casoDeUso\n",
      "uc0043    13099\n",
      "uc0232     7408\n",
      "uc0096     7042\n",
      "uc0146     5042\n",
      "uc0075     3394\n",
      "uc0222     3085\n",
      "uc0162     3018\n",
      "uc0111     2963\n",
      "uc0179     2896\n",
      "uc0069     2620\n",
      "Name: count, dtype: int64\n",
      "Processando dados para usuário: usuario_16\n",
      "Registros após filtro de usuário: 32\n",
      "Criando features históricas...\n",
      "Registros após limpeza: 32\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso_1', 'casoDeUso_2']\n",
      "Processando features contextuais...\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "Normalizando features sequenciais...\n",
      "Dividindo dados em treino e teste...\n",
      "⚠️ Aviso: 6 classes com apenas 1 amostra:\n",
      "casoDeUso\n",
      "uc0253    1\n",
      "uc0169    1\n",
      "uc0235    1\n",
      "uc0238    1\n",
      "uc0181    1\n",
      "Name: count, dtype: int64\n",
      "Removendo classes com poucas amostras para permitir estratificação...\n",
      "Dados após filtro: 26 amostras, 3 classes\n",
      "Aplicando One-Hot Encoding em: ['casoDeUso']\n",
      "✅ Divisão estratificada realizada com sucesso\n",
      "Treino: 15 samples\n",
      "Teste: 11 samples\n",
      "=== CRIANDO MODELO DENSE HÍBRIDO ===\n",
      "Usando Dense layers: [128, 64]\n",
      "Modelo criado e compilado!\n",
      "Parâmetros totais: 10,758\n",
      "\n",
      "\n",
      "=== ARQUITETURA DO MODELO ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_17\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_17\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> │ input_sequence[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ input_epoch[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_sequence      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m2,304\u001b[0m │ input_sequence[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_epoch         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ input_epoch[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m198\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,758</span> (42.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,758\u001b[0m (42.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,758</span> (42.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,758\u001b[0m (42.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INICIANDO TREINAMENTO ===\n",
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.0833 - loss: 1.2356 - val_accuracy: 0.0000e+00 - val_loss: 1.4227 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.3333 - loss: 1.1494 - val_accuracy: 0.0000e+00 - val_loss: 1.3814 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.2500 - loss: 1.0766 - val_accuracy: 0.0000e+00 - val_loss: 1.3395 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.4167 - loss: 0.9392 - val_accuracy: 0.0000e+00 - val_loss: 1.2988 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.4167 - loss: 0.9805 - val_accuracy: 0.0000e+00 - val_loss: 1.2609 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5833 - loss: 0.8933 - val_accuracy: 0.0000e+00 - val_loss: 1.2280 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5833 - loss: 0.9111 - val_accuracy: 0.0000e+00 - val_loss: 1.1982 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6667 - loss: 0.8069 - val_accuracy: 0.0000e+00 - val_loss: 1.1702 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7500 - loss: 0.7484 - val_accuracy: 0.3333 - val_loss: 1.1449 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.9167 - loss: 0.7275 - val_accuracy: 0.6667 - val_loss: 1.1213 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.8333 - loss: 0.7242 - val_accuracy: 0.6667 - val_loss: 1.0993 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7500 - loss: 0.7168 - val_accuracy: 0.6667 - val_loss: 1.0786 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8333 - loss: 0.7812 - val_accuracy: 0.6667 - val_loss: 1.0597 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8333 - loss: 0.7289 - val_accuracy: 0.6667 - val_loss: 1.0435 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7500 - loss: 0.7220 - val_accuracy: 0.6667 - val_loss: 1.0283 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9167 - loss: 0.5076 - val_accuracy: 0.6667 - val_loss: 1.0144 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8333 - loss: 0.6188 - val_accuracy: 0.6667 - val_loss: 1.0017 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8333 - loss: 0.5663 - val_accuracy: 0.6667 - val_loss: 0.9906 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.4159 - val_accuracy: 0.6667 - val_loss: 0.9808 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9167 - loss: 0.5019 - val_accuracy: 0.6667 - val_loss: 0.9735 - learning_rate: 0.0010\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Treinamento concluído!\n",
      "=== AVALIANDO MODELO ===\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
      "Acurácia: 72.73%\n",
      "\n",
      "=== RELATÓRIO DE CLASSIFICAÇÃO ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      uc0043       0.00      0.00      0.00         1\n",
      "      uc0162       0.80      1.00      0.89         4\n",
      "      uc0232       0.80      0.67      0.73         6\n",
      "\n",
      "    accuracy                           0.73        11\n",
      "   macro avg       0.53      0.56      0.54        11\n",
      "weighted avg       0.73      0.73      0.72        11\n",
      "\n",
      "🔍 Debug - Tipo de 'results': <class 'dict'>\n",
      "🔍 Debug - Chaves disponíveis: ['accuracy', 'y_pred', 'y_test', 'confusion_matrix', 'class_names', 'y_pred_proba']\n",
      "✅ Usuário usuario_16 processado com sucesso!\n",
      "\n",
      "============================================================\n",
      "📊 COMPARAÇÃO DE RESULTADOS\n",
      "============================================================\n",
      "\n",
      "👤 Usuário: usuario_00\n",
      "   🎯 Accuracy: 0.2183\n",
      "   📊 Precision: N/A\n",
      "   📊 Recall: N/A\n",
      "   📊 F1-Score: N/A\n",
      "   🏷️ Classes: ['uc0212', 'uc0232', 'uc2001', 'uc2002', 'uc2005', 'uc2006', 'uc2007', 'uc2008', 'uc2011', 'uc2012', 'uc2014', 'uc2019', 'uc2020', 'uc2023', 'uc2025', 'uc2026', 'uc2027', 'uc2028', 'uc2029', 'uc2030', 'uc2032', 'uc2033', 'uc2034', 'uc2036', 'uc2037', 'uc2039', 'uc2040', 'uc2043', 'uc2045', 'uc2046', 'uc2048', 'uc2049', 'uc2053', 'uc2055', 'uc2056', 'uc2059', 'uc2060', 'uc2062', 'uc2063', 'uc2064', 'uc2065', 'uc2066', 'uc2067', 'uc2068', 'uc2071', 'uc2072', 'uc2073', 'uc2074', 'uc2075', 'uc2076', 'uc2077', 'uc2078', 'uc2082', 'uc2083', 'uc2084', 'uc2086', 'uc2092', 'uc2095', 'uc2096', 'uc2098', 'uc2100']\n",
      "\n",
      "👤 Usuário: usuario_01\n",
      "   🎯 Accuracy: 0.5703\n",
      "   📊 Precision: N/A\n",
      "   📊 Recall: N/A\n",
      "   📊 F1-Score: N/A\n",
      "   🏷️ Classes: ['uc0043', 'uc0111', 'uc0131', 'uc0142', 'uc0146', 'uc0162', 'uc0169', 'uc0181', 'uc0221', 'uc0222', 'uc0232', 'uc0235', 'uc0238', 'uc1003', 'uc1017']\n",
      "\n",
      "👤 Usuário: usuario_02\n",
      "   🎯 Accuracy: 0.6275\n",
      "   📊 Precision: 0.6275\n",
      "   📊 Recall: 1.0000\n",
      "   📊 F1-Score: 0.7711\n",
      "   🏷️ Classes: ['uc0232', 'uc2057']\n",
      "\n",
      "👤 Usuário: usuario_03\n",
      "   🎯 Accuracy: 0.2587\n",
      "   📊 Precision: N/A\n",
      "   📊 Recall: N/A\n",
      "   📊 F1-Score: N/A\n",
      "   🏷️ Classes: ['uc0003', 'uc0004', 'uc0012', 'uc0013', 'uc0014', 'uc0015', 'uc0016', 'uc0017', 'uc0018b', 'uc0019', 'uc0020', 'uc0021', 'uc0023', 'uc0024', 'uc0025', 'uc0025_01', 'uc0026', 'uc0027', 'uc0028', 'uc0029', 'uc0030', 'uc0031', 'uc0032', 'uc0033', 'uc0034', 'uc0036', 'uc0039', 'uc0040', 'uc0041', 'uc0042', 'uc0043', 'uc0044', 'uc0045', 'uc0046', 'uc0047', 'uc0049', 'uc0052', 'uc0053', 'uc0054', 'uc0056', 'uc0058', 'uc0059', 'uc0060', 'uc0061', 'uc0062', 'uc0065', 'uc0067', 'uc0068', 'uc0069', 'uc0070', 'uc0072', 'uc0075', 'uc0076', 'uc0077', 'uc0078', 'uc0079', 'uc0080', 'uc0081', 'uc0082', 'uc0084', 'uc0085', 'uc0086', 'uc0087', 'uc0089', 'uc0090', 'uc0091', 'uc0093', 'uc0094', 'uc0096', 'uc0097', 'uc0098', 'uc0099', 'uc0100', 'uc0101', 'uc0102', 'uc0103', 'uc0105', 'uc0107', 'uc0108', 'uc0109', 'uc0110', 'uc0111', 'uc0112', 'uc0113', 'uc0114', 'uc0115', 'uc0116', 'uc0117', 'uc0118', 'uc0124', 'uc0125', 'uc0126', 'uc0128', 'uc0130', 'uc0131', 'uc0132', 'uc0133', 'uc0134', 'uc0135', 'uc0136', 'uc0137', 'uc0138', 'uc0139', 'uc0141', 'uc0146', 'uc0149', 'uc0150', 'uc0153', 'uc0156', 'uc0157', 'uc0158', 'uc0159', 'uc0161', 'uc0162', 'uc0163', 'uc0165', 'uc0167', 'uc0169', 'uc0171', 'uc0172', 'uc0173', 'uc0178', 'uc0179', 'uc0180', 'uc0181', 'uc0186', 'uc0187', 'uc0189', 'uc0190', 'uc0191', 'uc0192', 'uc0193', 'uc0195', 'uc0197', 'uc0198', 'uc0199', 'uc0209', 'uc0211', 'uc0212', 'uc0215', 'uc0216', 'uc0217', 'uc0219', 'uc0220', 'uc0221', 'uc0222', 'uc0223', 'uc0225', 'uc0226', 'uc0228', 'uc0229', 'uc0230', 'uc0232', 'uc0233', 'uc0234', 'uc0235', 'uc0240', 'uc0241', 'uc0242', 'uc0243', 'uc0244', 'uc0256', 'uc1003', 'uc1004', 'uc1006', 'uc1007', 'uc1008', 'uc1009', 'uc1010', 'uc1011', 'uc1012', 'uc1013', 'uc1014', 'uc1015', 'uc1016', 'uc1017', 'uc1018', 'uc1019', 'uc2097']\n",
      "\n",
      "👤 Usuário: usuario_04\n",
      "   🎯 Accuracy: 0.2486\n",
      "   📊 Precision: N/A\n",
      "   📊 Recall: N/A\n",
      "   📊 F1-Score: N/A\n",
      "   🏷️ Classes: ['uc0212', 'uc0232', 'uc0234', 'uc0237', 'uc2001', 'uc2002', 'uc2005', 'uc2006', 'uc2007', 'uc2008', 'uc2009', 'uc2010', 'uc2011', 'uc2012', 'uc2014', 'uc2015', 'uc2017', 'uc2019', 'uc2020', 'uc2023', 'uc2025', 'uc2026', 'uc2027', 'uc2028', 'uc2029', 'uc2030', 'uc2031', 'uc2032', 'uc2033', 'uc2034', 'uc2036', 'uc2037', 'uc2038', 'uc2039', 'uc2040', 'uc2041', 'uc2043', 'uc2045', 'uc2046', 'uc2048', 'uc2049', 'uc2053', 'uc2054', 'uc2055', 'uc2056', 'uc2059', 'uc2060', 'uc2061', 'uc2062', 'uc2063', 'uc2064', 'uc2065', 'uc2066', 'uc2067', 'uc2068', 'uc2071', 'uc2072', 'uc2073', 'uc2074', 'uc2075', 'uc2076', 'uc2077', 'uc2078', 'uc2079', 'uc2081', 'uc2083', 'uc2084', 'uc2085', 'uc2086', 'uc2092', 'uc2095', 'uc2096', 'uc2098', 'uc2100']\n",
      "\n",
      "👤 Usuário: usuario_05\n",
      "   🎯 Accuracy: 0.2733\n",
      "   📊 Precision: N/A\n",
      "   📊 Recall: N/A\n",
      "   📊 F1-Score: N/A\n",
      "   🏷️ Classes: ['uc0001', 'uc0003', 'uc0004', 'uc0012', 'uc0013', 'uc0015', 'uc0016', 'uc0017', 'uc0018b', 'uc0019', 'uc0020', 'uc0023', 'uc0024', 'uc0025_01', 'uc0026', 'uc0027', 'uc0028', 'uc0029', 'uc0030', 'uc0031', 'uc0032', 'uc0033', 'uc0034', 'uc0035', 'uc0036', 'uc0039', 'uc0040', 'uc0041', 'uc0042', 'uc0043', 'uc0044', 'uc0045', 'uc0047', 'uc0050', 'uc0052', 'uc0053', 'uc0056', 'uc0058', 'uc0059', 'uc0060', 'uc0061', 'uc0062', 'uc0065', 'uc0067', 'uc0068', 'uc0069', 'uc0070', 'uc0075', 'uc0076', 'uc0077', 'uc0078', 'uc0079', 'uc0080', 'uc0081', 'uc0084', 'uc0085', 'uc0086', 'uc0087', 'uc0089', 'uc0090', 'uc0091', 'uc0093', 'uc0094', 'uc0096', 'uc0097', 'uc0098', 'uc0100', 'uc0101', 'uc0102', 'uc0103', 'uc0105', 'uc0107', 'uc0108', 'uc0109', 'uc0110', 'uc0111', 'uc0112', 'uc0113', 'uc0114', 'uc0115', 'uc0116', 'uc0117', 'uc0118', 'uc0124', 'uc0125', 'uc0126', 'uc0127', 'uc0128', 'uc0130', 'uc0131', 'uc0133', 'uc0134', 'uc0135', 'uc0136', 'uc0137', 'uc0138', 'uc0139', 'uc0141', 'uc0146', 'uc0147', 'uc0149', 'uc0150', 'uc0153', 'uc0155', 'uc0156', 'uc0157', 'uc0158', 'uc0159', 'uc0161', 'uc0162', 'uc0163', 'uc0165', 'uc0167', 'uc0169', 'uc0171', 'uc0175', 'uc0179', 'uc0181', 'uc0186', 'uc0187', 'uc0189', 'uc0192', 'uc0193', 'uc0198', 'uc0209', 'uc0211', 'uc0212', 'uc0215', 'uc0216', 'uc0219', 'uc0220', 'uc0221', 'uc0222', 'uc0226', 'uc0230', 'uc0233', 'uc0234', 'uc0235', 'uc0238', 'uc0240', 'uc1003', 'uc1004', 'uc1005', 'uc1006', 'uc1007', 'uc1009', 'uc1010', 'uc1011', 'uc1012', 'uc1013', 'uc1014', 'uc1017', 'uc1019']\n",
      "\n",
      "👤 Usuário: usuario_06\n",
      "   🎯 Accuracy: 0.8611\n",
      "   📊 Precision: 1.0000\n",
      "   📊 Recall: 0.5833\n",
      "   📊 F1-Score: 0.7368\n",
      "   🏷️ Classes: ['uc2087', 'uc2090']\n",
      "\n",
      "👤 Usuário: usuario_07\n",
      "   🎯 Accuracy: 0.3336\n",
      "   📊 Precision: N/A\n",
      "   📊 Recall: N/A\n",
      "   📊 F1-Score: N/A\n",
      "   🏷️ Classes: ['uc0013', 'uc0016', 'uc0017', 'uc0018b', 'uc0019', 'uc0031', 'uc0039', 'uc0040', 'uc0042', 'uc0043', 'uc0044', 'uc0045', 'uc0047', 'uc0052', 'uc0053', 'uc0054', 'uc0056', 'uc0058', 'uc0059', 'uc0060', 'uc0061', 'uc0068', 'uc0069', 'uc0075', 'uc0076', 'uc0077', 'uc0079', 'uc0080', 'uc0086', 'uc0087', 'uc0094', 'uc0096', 'uc0097', 'uc0098', 'uc0102', 'uc0103', 'uc0107', 'uc0110', 'uc0111', 'uc0114', 'uc0115', 'uc0124', 'uc0125', 'uc0126', 'uc0131', 'uc0132', 'uc0134', 'uc0139', 'uc0140', 'uc0146', 'uc0150', 'uc0153', 'uc0156', 'uc0157', 'uc0159', 'uc0162', 'uc0169', 'uc0173', 'uc0178', 'uc0179', 'uc0181', 'uc0191', 'uc0192', 'uc0200', 'uc0209', 'uc0211', 'uc0212', 'uc0215', 'uc0222', 'uc0223', 'uc0226', 'uc0229', 'uc0232', 'uc0233', 'uc0234', 'uc0235', 'uc0238', 'uc0240', 'uc0241', 'uc0242', 'uc0244', 'uc0253', 'uc0265', 'uc1003', 'uc1004', 'uc1006', 'uc1007', 'uc1009', 'uc1010', 'uc1011', 'uc1012', 'uc1013', 'uc1015', 'uc1017', 'uc2001', 'uc2002', 'uc2005', 'uc2006', 'uc2007', 'uc2008', 'uc2009', 'uc2011', 'uc2012', 'uc2014', 'uc2017', 'uc2019', 'uc2020', 'uc2021', 'uc2023', 'uc2025', 'uc2026', 'uc2027', 'uc2028', 'uc2029', 'uc2030', 'uc2031', 'uc2032', 'uc2033', 'uc2034', 'uc2036', 'uc2037', 'uc2039', 'uc2040', 'uc2041', 'uc2043', 'uc2044', 'uc2045', 'uc2046', 'uc2048', 'uc2049', 'uc2051', 'uc2053', 'uc2054', 'uc2055', 'uc2056', 'uc2059', 'uc2060', 'uc2061', 'uc2062', 'uc2063', 'uc2064', 'uc2065', 'uc2066', 'uc2067', 'uc2068', 'uc2071', 'uc2072', 'uc2073', 'uc2074', 'uc2075', 'uc2076', 'uc2077', 'uc2078', 'uc2079', 'uc2081', 'uc2082', 'uc2083', 'uc2084', 'uc2085', 'uc2086', 'uc2092', 'uc2095', 'uc2096', 'uc2101']\n",
      "\n",
      "👤 Usuário: usuario_08\n",
      "   🎯 Accuracy: 0.6033\n",
      "   📊 Precision: N/A\n",
      "   📊 Recall: N/A\n",
      "   📊 F1-Score: N/A\n",
      "   🏷️ Classes: ['uc0043', 'uc0111', 'uc0131', 'uc0146', 'uc0162', 'uc0169', 'uc0171', 'uc0181', 'uc0187', 'uc0221', 'uc0222', 'uc0232', 'uc0233', 'uc0235', 'uc0238', 'uc0253', 'uc1003', 'uc1017']\n",
      "\n",
      "👤 Usuário: usuario_09\n",
      "   🎯 Accuracy: 0.3030\n",
      "   📊 Precision: N/A\n",
      "   📊 Recall: N/A\n",
      "   📊 F1-Score: N/A\n",
      "   🏷️ Classes: ['uc0003', 'uc0004', 'uc0006', 'uc0016', 'uc0017', 'uc0018b', 'uc0019', 'uc0023', 'uc0024', 'uc0025', 'uc0025_01', 'uc0026', 'uc0027', 'uc0028', 'uc0029', 'uc0030', 'uc0031', 'uc0032', 'uc0034', 'uc0036', 'uc0043', 'uc0044', 'uc0045', 'uc0047', 'uc0052', 'uc0053', 'uc0056', 'uc0058', 'uc0059', 'uc0060', 'uc0061', 'uc0068', 'uc0069', 'uc0075', 'uc0076', 'uc0077', 'uc0087', 'uc0094', 'uc0096', 'uc0097', 'uc0100', 'uc0111', 'uc0112', 'uc0114', 'uc0124', 'uc0125', 'uc0126', 'uc0127', 'uc0130', 'uc0131', 'uc0134', 'uc0137', 'uc0138', 'uc0139', 'uc0140', 'uc0146', 'uc0149', 'uc0150', 'uc0162', 'uc0165', 'uc0169', 'uc0172', 'uc0175', 'uc0178', 'uc0179', 'uc0181', 'uc0186', 'uc0190', 'uc0191', 'uc0195', 'uc0198', 'uc0201', 'uc0209', 'uc0211', 'uc0212', 'uc0215', 'uc0219', 'uc0221', 'uc0222', 'uc0226', 'uc0228', 'uc0229', 'uc0230', 'uc0232', 'uc0234', 'uc0235', 'uc0238', 'uc0243', 'uc0253', 'uc0255', 'uc0265', 'uc0266', 'uc1003', 'uc1004', 'uc1006', 'uc1007', 'uc1009', 'uc1010', 'uc1015', 'uc1017', 'uc2097', 'uc2101']\n",
      "\n",
      "👤 Usuário: usuario_10\n",
      "   🎯 Accuracy: 0.3117\n",
      "   📊 Precision: N/A\n",
      "   📊 Recall: N/A\n",
      "   📊 F1-Score: N/A\n",
      "   🏷️ Classes: ['uc0003', 'uc0004', 'uc0006', 'uc0012', 'uc0013', 'uc0014', 'uc0015', 'uc0016', 'uc0017', 'uc0018b', 'uc0019', 'uc0021', 'uc0023', 'uc0024', 'uc0025', 'uc0025_01', 'uc0026', 'uc0027', 'uc0028', 'uc0029', 'uc0030', 'uc0031', 'uc0032', 'uc0033', 'uc0034', 'uc0036', 'uc0037', 'uc0039', 'uc0040', 'uc0041', 'uc0042', 'uc0043', 'uc0044', 'uc0045', 'uc0047', 'uc0049', 'uc0050', 'uc0052', 'uc0053', 'uc0056', 'uc0058', 'uc0059', 'uc0060', 'uc0061', 'uc0062', 'uc0064', 'uc0067', 'uc0068', 'uc0069', 'uc0075', 'uc0077', 'uc0078', 'uc0079', 'uc0080', 'uc0081', 'uc0085', 'uc0086', 'uc0087', 'uc0089', 'uc0090', 'uc0091', 'uc0092', 'uc0093', 'uc0094', 'uc0096', 'uc0097', 'uc0098', 'uc0100', 'uc0102', 'uc0103', 'uc0105', 'uc0107', 'uc0108', 'uc0109', 'uc0110', 'uc0111', 'uc0112', 'uc0113', 'uc0114', 'uc0115', 'uc0116', 'uc0117', 'uc0118', 'uc0124', 'uc0125', 'uc0126', 'uc0127', 'uc0128', 'uc0130', 'uc0131', 'uc0133', 'uc0134', 'uc0135', 'uc0136', 'uc0137', 'uc0138', 'uc0139', 'uc0141', 'uc0146', 'uc0148', 'uc0149', 'uc0150', 'uc0153', 'uc0157', 'uc0158', 'uc0159', 'uc0161', 'uc0162', 'uc0164', 'uc0165', 'uc0167', 'uc0169', 'uc0171', 'uc0173', 'uc0175', 'uc0178', 'uc0179', 'uc0181', 'uc0186', 'uc0187', 'uc0189', 'uc0190', 'uc0191', 'uc0193', 'uc0195', 'uc0198', 'uc0209', 'uc0211', 'uc0212', 'uc0215', 'uc0216', 'uc0219', 'uc0220', 'uc0221', 'uc0222', 'uc0223', 'uc0226', 'uc0229', 'uc0230', 'uc0232', 'uc0233', 'uc0234', 'uc0235', 'uc0238', 'uc0242', 'uc0243', 'uc1003', 'uc1004', 'uc1006', 'uc1007', 'uc1008', 'uc1009', 'uc1010', 'uc1011', 'uc1012', 'uc1013', 'uc1014', 'uc1016', 'uc1017', 'uc1018', 'uc1019']\n",
      "\n",
      "👤 Usuário: usuario_11\n",
      "   🎯 Accuracy: 0.3077\n",
      "   📊 Precision: N/A\n",
      "   📊 Recall: N/A\n",
      "   📊 F1-Score: N/A\n",
      "   🏷️ Classes: ['uc0114', 'uc0232', 'uc2023', 'uc2025', 'uc2029', 'uc2030', 'uc2031', 'uc2032', 'uc2033', 'uc2034', 'uc2036', 'uc2040', 'uc2041', 'uc2056', 'uc2061', 'uc2062', 'uc2074', 'uc2075', 'uc2083', 'uc2086', 'uc2092']\n",
      "\n",
      "👤 Usuário: usuario_12\n",
      "   🎯 Accuracy: 0.3805\n",
      "   📊 Precision: N/A\n",
      "   📊 Recall: N/A\n",
      "   📊 F1-Score: N/A\n",
      "   🏷️ Classes: ['uc0096', 'uc0114', 'uc0235', 'uc2001', 'uc2002', 'uc2023', 'uc2029', 'uc2031', 'uc2032', 'uc2033', 'uc2036', 'uc2045', 'uc2059', 'uc2061', 'uc2074', 'uc2075', 'uc2093']\n",
      "\n",
      "👤 Usuário: usuario_13\n",
      "   🎯 Accuracy: 0.6282\n",
      "   📊 Precision: N/A\n",
      "   📊 Recall: N/A\n",
      "   📊 F1-Score: N/A\n",
      "   🏷️ Classes: ['uc0232', 'uc2087', 'uc2088', 'uc2089', 'uc2090']\n",
      "\n",
      "👤 Usuário: usuario_14\n",
      "   🎯 Accuracy: 0.3564\n",
      "   📊 Precision: N/A\n",
      "   📊 Recall: N/A\n",
      "   📊 F1-Score: N/A\n",
      "   🏷️ Classes: ['uc0012', 'uc0013', 'uc0015', 'uc0016', 'uc0017', 'uc0018b', 'uc0019', 'uc0031', 'uc0036', 'uc0039', 'uc0040', 'uc0041', 'uc0042', 'uc0043', 'uc0044', 'uc0045', 'uc0047', 'uc0052', 'uc0053', 'uc0054', 'uc0056', 'uc0058', 'uc0059', 'uc0060', 'uc0061', 'uc0062', 'uc0065', 'uc0067', 'uc0068', 'uc0069', 'uc0075', 'uc0076', 'uc0077', 'uc0079', 'uc0080', 'uc0085', 'uc0086', 'uc0087', 'uc0090', 'uc0091', 'uc0094', 'uc0096', 'uc0097', 'uc0098', 'uc0099', 'uc0100', 'uc0102', 'uc0103', 'uc0107', 'uc0108', 'uc0110', 'uc0111', 'uc0112', 'uc0113', 'uc0114', 'uc0115', 'uc0124', 'uc0125', 'uc0126', 'uc0128', 'uc0130', 'uc0131', 'uc0134', 'uc0136', 'uc0137', 'uc0140', 'uc0146', 'uc0150', 'uc0153', 'uc0162', 'uc0167', 'uc0169', 'uc0171', 'uc0173', 'uc0178', 'uc0179', 'uc0180', 'uc0181', 'uc0187', 'uc0189', 'uc0190', 'uc0191', 'uc0193', 'uc0195', 'uc0209', 'uc0211', 'uc0212', 'uc0215', 'uc0217', 'uc0221', 'uc0222', 'uc0223', 'uc0226', 'uc0229', 'uc0232', 'uc0233', 'uc0234', 'uc0235', 'uc0238', 'uc0240', 'uc0241', 'uc0242', 'uc0253', 'uc0255', 'uc0256', 'uc0265', 'uc1003', 'uc1004', 'uc1006', 'uc1007', 'uc1009', 'uc1010', 'uc1011', 'uc1012', 'uc1013', 'uc1014', 'uc1015', 'uc1016', 'uc1017', 'uc2101']\n",
      "\n",
      "👤 Usuário: usuario_15\n",
      "   🎯 Accuracy: 0.2914\n",
      "   📊 Precision: N/A\n",
      "   📊 Recall: N/A\n",
      "   📊 F1-Score: N/A\n",
      "   🏷️ Classes: ['uc0003', 'uc0004', 'uc0012', 'uc0013', 'uc0014', 'uc0015', 'uc0016', 'uc0017', 'uc0018b', 'uc0019', 'uc0020', 'uc0023', 'uc0024', 'uc0025', 'uc0025_01', 'uc0026', 'uc0027', 'uc0028', 'uc0029', 'uc0030', 'uc0031', 'uc0032', 'uc0033', 'uc0034', 'uc0035', 'uc0036', 'uc0037', 'uc0039', 'uc0040', 'uc0041', 'uc0042', 'uc0043', 'uc0044', 'uc0045', 'uc0047', 'uc0049', 'uc0050', 'uc0052', 'uc0053', 'uc0056', 'uc0058', 'uc0059', 'uc0060', 'uc0061', 'uc0062', 'uc0067', 'uc0068', 'uc0069', 'uc0070', 'uc0072', 'uc0075', 'uc0076', 'uc0077', 'uc0078', 'uc0079', 'uc0080', 'uc0081', 'uc0084', 'uc0085', 'uc0086', 'uc0087', 'uc0089', 'uc0090', 'uc0091', 'uc0093', 'uc0094', 'uc0096', 'uc0097', 'uc0098', 'uc0100', 'uc0102', 'uc0103', 'uc0105', 'uc0107', 'uc0108', 'uc0109', 'uc0110', 'uc0111', 'uc0112', 'uc0113', 'uc0114', 'uc0115', 'uc0116', 'uc0117', 'uc0118', 'uc0124', 'uc0125', 'uc0126', 'uc0130', 'uc0131', 'uc0133', 'uc0134', 'uc0135', 'uc0136', 'uc0137', 'uc0138', 'uc0139', 'uc0141', 'uc0146', 'uc0147', 'uc0149', 'uc0150', 'uc0153', 'uc0157', 'uc0158', 'uc0162', 'uc0165', 'uc0167', 'uc0169', 'uc0171', 'uc0173', 'uc0175', 'uc0178', 'uc0179', 'uc0181', 'uc0186', 'uc0187', 'uc0189', 'uc0190', 'uc0191', 'uc0192', 'uc0193', 'uc0197', 'uc0198', 'uc0201', 'uc0202', 'uc0206', 'uc0209', 'uc0211', 'uc0212', 'uc0215', 'uc0216', 'uc0217', 'uc0219', 'uc0220', 'uc0221', 'uc0222', 'uc0223', 'uc0225', 'uc0226', 'uc0228', 'uc0229', 'uc0230', 'uc0232', 'uc0233', 'uc0234', 'uc0235', 'uc0238', 'uc0240', 'uc0241', 'uc0242', 'uc0250', 'uc0253', 'uc0254', 'uc0256', 'uc0264', 'uc0265', 'uc1003', 'uc1004', 'uc1009', 'uc1010', 'uc1013', 'uc1014', 'uc1016', 'uc1017', 'uc1019', 'uc2097', 'uc2101']\n",
      "\n",
      "👤 Usuário: usuario_16\n",
      "   🎯 Accuracy: 0.7273\n",
      "   📊 Precision: N/A\n",
      "   📊 Recall: N/A\n",
      "   📊 F1-Score: N/A\n",
      "   🏷️ Classes: ['uc0043', 'uc0162', 'uc0232']\n",
      "\n",
      "============================================================\n",
      "🏆 RANKING DOS MELHORES RESULTADOS\n",
      "============================================================\n",
      "\n",
      "🥇 TOP 3 USUÁRIOS:\n",
      "🥇 1º lugar - usuario_06\n",
      "    🎯 Accuracy: 0.8611\n",
      "    📊 Precision: 1.0000\n",
      "    📊 F1-Score: 0.7368\n",
      "🥈 2º lugar - usuario_16\n",
      "    🎯 Accuracy: 0.7273\n",
      "    📊 Precision: N/A\n",
      "    📊 F1-Score: N/A\n",
      "🥉 3º lugar - usuario_13\n",
      "    🎯 Accuracy: 0.6282\n",
      "    📊 Precision: N/A\n",
      "    📊 F1-Score: N/A\n",
      "\n",
      "🎯 MELHOR MODELO: usuario_06 (Accuracy: 0.8611)\n",
      "\n",
      "============================================================\n",
      "📋 RESUMO ESTATÍSTICO\n",
      "============================================================\n",
      "Total de usuários processados: 17\n",
      "Sucessos: 17\n",
      "Erros: 0\n",
      "Taxa de sucesso: 100.0%\n",
      "\n",
      "✅ Pipeline concluído! Resultados salvos em 'resultados_completos'\n",
      "💡 Use 'resultados_completos[\"nome_usuario\"]' para acessar resultados específicos\n"
     ]
    }
   ],
   "source": [
    "print(\"🚀 Iniciando pipeline de Machine Learning por usuário...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "data_path='../dados/processados/Dados_TechChallenge_Fase3.csv'\n",
    "\n",
    "# Testar Listar usuários\n",
    "lista_usuarios = listar_usuarios(data_path=data_path)\n",
    "print(f\"Usuários encontrados: {lista_usuarios}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Dicionário para armazenar todos os resultados\n",
    "resultados_usuarios = {}\n",
    "\n",
    "# Loop através de todos os usuários\n",
    "for i, usuario in enumerate(lista_usuarios, 1):\n",
    "    print(f\"\\n🔄 Processando usuário {i}/{len(lista_usuarios)}: {usuario}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        model, history, results = main(\n",
    "            data_path=data_path,\n",
    "            usuario=usuario,\n",
    "            use_lstm=False,  # Usar Dense layers (mais estável)\n",
    "            epochs=50,\n",
    "            plotar_resultado=False,\n",
    "            salvar_modelo=False\n",
    "        )\n",
    "        \n",
    "        # Debug: verificar estrutura dos resultados\n",
    "        print(f\"Debug - Tipo de 'results': {type(results)}\")\n",
    "        print(f\"Debug - Chaves disponíveis: {list(results.keys()) if isinstance(results, dict) else 'N/A'}\")\n",
    "        \n",
    "        # Armazenar resultados do usuário\n",
    "        resultados_usuarios[usuario] = {\n",
    "            'model': model,\n",
    "            'history': history,\n",
    "            'results': results,\n",
    "            'status': 'sucesso'\n",
    "        }\n",
    "        \n",
    "        print(f\"✅ Usuário {usuario} processado com sucesso!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro ao processar usuário {usuario}: {str(e)}\")\n",
    "        resultados_usuarios[usuario] = {\n",
    "            'model': None,\n",
    "            'history': None,\n",
    "            'results': None,\n",
    "            'status': 'erro',\n",
    "            'erro': str(e)\n",
    "        }\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COMPARAÇÃO DE RESULTADOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Comparar resultados\n",
    "usuarios_sucesso = []\n",
    "usuarios_erro = []\n",
    "\n",
    "for usuario, dados in resultados_usuarios.items():\n",
    "    if dados['status'] == 'sucesso':\n",
    "        usuarios_sucesso.append(usuario)\n",
    "        results = dados['results']\n",
    "        \n",
    "        # Extrair métricas de classificação\n",
    "        accuracy = results.get('accuracy', 'N/A')\n",
    "        confusion_matrix = results.get('confusion_matrix', 'N/A')\n",
    "        class_names = results.get('class_names', 'N/A')\n",
    "        \n",
    "        # Calcular métricas adicionais da matriz de confusão\n",
    "        precision = recall = f1_score = 'N/A'\n",
    "        \n",
    "        if isinstance(confusion_matrix, type(results.get('confusion_matrix'))) and hasattr(confusion_matrix, 'shape'):\n",
    "            try:\n",
    "                # Para classificação binária\n",
    "                tn, fp, fn, tp = confusion_matrix.ravel()\n",
    "                precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "                recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "                f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        print(f\"\\nUsuário: {usuario}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\" if isinstance(accuracy, (int, float)) else f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Precision: {precision:.4f}\" if isinstance(precision, (int, float)) else f\"Precision: {precision}\")\n",
    "        print(f\"Recall: {recall:.4f}\" if isinstance(recall, (int, float)) else f\"Recall: {recall}\")\n",
    "        print(f\"F1-Score: {f1_score:.4f}\" if isinstance(f1_score, (int, float)) else f\"F1-Score: {f1_score}\")\n",
    "        print(f\"Classes: {class_names}\")\n",
    "    else:\n",
    "        usuarios_erro.append(usuario)\n",
    "        print(f\"\\n❌ Usuário: {usuario} - ERRO: {dados['erro']}\")\n",
    "\n",
    "# Encontrar o melhor usuário baseado em R²\n",
    "if usuarios_sucesso:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"🏆 RANKING DOS MELHORES RESULTADOS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Criar lista de usuários com suas métricas para ranking\n",
    "    usuarios_com_metricas = []\n",
    "    for usuario in usuarios_sucesso:\n",
    "        results = resultados_usuarios[usuario]['results']\n",
    "        \n",
    "        # Usar accuracy como métrica principal para ranking\n",
    "        accuracy_score = results.get('accuracy', 0)\n",
    "        \n",
    "        if isinstance(accuracy_score, (int, float)):\n",
    "            usuarios_com_metricas.append((usuario, accuracy_score, results))\n",
    "    \n",
    "    # Ordenar por Accuracy (maior é melhor)\n",
    "    usuarios_com_metricas.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(f\"\\n🥇 TOP 3 USUÁRIOS:\")\n",
    "    for i, (usuario, accuracy_score, results) in enumerate(usuarios_com_metricas[:3], 1):\n",
    "        \n",
    "        # Calcular métricas adicionais\n",
    "        confusion_matrix = results.get('confusion_matrix')\n",
    "        precision = recall = f1_score = 'N/A'\n",
    "        \n",
    "        if hasattr(confusion_matrix, 'ravel'):\n",
    "            try:\n",
    "                tn, fp, fn, tp = confusion_matrix.ravel()\n",
    "                precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "                recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "                f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        print(f\"{i}º lugar - {usuario}\")\n",
    "        print(f\"Accuracy: {accuracy_score:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\" if isinstance(precision, (int, float)) else f\"Precision: {precision}\")\n",
    "        print(f\"F1-Score: {f1_score:.4f}\" if isinstance(f1_score, (int, float)) else f\"F1-Score: {f1_score}\")\n",
    "    \n",
    "    melhor_usuario = usuarios_com_metricas[0][0]\n",
    "    print(f\"\\n🎯 MELHOR MODELO: {melhor_usuario} (Accuracy: {usuarios_com_metricas[0][1]:.4f})\")\n",
    "    \n",
    "# Resumo estatístico\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RESUMO ESTATÍSTICO\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total de usuários processados: {len(lista_usuarios)}\")\n",
    "print(f\"Sucessos: {len(usuarios_sucesso)}\")\n",
    "print(f\"Erros: {len(usuarios_erro)}\")\n",
    "print(f\"Taxa de sucesso: {len(usuarios_sucesso)/len(lista_usuarios)*100:.1f}%\")\n",
    "\n",
    "if usuarios_erro:\n",
    "    print(f\"\\nUsuários com erro: {', '.join(usuarios_erro)}\")\n",
    "\n",
    "# Salvar resultados em variável global para acesso posterior\n",
    "globals()['resultados_completos'] = resultados_usuarios\n",
    "\n",
    "print(\"\\n✅ Pipeline concluído! Resultados salvos em 'resultados_completos'\")\n",
    "print(\"Use 'resultados_completos[\\\"nome_usuario\\\"]' para acessar resultados específicos\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
